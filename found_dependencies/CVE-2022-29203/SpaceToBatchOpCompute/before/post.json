[
    {
        "line": 5,
        "fullcodeline": "const int input_dims = orig_input_tensor.dims();"
    },
    {
        "line": 11,
        "fullcodeline": "const int block_dims = orig_block_shape.dim_size(0);"
    },
    {
        "line": 27,
        "fullcodeline": "gtl::InlinedVector<int64_t, 4> block_shape;"
    },
    {
        "line": 28,
        "fullcodeline": "gtl::InlinedVector<int64_t, 8> paddings;"
    },
    {
        "line": 29,
        "fullcodeline": "internal::spacetobatch::SubtleMustCopyFlat(orig_block_shape, &block_shape);"
    },
    {
        "line": 30,
        "fullcodeline": "internal::spacetobatch::SubtleMustCopyFlat(orig_paddings, &paddings);"
    },
    {
        "line": 34,
        "fullcodeline": "int removed_prefix_block_dims = 0;"
    },
    {
        "line": 45,
        "fullcodeline": "int removed_suffix_block_dims = 0;"
    },
    {
        "line": 56,
        "fullcodeline": "int64_t block_shape_product = 1;"
    },
    {
        "line": 65,
        "fullcodeline": "const int internal_block_dims ="
    },
    {
        "line": 90,
        "fullcodeline": "external_output_shape.AddDim(orig_input_tensor.dim_size(0) *"
    },
    {
        "line": 93,
        "fullcodeline": "int64_t input_batch_size = orig_input_tensor.dim_size(0);"
    },
    {
        "line": 99,
        "fullcodeline": "internal_input_shape.AddDim(input_batch_size);"
    },
    {
        "line": 100,
        "fullcodeline": "internal_output_shape.AddDim(input_batch_size * block_shape_product);"
    },
    {
        "line": 124,
        "fullcodeline": "int64_t depth = 1;"
    },
    {
        "line": 131,
        "fullcodeline": "internal_input_shape.AddDim(depth);"
    },
    {
        "line": 132,
        "fullcodeline": "internal_output_shape.AddDim(depth);"
    },
    {
        "line": 135,
        "fullcodeline": "Tensor* output_tensor = nullptr;"
    },
    {
        "line": 136,
        "fullcodeline": "TF_RETURN_IF_ERROR("
    },
    {
        "line": 139,
        "fullcodeline": "const int64_t* internal_paddings = &paddings[2 * removed_prefix_block_dims];"
    },
    {
        "line": 140,
        "fullcodeline": "const int64_t* internal_block_shape = &block_shape[removed_prefix_block_dims];"
    },
    {
        "line": 6,
        "fullcodeline": "if (!TensorShapeUtils::IsVector(orig_block_shape.shape())) {"
    },
    {
        "line": 12,
        "fullcodeline": "if (orig_input_tensor.dims() < 1 + block_dims) {"
    },
    {
        "line": 17,
        "fullcodeline": "if (!(TensorShapeUtils::IsMatrix(orig_paddings.shape()) &&"
    },
    {
        "line": 35,
        "fullcodeline": "for (; removed_prefix_block_dims < block_dims; ++removed_prefix_block_dims) {"
    },
    {
        "line": 46,
        "fullcodeline": "for (; removed_suffix_block_dims < block_dims - removed_prefix_block_dims;"
    },
    {
        "line": 47,
        "fullcodeline": "++removed_suffix_block_dims) {"
    },
    {
        "line": 57,
        "fullcodeline": "for (int block_dim = 0; block_dim < block_dims; ++block_dim) {"
    },
    {
        "line": 60,
        "fullcodeline": "if (block_shape_product <= 0) {"
    },
    {
        "line": 66,
        "fullcodeline": "block_dims - removed_prefix_block_dims - removed_suffix_block_dims;"
    },
    {
        "line": 67,
        "fullcodeline": "if (internal_block_dims > kMaxSpaceToBatchBlockDims) {"
    },
    {
        "line": 74,
        "fullcodeline": "if (internal_block_dims == 0) {"
    },
    {
        "line": 94,
        "fullcodeline": "for (int block_dim = 0; block_dim < removed_prefix_block_dims; ++block_dim) {"
    },
    {
        "line": 103,
        "fullcodeline": "block_dim < block_dims - removed_suffix_block_dims; ++block_dim) {"
    },
    {
        "line": 125,
        "fullcodeline": "for (int dim = block_dims - removed_suffix_block_dims + 1; dim < input_dims;"
    },
    {
        "line": 126,
        "fullcodeline": "++dim) {"
    },
    {
        "line": 137,
        "fullcodeline": "context->allocate_output(0, external_output_shape, &output_tensor));"
    },
    {
        "line": 158,
        "fullcodeline": "return Status::OK();"
    },
    {
        "line": 36,
        "fullcodeline": "const int dim = removed_prefix_block_dims;"
    },
    {
        "line": 48,
        "fullcodeline": "const int dim = block_dims - 1 - removed_suffix_block_dims;"
    },
    {
        "line": 58,
        "fullcodeline": "block_shape_product *= block_shape[block_dim];"
    },
    {
        "line": 75,
        "fullcodeline": "context->set_output(0, orig_input_tensor);"
    },
    {
        "line": 95,
        "fullcodeline": "const int64_t size = orig_input_tensor.dim_size(block_dim + 1);"
    },
    {
        "line": 96,
        "fullcodeline": "input_batch_size *= size;"
    },
    {
        "line": 97,
        "fullcodeline": "external_output_shape.AddDim(size);"
    },
    {
        "line": 102,
        "fullcodeline": "for (int block_dim = removed_prefix_block_dims;"
    },
    {
        "line": 104,
        "fullcodeline": "const int64_t pad_start = paddings[2 * block_dim],"
    },
    {
        "line": 105,
        "fullcodeline": "pad_end = paddings[2 * block_dim + 1];"
    },
    {
        "line": 109,
        "fullcodeline": "const int64_t input_size = orig_input_tensor.dim_size(block_dim + 1);"
    },
    {
        "line": 110,
        "fullcodeline": "const int64_t block_shape_value = block_shape[block_dim];"
    },
    {
        "line": 111,
        "fullcodeline": "const int64_t padded_size = input_size + pad_start + pad_end;"
    },
    {
        "line": 118,
        "fullcodeline": "internal_input_shape.AddDim(input_size);"
    },
    {
        "line": 119,
        "fullcodeline": "const int64_t output_size = padded_size / block_shape_value;"
    },
    {
        "line": 120,
        "fullcodeline": "internal_output_shape.AddDim(output_size);"
    },
    {
        "line": 121,
        "fullcodeline": "external_output_shape.AddDim(output_size);"
    },
    {
        "line": 127,
        "fullcodeline": "const int64_t size = orig_input_tensor.dim_size(dim);"
    },
    {
        "line": 128,
        "fullcodeline": "external_output_shape.AddDim(size);"
    },
    {
        "line": 129,
        "fullcodeline": "depth *= size;"
    },
    {
        "line": 7,
        "fullcodeline": "return errors::InvalidArgument(\"block_shape rank should be 1 instead of \","
    },
    {
        "line": 13,
        "fullcodeline": "return errors::InvalidArgument(\"input rank should be >= \", 1 + block_dims,"
    },
    {
        "line": 19,
        "fullcodeline": "2 == orig_paddings.dim_size(1))) {"
    },
    {
        "line": 20,
        "fullcodeline": "return errors::InvalidArgument(\"paddings should have shape [\", block_dims,"
    },
    {
        "line": 37,
        "fullcodeline": "if (paddings[2 * dim] != 0 || paddings[2 * dim + 1] != 0 ||"
    },
    {
        "line": 49,
        "fullcodeline": "if (paddings[dim * 2] != 0 || paddings[dim * 2 + 1] != 0 ||"
    },
    {
        "line": 61,
        "fullcodeline": "return errors::InvalidArgument("
    },
    {
        "line": 68,
        "fullcodeline": "return errors::InvalidArgument("
    },
    {
        "line": 76,
        "fullcodeline": "return Status::OK();"
    },
    {
        "line": 106,
        "fullcodeline": "if (pad_start < 0 || pad_end < 0) {"
    },
    {
        "line": 112,
        "fullcodeline": "if (padded_size % block_shape_value != 0) {"
    },
    {
        "line": 8,
        "fullcodeline": "orig_block_shape.dims());"
    },
    {
        "line": 14,
        "fullcodeline": "\" instead of \", orig_input_tensor.dims());"
    },
    {
        "line": 18,
        "fullcodeline": "block_dims == orig_paddings.dim_size(0) &&"
    },
    {
        "line": 22,
        "fullcodeline": "orig_paddings.shape().DebugString());"
    },
    {
        "line": 38,
        "fullcodeline": "block_shape[dim] != 1) {"
    },
    {
        "line": 50,
        "fullcodeline": "block_shape[dim] != 1) {"
    },
    {
        "line": 107,
        "fullcodeline": "return errors::InvalidArgument(\"Paddings must be non-negative\");"
    },
    {
        "line": 113,
        "fullcodeline": "return errors::InvalidArgument(\"padded_shape[\", block_dim,"
    }
]