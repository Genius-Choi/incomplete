[
    {
        "line": 9,
        "fullcodeline": "const bool time_major = params->time_major;"
    },
    {
        "line": 10,
        "fullcodeline": "const int batch_size ="
    },
    {
        "line": 12,
        "fullcodeline": "const int max_time ="
    },
    {
        "line": 14,
        "fullcodeline": "const int num_units = input_weights->dims->data[0];"
    },
    {
        "line": 15,
        "fullcodeline": "const int input_size = input->dims->data[2];"
    },
    {
        "line": 18,
        "fullcodeline": "const float* bias_ptr = GetTensorData<float>(bias);"
    },
    {
        "line": 22,
        "fullcodeline": "const int8_t* input_weights_ptr = GetTensorData<int8_t>(input_weights);"
    },
    {
        "line": 23,
        "fullcodeline": "const int8_t* recurrent_weights_ptr ="
    },
    {
        "line": 25,
        "fullcodeline": "int8_t* quantized_input_ptr = GetTensorData<int8_t>(input_scratch);"
    },
    {
        "line": 26,
        "fullcodeline": "int8_t* quantized_hidden_state_ptr ="
    },
    {
        "line": 30,
        "fullcodeline": "float input_weights_scale = input_weights->params.scale;"
    },
    {
        "line": 31,
        "fullcodeline": "float recurrent_weights_scale = recurrent_weights->params.scale;"
    },
    {
        "line": 32,
        "fullcodeline": "float* scaling_factors_ptr = GetTensorData<float>(scaling_factors);"
    },
    {
        "line": 33,
        "fullcodeline": "int32_t* accum_scratch_ptr = GetTensorData<int32_t>(accum_scratch);"
    },
    {
        "line": 34,
        "fullcodeline": "int32_t* zero_points_ptr = nullptr;"
    },
    {
        "line": 35,
        "fullcodeline": "int32_t* row_sums_ptr = nullptr;"
    },
    {
        "line": 13,
        "fullcodeline": "(time_major) ? input->dims->data[0] : input->dims->data[1];"
    },
    {
        "line": 24,
        "fullcodeline": "GetTensorData<int8_t>(recurrent_weights);"
    },
    {
        "line": 27,
        "fullcodeline": "GetTensorData<int8_t>(hidden_state_scratch);"
    },
    {
        "line": 38,
        "fullcodeline": "zero_points_ptr = GetTensorData<int32_t>(zero_points);"
    },
    {
        "line": 39,
        "fullcodeline": "row_sums_ptr = GetTensorData<int32_t>(row_sums);"
    },
    {
        "line": 44,
        "fullcodeline": "float* hidden_state_ptr_batch = GetTensorData<float>(hidden_state);"
    },
    {
        "line": 46,
        "fullcodeline": "for (int s = 0; s < max_time; s++) {"
    },
    {
        "line": 48,
        "fullcodeline": "const float* input_ptr_batch ="
    },
    {
        "line": 50,
        "fullcodeline": "float* output_ptr_batch ="
    },
    {
        "line": 53,
        "fullcodeline": "kernel_utils::RnnBatchStep("
    },
    {
        "line": 64,
        "fullcodeline": "for (int b = 0; b < batch_size; b++) {"
    },
    {
        "line": 49,
        "fullcodeline": "GetTensorData<float>(input) + s * input_size * batch_size;"
    },
    {
        "line": 51,
        "fullcodeline": "GetTensorData<float>(output) + s * num_units * batch_size;"
    },
    {
        "line": 66,
        "fullcodeline": "float* hidden_state_ptr_batch ="
    },
    {
        "line": 67,
        "fullcodeline": "GetTensorData<float>(hidden_state) + b * num_units;"
    },
    {
        "line": 68,
        "fullcodeline": "for (int s = 0; s < max_time; s++) {"
    },
    {
        "line": 70,
        "fullcodeline": "const float* input_ptr_batch = GetTensorData<float>(input) +"
    },
    {
        "line": 73,
        "fullcodeline": "float* output_ptr_batch = GetTensorData<float>(output) +"
    },
    {
        "line": 75,
        "fullcodeline": "kernel_utils::RnnBatchStep("
    },
    {
        "line": 72,
        "fullcodeline": "s * input_size;"
    },
    {
        "line": 74,
        "fullcodeline": "b * num_units * max_time + s * num_units;"
    },
    {
        "line": 71,
        "fullcodeline": "b * input_size * max_time +"
    }
]