[
    {
        "line": 7,
        "fullcodeline": "CalculateActivationRange(params->activation, &output_activation_min,"
    },
    {
        "line": 10,
        "fullcodeline": "const int input_size = NumElements(input) / SizeOfDimension(input, 0);"
    },
    {
        "line": 11,
        "fullcodeline": "const int batch_size = SizeOfDimension(input, 0);"
    },
    {
        "line": 13,
        "fullcodeline": "const float* input_ptr = GetTensorData<float>(input);"
    },
    {
        "line": 14,
        "fullcodeline": "int8_t* quantized_input_ptr_batch = GetTensorData<int8_t>("
    },
    {
        "line": 16,
        "fullcodeline": "float* scaling_factors_ptr = GetTensorData<float>("
    },
    {
        "line": 21,
        "fullcodeline": "ruy::profiler::ScopeLabel label(\"ConvHybridQuantizeInputs\");"
    },
    {
        "line": 15,
        "fullcodeline": "GetTemporary(context, node, data->input_quantized_index));"
    },
    {
        "line": 17,
        "fullcodeline": "GetTemporary(context, node, data->scaling_factors_index));"
    },
    {
        "line": 22,
        "fullcodeline": "for (int b = 0; b < batch_size; ++b) {"
    },
    {
        "line": 24,
        "fullcodeline": "const int offset = b * input_size;"
    },
    {
        "line": 25,
        "fullcodeline": "tensor_utils::SymmetricQuantizeFloats("
    },
    {
        "line": 28,
        "fullcodeline": "scaling_factors_ptr[b] *= filter->params.scale;"
    },
    {
        "line": 39,
        "fullcodeline": "op_params.padding_type = PaddingType::kSame;"
    },
    {
        "line": 42,
        "fullcodeline": "op_params.stride_width = params->stride_width;"
    },
    {
        "line": 43,
        "fullcodeline": "op_params.stride_height = params->stride_height;"
    },
    {
        "line": 44,
        "fullcodeline": "op_params.dilation_width_factor = 1;"
    },
    {
        "line": 45,
        "fullcodeline": "op_params.dilation_height_factor = 1;"
    },
    {
        "line": 46,
        "fullcodeline": "op_params.float_activation_min = output_activation_min;"
    },
    {
        "line": 47,
        "fullcodeline": "op_params.float_activation_max = output_activation_max;"
    },
    {
        "line": 26,
        "fullcodeline": "input_ptr + offset, input_size, quantized_input_ptr_batch + offset,"
    },
    {
        "line": 49,
        "fullcodeline": "op_params, scaling_factors_ptr, GetTensorShape(input),"
    },
    {
        "line": 50,
        "fullcodeline": "quantized_input_ptr_batch, GetTensorShape(filter),"
    },
    {
        "line": 51,
        "fullcodeline": "GetTensorData<int8_t>(filter), GetTensorShape(bias),"
    },
    {
        "line": 52,
        "fullcodeline": "GetTensorData<float>(bias), GetTensorShape(accum_scratch),"
    },
    {
        "line": 53,
        "fullcodeline": "GetTensorData<int32_t>(accum_scratch), GetTensorShape(output),"
    },
    {
        "line": 54,
        "fullcodeline": "GetTensorData<float>(output), GetTensorShape(im2col),"
    },
    {
        "line": 55,
        "fullcodeline": "GetTensorData<int8_t>(im2col),"
    },
    {
        "line": 56,
        "fullcodeline": "CpuBackendContext::GetFromContext(context));"
    }
]