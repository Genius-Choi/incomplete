[
    {
        "line": 5,
        "fullcodeline": "const auto* params = static_cast<TfLiteLSTMParams*>(node->builtin_data);"
    },
    {
        "line": 6,
        "fullcodeline": "const float cell_clip = params->cell_clip;"
    },
    {
        "line": 7,
        "fullcodeline": "const float proj_clip = params->proj_clip;"
    },
    {
        "line": 9,
        "fullcodeline": "const TfLiteTensor* cell_state ="
    },
    {
        "line": 11,
        "fullcodeline": "TF_LITE_ENSURE(context, cell_state != nullptr);"
    },
    {
        "line": 12,
        "fullcodeline": "const TfLiteTensor* output_tensor = GetOutput(context, node, kOutputTensor);"
    },
    {
        "line": 14,
        "fullcodeline": "auto* cell_state_params ="
    },
    {
        "line": 16,
        "fullcodeline": "auto* proj_params = static_cast<TfLiteAffineQuantization*>("
    },
    {
        "line": 33,
        "fullcodeline": "OpData* op_data = static_cast<OpData*>(node->user_data);"
    },
    {
        "line": 34,
        "fullcodeline": "const bool use_layer_norm = op_data->use_layer_norm;"
    },
    {
        "line": 36,
        "fullcodeline": "const TfLiteTensor* input = GetInput(context, node, kInputTensor);"
    },
    {
        "line": 38,
        "fullcodeline": "const TfLiteTensor* input_to_input_weights ="
    },
    {
        "line": 40,
        "fullcodeline": "const TfLiteTensor* input_to_forget_weights ="
    },
    {
        "line": 42,
        "fullcodeline": "const TfLiteTensor* input_to_cell_weights ="
    },
    {
        "line": 44,
        "fullcodeline": "const TfLiteTensor* input_to_output_weights ="
    },
    {
        "line": 47,
        "fullcodeline": "const TfLiteTensor* recurrent_to_input_weights ="
    },
    {
        "line": 49,
        "fullcodeline": "const TfLiteTensor* recurrent_to_forget_weights ="
    },
    {
        "line": 51,
        "fullcodeline": "const TfLiteTensor* recurrent_to_cell_weights ="
    },
    {
        "line": 53,
        "fullcodeline": "const TfLiteTensor* recurrent_to_output_weights ="
    },
    {
        "line": 56,
        "fullcodeline": "const TfLiteTensor* cell_to_input_weights ="
    },
    {
        "line": 58,
        "fullcodeline": "const TfLiteTensor* cell_to_forget_weights ="
    },
    {
        "line": 60,
        "fullcodeline": "const TfLiteTensor* cell_to_output_weights ="
    },
    {
        "line": 63,
        "fullcodeline": "const TfLiteTensor* input_layer_norm_coefficients ="
    },
    {
        "line": 65,
        "fullcodeline": "const TfLiteTensor* forget_layer_norm_coefficients ="
    },
    {
        "line": 67,
        "fullcodeline": "const TfLiteTensor* cell_layer_norm_coefficients ="
    },
    {
        "line": 69,
        "fullcodeline": "const TfLiteTensor* output_layer_norm_coefficients ="
    },
    {
        "line": 72,
        "fullcodeline": "const TfLiteTensor* projection_weights ="
    },
    {
        "line": 75,
        "fullcodeline": "TfLiteTensor* output_state ="
    },
    {
        "line": 77,
        "fullcodeline": "TF_LITE_ENSURE(context, output_state != nullptr);"
    },
    {
        "line": 81,
        "fullcodeline": "const bool use_cifg = (input_to_input_weights == nullptr);"
    },
    {
        "line": 82,
        "fullcodeline": "const bool use_peephole = (cell_to_output_weights != nullptr);"
    },
    {
        "line": 83,
        "fullcodeline": "const bool use_projection = (projection_weights != nullptr);"
    },
    {
        "line": 87,
        "fullcodeline": "std::vector<int32> intermediate_zp;"
    },
    {
        "line": 103,
        "fullcodeline": "const TfLiteTensor* hidden = GetIntermediates(context, node, 4);"
    },
    {
        "line": 104,
        "fullcodeline": "auto* hidden_params ="
    },
    {
        "line": 106,
        "fullcodeline": "intermediate_scale.push_back(hidden_params->scale->data[0]);"
    },
    {
        "line": 107,
        "fullcodeline": "intermediate_zp.push_back(hidden_params->zero_point->data[0]);"
    },
    {
        "line": 110,
        "fullcodeline": "const float default_scale = 1.0;"
    },
    {
        "line": 111,
        "fullcodeline": "float input_scale = default_scale;"
    },
    {
        "line": 112,
        "fullcodeline": "float input_to_input_weight_scale = default_scale;"
    },
    {
        "line": 113,
        "fullcodeline": "float recurrent_to_input_weight_scale = default_scale;"
    },
    {
        "line": 114,
        "fullcodeline": "float cell_to_input_weight_scale = default_scale;"
    },
    {
        "line": 115,
        "fullcodeline": "float input_to_forget_weight_scale = default_scale;"
    },
    {
        "line": 116,
        "fullcodeline": "float recurrent_to_forget_weight_scale = default_scale;"
    },
    {
        "line": 117,
        "fullcodeline": "float cell_to_forget_weight_scale = default_scale;"
    },
    {
        "line": 118,
        "fullcodeline": "float input_to_cell_weight_scale = default_scale;"
    },
    {
        "line": 119,
        "fullcodeline": "float recurrent_to_cell_weight_scale = default_scale;"
    },
    {
        "line": 120,
        "fullcodeline": "float input_to_output_weight_scale = default_scale;"
    },
    {
        "line": 121,
        "fullcodeline": "float recurrent_to_output_weight_scale = default_scale;"
    },
    {
        "line": 122,
        "fullcodeline": "float cell_to_output_weight_scale = default_scale;"
    },
    {
        "line": 123,
        "fullcodeline": "float projection_weight_scale = default_scale;"
    },
    {
        "line": 124,
        "fullcodeline": "float layer_norm_input_scale = default_scale;"
    },
    {
        "line": 125,
        "fullcodeline": "float layer_norm_forget_scale = default_scale;"
    },
    {
        "line": 126,
        "fullcodeline": "float layer_norm_cell_scale = default_scale;"
    },
    {
        "line": 127,
        "fullcodeline": "float layer_norm_output_scale = default_scale;"
    },
    {
        "line": 128,
        "fullcodeline": "float output_state_scale = default_scale;"
    },
    {
        "line": 129,
        "fullcodeline": "int cell_scale = 1;"
    },
    {
        "line": 132,
        "fullcodeline": "float effective_input_to_input_scale = default_scale;"
    },
    {
        "line": 133,
        "fullcodeline": "float effective_recurrent_to_input_scale = default_scale;"
    },
    {
        "line": 134,
        "fullcodeline": "float effective_cell_to_input_scale = default_scale;"
    },
    {
        "line": 135,
        "fullcodeline": "float effective_input_to_forget_scale = default_scale;"
    },
    {
        "line": 136,
        "fullcodeline": "float effective_recurrent_to_forget_scale = default_scale;"
    },
    {
        "line": 137,
        "fullcodeline": "float effective_cell_to_forget_scale = default_scale;"
    },
    {
        "line": 138,
        "fullcodeline": "float effective_input_to_cell_scale = default_scale;"
    },
    {
        "line": 139,
        "fullcodeline": "float effective_recurrent_to_cell_scale = default_scale;"
    },
    {
        "line": 140,
        "fullcodeline": "float effective_input_to_output_scale = default_scale;"
    },
    {
        "line": 141,
        "fullcodeline": "float effective_recurrent_to_output_scale = default_scale;"
    },
    {
        "line": 142,
        "fullcodeline": "float effective_cell_to_output_scale = default_scale;"
    },
    {
        "line": 143,
        "fullcodeline": "float effective_proj_scale = default_scale;"
    },
    {
        "line": 144,
        "fullcodeline": "float effective_hidden_scale = default_scale;"
    },
    {
        "line": 172,
        "fullcodeline": "output_state_scale = output_state->params.scale;"
    },
    {
        "line": 174,
        "fullcodeline": "input_to_forget_weight_scale = input_to_forget_weights->params.scale;"
    },
    {
        "line": 175,
        "fullcodeline": "input_to_cell_weight_scale = input_to_cell_weights->params.scale;"
    },
    {
        "line": 176,
        "fullcodeline": "input_to_output_weight_scale = input_to_output_weights->params.scale;"
    },
    {
        "line": 177,
        "fullcodeline": "recurrent_to_forget_weight_scale = recurrent_to_forget_weights->params.scale;"
    },
    {
        "line": 178,
        "fullcodeline": "recurrent_to_cell_weight_scale = recurrent_to_cell_weights->params.scale;"
    },
    {
        "line": 179,
        "fullcodeline": "recurrent_to_output_weight_scale = recurrent_to_output_weights->params.scale;"
    },
    {
        "line": 182,
        "fullcodeline": "TF_LITE_ENSURE(context, CheckedLog2(cell_state->params.scale, &cell_scale));"
    },
    {
        "line": 183,
        "fullcodeline": "TF_LITE_ENSURE(context, cell_scale <= -9);"
    },
    {
        "line": 184,
        "fullcodeline": "integer_lstm_param->cell_scale = cell_scale;"
    },
    {
        "line": 185,
        "fullcodeline": "input_scale = input->params.scale;"
    },
    {
        "line": 195,
        "fullcodeline": "effective_input_to_forget_scale ="
    },
    {
        "line": 197,
        "fullcodeline": "effective_recurrent_to_forget_scale = recurrent_to_forget_weight_scale *"
    },
    {
        "line": 201,
        "fullcodeline": "effective_input_to_cell_scale ="
    },
    {
        "line": 203,
        "fullcodeline": "effective_recurrent_to_cell_scale = recurrent_to_cell_weight_scale *"
    },
    {
        "line": 207,
        "fullcodeline": "effective_input_to_output_scale ="
    },
    {
        "line": 209,
        "fullcodeline": "effective_recurrent_to_output_scale = recurrent_to_output_weight_scale *"
    },
    {
        "line": 213,
        "fullcodeline": "effective_hidden_scale ="
    },
    {
        "line": 216,
        "fullcodeline": "effective_proj_scale ="
    },
    {
        "line": 234,
        "fullcodeline": "QuantizeMultiplier(effective_input_to_input_scale,"
    },
    {
        "line": 237,
        "fullcodeline": "QuantizeMultiplier(effective_recurrent_to_input_scale,"
    },
    {
        "line": 240,
        "fullcodeline": "QuantizeMultiplier(effective_cell_to_input_scale,"
    },
    {
        "line": 243,
        "fullcodeline": "QuantizeMultiplier(effective_input_to_forget_scale,"
    },
    {
        "line": 246,
        "fullcodeline": "QuantizeMultiplier("
    },
    {
        "line": 250,
        "fullcodeline": "QuantizeMultiplier(effective_cell_to_forget_scale,"
    },
    {
        "line": 253,
        "fullcodeline": "QuantizeMultiplier(effective_input_to_cell_scale,"
    },
    {
        "line": 256,
        "fullcodeline": "QuantizeMultiplier(effective_recurrent_to_cell_scale,"
    },
    {
        "line": 259,
        "fullcodeline": "QuantizeMultiplier(effective_input_to_output_scale,"
    },
    {
        "line": 262,
        "fullcodeline": "QuantizeMultiplier("
    },
    {
        "line": 266,
        "fullcodeline": "QuantizeMultiplier(effective_cell_to_output_scale,"
    },
    {
        "line": 269,
        "fullcodeline": "QuantizeMultiplier(effective_proj_scale,"
    },
    {
        "line": 272,
        "fullcodeline": "QuantizeMultiplier(effective_hidden_scale,"
    },
    {
        "line": 275,
        "fullcodeline": "QuantizeMultiplier(layer_norm_input_scale,"
    },
    {
        "line": 278,
        "fullcodeline": "QuantizeMultiplier(layer_norm_forget_scale,"
    },
    {
        "line": 281,
        "fullcodeline": "QuantizeMultiplier(layer_norm_cell_scale,"
    },
    {
        "line": 284,
        "fullcodeline": "QuantizeMultiplier(layer_norm_output_scale,"
    },
    {
        "line": 288,
        "fullcodeline": "integer_lstm_param->hidden_zp = intermediate_zp[4];"
    },
    {
        "line": 295,
        "fullcodeline": "integer_lstm_param->forget_variance_guard ="
    },
    {
        "line": 297,
        "fullcodeline": "integer_lstm_param->cell_variance_guard ="
    },
    {
        "line": 299,
        "fullcodeline": "integer_lstm_param->output_variance_guard ="
    },
    {
        "line": 10,
        "fullcodeline": "GetVariableInput(context, node, kCellStateTensor);"
    },
    {
        "line": 15,
        "fullcodeline": "static_cast<TfLiteAffineQuantization*>(cell_state->quantization.params);"
    },
    {
        "line": 18,
        "fullcodeline": "if (cell_clip > 0.0) {"
    },
    {
        "line": 25,
        "fullcodeline": "if (proj_clip > 0.0) {"
    },
    {
        "line": 39,
        "fullcodeline": "GetOptionalInputTensor(context, node, kInputToInputWeightsTensor);"
    },
    {
        "line": 41,
        "fullcodeline": "GetInput(context, node, kInputToForgetWeightsTensor);"
    },
    {
        "line": 43,
        "fullcodeline": "GetInput(context, node, kInputToCellWeightsTensor);"
    },
    {
        "line": 45,
        "fullcodeline": "GetInput(context, node, kInputToOutputWeightsTensor);"
    },
    {
        "line": 48,
        "fullcodeline": "GetOptionalInputTensor(context, node, kRecurrentToInputWeightsTensor);"
    },
    {
        "line": 50,
        "fullcodeline": "GetInput(context, node, kRecurrentToForgetWeightsTensor);"
    },
    {
        "line": 52,
        "fullcodeline": "GetInput(context, node, kRecurrentToCellWeightsTensor);"
    },
    {
        "line": 54,
        "fullcodeline": "GetInput(context, node, kRecurrentToOutputWeightsTensor);"
    },
    {
        "line": 57,
        "fullcodeline": "GetOptionalInputTensor(context, node, kCellToInputWeightsTensor);"
    },
    {
        "line": 59,
        "fullcodeline": "GetOptionalInputTensor(context, node, kCellToForgetWeightsTensor);"
    },
    {
        "line": 61,
        "fullcodeline": "GetOptionalInputTensor(context, node, kCellToOutputWeightsTensor);"
    },
    {
        "line": 64,
        "fullcodeline": "GetOptionalInputTensor(context, node, kInputLayerNormCoefficientsTensor);"
    },
    {
        "line": 66,
        "fullcodeline": "GetOptionalInputTensor(context, node, kForgetLayerNormCoefficientsTensor);"
    },
    {
        "line": 68,
        "fullcodeline": "GetOptionalInputTensor(context, node, kCellLayerNormCoefficientsTensor);"
    },
    {
        "line": 70,
        "fullcodeline": "GetOptionalInputTensor(context, node, kOutputLayerNormCoefficientsTensor);"
    },
    {
        "line": 73,
        "fullcodeline": "GetOptionalInputTensor(context, node, kProjectionWeightsTensor);"
    },
    {
        "line": 76,
        "fullcodeline": "GetVariableInput(context, node, kOutputStateTensor);"
    },
    {
        "line": 88,
        "fullcodeline": "for (int i = 0; i < 4; ++i) {"
    },
    {
        "line": 105,
        "fullcodeline": "static_cast<TfLiteAffineQuantization*>(hidden->quantization.params);"
    },
    {
        "line": 147,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 188,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 196,
        "fullcodeline": "input_to_forget_weight_scale * input_scale / intermediate_scale[1];"
    },
    {
        "line": 202,
        "fullcodeline": "input_to_cell_weight_scale * input_scale / intermediate_scale[2];"
    },
    {
        "line": 208,
        "fullcodeline": "input_to_output_weight_scale * input_scale / intermediate_scale[3];"
    },
    {
        "line": 214,
        "fullcodeline": "std::pow(2, -15) / intermediate_scale[4] * std::pow(2, -15);"
    },
    {
        "line": 217,
        "fullcodeline": "projection_weight_scale * intermediate_scale[4] / output_state_scale;"
    },
    {
        "line": 291,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 296,
        "fullcodeline": "std::max(1, static_cast<int32_t>(10000 * layer_norm_forget_scale));"
    },
    {
        "line": 298,
        "fullcodeline": "std::max(1, static_cast<int32_t>(10000 * layer_norm_cell_scale));"
    },
    {
        "line": 300,
        "fullcodeline": "std::max(1, static_cast<int32_t>(10000 * layer_norm_output_scale));"
    },
    {
        "line": 19,
        "fullcodeline": "integer_lstm_param->quantized_cell_clip = static_cast<int16_t>(std::min("
    },
    {
        "line": 26,
        "fullcodeline": "integer_lstm_param->quantized_proj_clip = static_cast<int8_t>(std::min("
    },
    {
        "line": 148,
        "fullcodeline": "input_to_input_weight_scale = input_to_input_weights->params.scale;"
    },
    {
        "line": 149,
        "fullcodeline": "recurrent_to_input_weight_scale = recurrent_to_input_weights->params.scale;"
    },
    {
        "line": 156,
        "fullcodeline": "cell_to_forget_weight_scale = cell_to_forget_weights->params.scale;"
    },
    {
        "line": 157,
        "fullcodeline": "cell_to_output_weight_scale = cell_to_output_weights->params.scale;"
    },
    {
        "line": 164,
        "fullcodeline": "layer_norm_forget_scale = forget_layer_norm_coefficients->params.scale;"
    },
    {
        "line": 165,
        "fullcodeline": "layer_norm_cell_scale = cell_layer_norm_coefficients->params.scale;"
    },
    {
        "line": 166,
        "fullcodeline": "layer_norm_output_scale = output_layer_norm_coefficients->params.scale;"
    },
    {
        "line": 170,
        "fullcodeline": "projection_weight_scale = projection_weights->params.scale;"
    },
    {
        "line": 189,
        "fullcodeline": "effective_input_to_input_scale ="
    },
    {
        "line": 191,
        "fullcodeline": "effective_recurrent_to_input_scale = recurrent_to_input_weight_scale *"
    },
    {
        "line": 225,
        "fullcodeline": "effective_cell_to_forget_scale = std::pow(2, cell_scale) *  // NOLINT"
    },
    {
        "line": 228,
        "fullcodeline": "effective_cell_to_output_scale = std::pow(2, cell_scale) *  // NOLINT"
    },
    {
        "line": 292,
        "fullcodeline": "integer_lstm_param->input_variance_guard ="
    },
    {
        "line": 23,
        "fullcodeline": "integer_lstm_param->quantized_cell_clip = 0;"
    },
    {
        "line": 29,
        "fullcodeline": "integer_lstm_param->quantized_proj_clip = 0;"
    },
    {
        "line": 153,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 161,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 190,
        "fullcodeline": "input_to_input_weight_scale * input_scale / intermediate_scale[0];"
    },
    {
        "line": 220,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 293,
        "fullcodeline": "std::max(1, static_cast<int32_t>(10000 * layer_norm_input_scale));"
    },
    {
        "line": 90,
        "fullcodeline": "const TfLiteTensor* intermediate = GetIntermediates(context, node, i);"
    },
    {
        "line": 91,
        "fullcodeline": "auto* params = static_cast<TfLiteAffineQuantization*>("
    },
    {
        "line": 93,
        "fullcodeline": "intermediate_scale.push_back(params->scale->data[0]);"
    },
    {
        "line": 94,
        "fullcodeline": "intermediate_zp.push_back(params->zero_point->data[0]);"
    },
    {
        "line": 154,
        "fullcodeline": "cell_to_input_weight_scale = cell_to_input_weights->params.scale;"
    },
    {
        "line": 162,
        "fullcodeline": "layer_norm_input_scale = input_layer_norm_coefficients->params.scale;"
    },
    {
        "line": 221,
        "fullcodeline": "effective_cell_to_input_scale = std::pow(2, cell_scale) *  // NOLINT"
    },
    {
        "line": 20,
        "fullcodeline": "std::max(cell_clip / cell_state_params->scale->data[0], -32768.0f),"
    },
    {
        "line": 27,
        "fullcodeline": "std::max(proj_clip / proj_params->scale->data[0], -128.0f), 127.0f));"
    },
    {
        "line": 97,
        "fullcodeline": "intermediate_scale.push_back(std::pow(2, -12));"
    },
    {
        "line": 98,
        "fullcodeline": "intermediate_zp.push_back(0);"
    }
]