[
    {
        "line": 2,
        "fullcodeline": "auto* params = reinterpret_cast<TfLiteSoftmaxParams*>(node->builtin_data);"
    },
    {
        "line": 3,
        "fullcodeline": "SoftmaxOpData* data = reinterpret_cast<SoftmaxOpData*>(node->user_data);"
    },
    {
        "line": 5,
        "fullcodeline": "const TfLiteTensor* input = GetInput(context, node, 0);"
    },
    {
        "line": 6,
        "fullcodeline": "TfLiteTensor* output = GetOutput(context, node, 0);"
    },
    {
        "line": 51,
        "fullcodeline": "TfLiteTypeGetName(input->type));"
    },
    {
        "line": 10,
        "fullcodeline": "return SoftmaxFloat(context, input, output, params);"
    },
    {
        "line": 44,
        "fullcodeline": "return SoftmaxQuantized<int16_t, int16_t>(context, input, output, data);"
    },
    {
        "line": 15,
        "fullcodeline": "return SoftmaxQuantized<uint8_t, uint8_t>(context, input, output,"
    },
    {
        "line": 18,
        "fullcodeline": "return SoftmaxQuantized<uint8_t, int16_t>(context, input, output,"
    },
    {
        "line": 24,
        "fullcodeline": "TfLiteTypeGetName(output->type));"
    },
    {
        "line": 31,
        "fullcodeline": "return SoftmaxQuantized<int8_t, int8_t>(context, input, output, data);"
    },
    {
        "line": 33,
        "fullcodeline": "return SoftmaxQuantized<int8_t, int16_t>(context, input, output,"
    },
    {
        "line": 39,
        "fullcodeline": "TfLiteTypeGetName(output->type));"
    }
]