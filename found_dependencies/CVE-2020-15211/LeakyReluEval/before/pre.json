[
    {
        "line": 2,
        "fullcodeline": "const TfLiteTensor* input = GetInput(context, node, 0);"
    },
    {
        "line": 3,
        "fullcodeline": "TfLiteTensor* output = GetOutput(context, node, 0);"
    },
    {
        "line": 4,
        "fullcodeline": "const auto* params ="
    },
    {
        "line": 6,
        "fullcodeline": "const LeakyReluOpData* data ="
    },
    {
        "line": 5,
        "fullcodeline": "reinterpret_cast<TfLiteLeakyReluParams*>(node->builtin_data);"
    },
    {
        "line": 7,
        "fullcodeline": "reinterpret_cast<LeakyReluOpData*>(node->user_data);"
    },
    {
        "line": 12,
        "fullcodeline": "op_params.alpha = params->alpha;"
    },
    {
        "line": 13,
        "fullcodeline": "optimized_ops::LeakyRelu("
    },
    {
        "line": 34,
        "fullcodeline": "TfLiteTypeGetName(input->type));"
    },
    {
        "line": 14,
        "fullcodeline": "op_params, GetTensorShape(input), GetTensorData<float>(input),"
    },
    {
        "line": 15,
        "fullcodeline": "GetTensorShape(output), GetTensorData<float>(output));"
    },
    {
        "line": 19,
        "fullcodeline": "QuantizeLeakyRelu<uint8_t>(input, output, data);"
    },
    {
        "line": 23,
        "fullcodeline": "QuantizeLeakyRelu<int8_t>(input, output, data);"
    },
    {
        "line": 27,
        "fullcodeline": "QuantizeLeakyRelu<int16_t>(input, output, data);"
    }
]