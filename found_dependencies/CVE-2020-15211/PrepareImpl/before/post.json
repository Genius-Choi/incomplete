[
    {
        "line": 2,
        "fullcodeline": "auto* params ="
    },
    {
        "line": 4,
        "fullcodeline": "OpData* data = reinterpret_cast<OpData*>(node->user_data);"
    },
    {
        "line": 6,
        "fullcodeline": "TF_LITE_ENSURE(context, node->inputs->size == 2 || node->inputs->size == 3);"
    },
    {
        "line": 8,
        "fullcodeline": "const int expected_outputs_count ="
    },
    {
        "line": 11,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, node->outputs->size, expected_outputs_count);"
    },
    {
        "line": 13,
        "fullcodeline": "const TfLiteTensor* input = GetInput(context, node, kInputTensor);"
    },
    {
        "line": 14,
        "fullcodeline": "const TfLiteTensor* filter = GetInput(context, node, kWeightsTensor);"
    },
    {
        "line": 15,
        "fullcodeline": "const TfLiteTensor* bias ="
    },
    {
        "line": 19,
        "fullcodeline": "TfLiteTensor* output = GetOutput(context, node, kOutputTensor);"
    },
    {
        "line": 22,
        "fullcodeline": "TF_LITE_ENSURE_STATUS("
    },
    {
        "line": 27,
        "fullcodeline": "int input_size = 1;"
    },
    {
        "line": 32,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 2);"
    },
    {
        "line": 33,
        "fullcodeline": "const int batch_size = input_size / filter->dims->data[1];"
    },
    {
        "line": 131,
        "fullcodeline": "TfLiteIntArray* output_size_array = nullptr;"
    },
    {
        "line": 147,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 3,
        "fullcodeline": "reinterpret_cast<TfLiteFullyConnectedParams*>(node->builtin_data);"
    },
    {
        "line": 9,
        "fullcodeline": "params->weights_format == kTfLiteFullyConnectedWeightsFormatDefault ? 1"
    },
    {
        "line": 16,
        "fullcodeline": "(node->inputs->size == 3)"
    },
    {
        "line": 23,
        "fullcodeline": "CheckTypes(context, input, filter, bias, output, params));"
    },
    {
        "line": 28,
        "fullcodeline": "for (int i = 0; i < input->dims->size; i++) {"
    },
    {
        "line": 42,
        "fullcodeline": "if (input->type == kTfLiteUInt8 || input->type == kTfLiteInt8 ||"
    },
    {
        "line": 55,
        "fullcodeline": "if (input->type == kTfLiteInt16 && output->type == kTfLiteInt16) {"
    },
    {
        "line": 65,
        "fullcodeline": "if (input->type == kTfLiteFloat32 &&"
    },
    {
        "line": 148,
        "fullcodeline": "context->ResizeTensor(context, output, output_size_array));"
    },
    {
        "line": 17,
        "fullcodeline": "? GetOptionalInputTensor(context, node, kBiasTensor)"
    },
    {
        "line": 29,
        "fullcodeline": "input_size *= input->dims->data[i];"
    },
    {
        "line": 37,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumElements(bias), SizeOfDimension(filter, 0));"
    },
    {
        "line": 43,
        "fullcodeline": "input->type == kTfLiteInt16) {"
    },
    {
        "line": 44,
        "fullcodeline": "double real_multiplier = 0.0;"
    },
    {
        "line": 45,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(GetQuantizedConvolutionMultipler("
    },
    {
        "line": 48,
        "fullcodeline": "QuantizeMultiplier(real_multiplier, &data->output_multiplier, &exponent);"
    },
    {
        "line": 49,
        "fullcodeline": "data->output_shift = exponent;"
    },
    {
        "line": 50,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(CalculateActivationRangeQuantized("
    },
    {
        "line": 56,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);"
    },
    {
        "line": 57,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);"
    },
    {
        "line": 66,
        "fullcodeline": "(filter->type == kTfLiteUInt8 || filter->type == kTfLiteInt8)) {"
    },
    {
        "line": 67,
        "fullcodeline": "TfLiteIntArrayFree(node->temporaries);"
    },
    {
        "line": 68,
        "fullcodeline": "data->compute_row_sums = true;"
    },
    {
        "line": 69,
        "fullcodeline": "node->temporaries = TfLiteIntArrayCreate(5);"
    },
    {
        "line": 70,
        "fullcodeline": "node->temporaries->data[0] = data->scratch_tensor_index;"
    },
    {
        "line": 72,
        "fullcodeline": "TfLiteTensor* input_quantized = GetTemporary(context, node, /*index=*/0);"
    },
    {
        "line": 73,
        "fullcodeline": "input_quantized->type = filter->type;"
    },
    {
        "line": 74,
        "fullcodeline": "input_quantized->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 76,
        "fullcodeline": "TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);"
    },
    {
        "line": 77,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,"
    },
    {
        "line": 80,
        "fullcodeline": "node->temporaries->data[1] = data->scratch_tensor_index + 1;"
    },
    {
        "line": 81,
        "fullcodeline": "TfLiteTensor* scaling_factors = GetTemporary(context, node, /*index=*/1);"
    },
    {
        "line": 82,
        "fullcodeline": "scaling_factors->type = kTfLiteFloat32;"
    },
    {
        "line": 83,
        "fullcodeline": "scaling_factors->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 85,
        "fullcodeline": "int scaling_dims[1] = {batch_size};"
    },
    {
        "line": 93,
        "fullcodeline": "node->temporaries->data[2] = data->scratch_tensor_index + 2;"
    },
    {
        "line": 94,
        "fullcodeline": "TfLiteTensor* accum_scratch = GetTemporary(context, node, /*index=*/2);"
    },
    {
        "line": 95,
        "fullcodeline": "accum_scratch->type = kTfLiteInt32;"
    },
    {
        "line": 96,
        "fullcodeline": "accum_scratch->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 97,
        "fullcodeline": "int accum_scratch_dims[2] = {num_units, batch_size};"
    },
    {
        "line": 107,
        "fullcodeline": "node->temporaries->data[3] = data->scratch_tensor_index + 3;"
    },
    {
        "line": 108,
        "fullcodeline": "TfLiteTensor* input_offsets = GetTemporary(context, node, /*index=*/3);"
    },
    {
        "line": 109,
        "fullcodeline": "input_offsets->type = kTfLiteInt32;"
    },
    {
        "line": 110,
        "fullcodeline": "input_offsets->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 117,
        "fullcodeline": "node->temporaries->data[4] = data->scratch_tensor_index + 4;"
    },
    {
        "line": 118,
        "fullcodeline": "TfLiteTensor* row_sums = GetTemporary(context, node, /*index=*/4);"
    },
    {
        "line": 119,
        "fullcodeline": "row_sums->type = kTfLiteInt32;"
    },
    {
        "line": 120,
        "fullcodeline": "row_sums->allocation_type = kTfLiteArenaRwPersistent;"
    },
    {
        "line": 121,
        "fullcodeline": "int row_sums_dims[1] = {num_units};"
    },
    {
        "line": 137,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input->dims->data[input->dims->size - 1],"
    },
    {
        "line": 139,
        "fullcodeline": "output_size_array = TfLiteIntArrayCopy(input->dims);"
    },
    {
        "line": 140,
        "fullcodeline": "output_size_array->data[output_size_array->size - 1] = num_units;"
    },
    {
        "line": 86,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {"
    },
    {
        "line": 98,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(accum_scratch->dims, 2,"
    },
    {
        "line": 111,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {"
    },
    {
        "line": 122,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {"
    },
    {
        "line": 138,
        "fullcodeline": "SizeOfDimension(filter, 1));"
    },
    {
        "line": 143,
        "fullcodeline": "output_size_array = TfLiteIntArrayCreate(2);"
    },
    {
        "line": 144,
        "fullcodeline": "output_size_array->data[0] = batch_size;"
    },
    {
        "line": 145,
        "fullcodeline": "output_size_array->data[1] = num_units;"
    },
    {
        "line": 87,
        "fullcodeline": "TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 88,
        "fullcodeline": "scaling_factors_size->data[0] = batch_size;"
    },
    {
        "line": 89,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,"
    },
    {
        "line": 100,
        "fullcodeline": "TfLiteIntArray* accum_size = TfLiteIntArrayCreate(2);"
    },
    {
        "line": 101,
        "fullcodeline": "accum_size->data[0] = num_units;"
    },
    {
        "line": 102,
        "fullcodeline": "accum_size->data[1] = batch_size;"
    },
    {
        "line": 103,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 112,
        "fullcodeline": "TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 113,
        "fullcodeline": "input_offsets_size->data[0] = batch_size;"
    },
    {
        "line": 114,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,"
    },
    {
        "line": 123,
        "fullcodeline": "TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 124,
        "fullcodeline": "row_sums_size->data[0] = row_sums_dims[0];"
    },
    {
        "line": 125,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 104,
        "fullcodeline": "context, context->ResizeTensor(context, accum_scratch, accum_size));"
    },
    {
        "line": 126,
        "fullcodeline": "context, context->ResizeTensor(context, row_sums, row_sums_size));"
    }
]