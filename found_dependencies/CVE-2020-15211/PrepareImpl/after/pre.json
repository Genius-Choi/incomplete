[
    {
        "line": 2,
        "fullcodeline": "auto* params ="
    },
    {
        "line": 4,
        "fullcodeline": "OpData* data = reinterpret_cast<OpData*>(node->user_data);"
    },
    {
        "line": 6,
        "fullcodeline": "TF_LITE_ENSURE(context, node->inputs->size == 2 || node->inputs->size == 3);"
    },
    {
        "line": 8,
        "fullcodeline": "const int expected_outputs_count ="
    },
    {
        "line": 11,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, node->outputs->size, expected_outputs_count);"
    },
    {
        "line": 14,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));"
    },
    {
        "line": 16,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 18,
        "fullcodeline": "const TfLiteTensor* bias ="
    },
    {
        "line": 23,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 27,
        "fullcodeline": "TF_LITE_ENSURE_STATUS("
    },
    {
        "line": 32,
        "fullcodeline": "int input_size = 1;"
    },
    {
        "line": 37,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 2);"
    },
    {
        "line": 38,
        "fullcodeline": "const int batch_size = input_size / filter->dims->data[1];"
    },
    {
        "line": 39,
        "fullcodeline": "const int num_units = filter->dims->data[0];"
    },
    {
        "line": 146,
        "fullcodeline": "TfLiteIntArray* output_size_array = nullptr;"
    },
    {
        "line": 162,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 3,
        "fullcodeline": "reinterpret_cast<TfLiteFullyConnectedParams*>(node->builtin_data);"
    },
    {
        "line": 9,
        "fullcodeline": "params->weights_format == kTfLiteFullyConnectedWeightsFormatDefault ? 1"
    },
    {
        "line": 17,
        "fullcodeline": "GetInputSafe(context, node, kWeightsTensor, &filter));"
    },
    {
        "line": 19,
        "fullcodeline": "(node->inputs->size == 3)"
    },
    {
        "line": 24,
        "fullcodeline": "GetOutputSafe(context, node, kOutputTensor, &output));"
    },
    {
        "line": 28,
        "fullcodeline": "CheckTypes(context, input, filter, bias, output, params));"
    },
    {
        "line": 33,
        "fullcodeline": "for (int i = 0; i < input->dims->size; i++) {"
    },
    {
        "line": 47,
        "fullcodeline": "if (input->type == kTfLiteUInt8 || input->type == kTfLiteInt8 ||"
    },
    {
        "line": 60,
        "fullcodeline": "if (input->type == kTfLiteInt16 && output->type == kTfLiteInt16) {"
    },
    {
        "line": 70,
        "fullcodeline": "if (input->type == kTfLiteFloat32 &&"
    },
    {
        "line": 163,
        "fullcodeline": "context->ResizeTensor(context, output, output_size_array));"
    },
    {
        "line": 20,
        "fullcodeline": "? GetOptionalInputTensor(context, node, kBiasTensor)"
    },
    {
        "line": 34,
        "fullcodeline": "input_size *= input->dims->data[i];"
    },
    {
        "line": 42,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumElements(bias), SizeOfDimension(filter, 0));"
    },
    {
        "line": 48,
        "fullcodeline": "input->type == kTfLiteInt16) {"
    },
    {
        "line": 49,
        "fullcodeline": "double real_multiplier = 0.0;"
    },
    {
        "line": 50,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(GetQuantizedConvolutionMultipler("
    },
    {
        "line": 53,
        "fullcodeline": "QuantizeMultiplier(real_multiplier, &data->output_multiplier, &exponent);"
    },
    {
        "line": 54,
        "fullcodeline": "data->output_shift = exponent;"
    },
    {
        "line": 55,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(CalculateActivationRangeQuantized("
    },
    {
        "line": 61,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);"
    },
    {
        "line": 62,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);"
    },
    {
        "line": 71,
        "fullcodeline": "(filter->type == kTfLiteUInt8 || filter->type == kTfLiteInt8)) {"
    },
    {
        "line": 72,
        "fullcodeline": "TfLiteIntArrayFree(node->temporaries);"
    },
    {
        "line": 73,
        "fullcodeline": "data->compute_row_sums = true;"
    },
    {
        "line": 74,
        "fullcodeline": "node->temporaries = TfLiteIntArrayCreate(5);"
    },
    {
        "line": 75,
        "fullcodeline": "node->temporaries->data[0] = data->scratch_tensor_index;"
    },
    {
        "line": 78,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/0,"
    },
    {
        "line": 80,
        "fullcodeline": "input_quantized->type = filter->type;"
    },
    {
        "line": 81,
        "fullcodeline": "input_quantized->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 83,
        "fullcodeline": "TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);"
    },
    {
        "line": 84,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,"
    },
    {
        "line": 87,
        "fullcodeline": "node->temporaries->data[1] = data->scratch_tensor_index + 1;"
    },
    {
        "line": 89,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,"
    },
    {
        "line": 91,
        "fullcodeline": "scaling_factors->type = kTfLiteFloat32;"
    },
    {
        "line": 92,
        "fullcodeline": "scaling_factors->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 94,
        "fullcodeline": "int scaling_dims[1] = {batch_size};"
    },
    {
        "line": 102,
        "fullcodeline": "node->temporaries->data[2] = data->scratch_tensor_index + 2;"
    },
    {
        "line": 104,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 106,
        "fullcodeline": "accum_scratch->type = kTfLiteInt32;"
    },
    {
        "line": 107,
        "fullcodeline": "accum_scratch->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 108,
        "fullcodeline": "int accum_scratch_dims[2] = {num_units, batch_size};"
    },
    {
        "line": 118,
        "fullcodeline": "node->temporaries->data[3] = data->scratch_tensor_index + 3;"
    },
    {
        "line": 120,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 122,
        "fullcodeline": "input_offsets->type = kTfLiteInt32;"
    },
    {
        "line": 123,
        "fullcodeline": "input_offsets->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 130,
        "fullcodeline": "node->temporaries->data[4] = data->scratch_tensor_index + 4;"
    },
    {
        "line": 132,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 134,
        "fullcodeline": "row_sums->type = kTfLiteInt32;"
    },
    {
        "line": 135,
        "fullcodeline": "row_sums->allocation_type = kTfLiteArenaRwPersistent;"
    },
    {
        "line": 136,
        "fullcodeline": "int row_sums_dims[1] = {num_units};"
    },
    {
        "line": 152,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input->dims->data[input->dims->size - 1],"
    },
    {
        "line": 154,
        "fullcodeline": "output_size_array = TfLiteIntArrayCopy(input->dims);"
    },
    {
        "line": 155,
        "fullcodeline": "output_size_array->data[output_size_array->size - 1] = num_units;"
    },
    {
        "line": 95,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {"
    },
    {
        "line": 105,
        "fullcodeline": "context, GetTemporarySafe(context, node, /*index=*/2, &accum_scratch));"
    },
    {
        "line": 109,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(accum_scratch->dims, 2,"
    },
    {
        "line": 121,
        "fullcodeline": "context, GetTemporarySafe(context, node, /*index=*/3, &input_offsets));"
    },
    {
        "line": 124,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {"
    },
    {
        "line": 133,
        "fullcodeline": "GetTemporarySafe(context, node, /*index=*/4, &row_sums));"
    },
    {
        "line": 137,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {"
    },
    {
        "line": 153,
        "fullcodeline": "SizeOfDimension(filter, 1));"
    },
    {
        "line": 158,
        "fullcodeline": "output_size_array = TfLiteIntArrayCreate(2);"
    },
    {
        "line": 159,
        "fullcodeline": "output_size_array->data[0] = batch_size;"
    },
    {
        "line": 160,
        "fullcodeline": "output_size_array->data[1] = num_units;"
    },
    {
        "line": 96,
        "fullcodeline": "TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 97,
        "fullcodeline": "scaling_factors_size->data[0] = batch_size;"
    },
    {
        "line": 98,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,"
    },
    {
        "line": 111,
        "fullcodeline": "TfLiteIntArray* accum_size = TfLiteIntArrayCreate(2);"
    },
    {
        "line": 112,
        "fullcodeline": "accum_size->data[0] = num_units;"
    },
    {
        "line": 113,
        "fullcodeline": "accum_size->data[1] = batch_size;"
    },
    {
        "line": 114,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 125,
        "fullcodeline": "TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 126,
        "fullcodeline": "input_offsets_size->data[0] = batch_size;"
    },
    {
        "line": 127,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,"
    },
    {
        "line": 138,
        "fullcodeline": "TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 139,
        "fullcodeline": "row_sums_size->data[0] = row_sums_dims[0];"
    },
    {
        "line": 140,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 115,
        "fullcodeline": "context, context->ResizeTensor(context, accum_scratch, accum_size));"
    },
    {
        "line": 141,
        "fullcodeline": "context, context->ResizeTensor(context, row_sums, row_sums_size));"
    }
]