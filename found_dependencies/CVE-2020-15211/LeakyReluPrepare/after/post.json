[
    {
        "line": 2,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);"
    },
    {
        "line": 3,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);"
    },
    {
        "line": 5,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));"
    },
    {
        "line": 7,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));"
    },
    {
        "line": 8,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);"
    },
    {
        "line": 10,
        "fullcodeline": "LeakyReluOpData* data = reinterpret_cast<LeakyReluOpData*>(node->user_data);"
    },
    {
        "line": 12,
        "fullcodeline": "if (output->type == kTfLiteUInt8 || output->type == kTfLiteInt8 ||"
    },
    {
        "line": 25,
        "fullcodeline": "return context->ResizeTensor(context, output,"
    },
    {
        "line": 13,
        "fullcodeline": "output->type == kTfLiteInt16) {"
    },
    {
        "line": 14,
        "fullcodeline": "const auto* params ="
    },
    {
        "line": 17,
        "fullcodeline": "double alpha_multiplier ="
    },
    {
        "line": 19,
        "fullcodeline": "QuantizeMultiplier(alpha_multiplier, &data->output_multiplier_alpha,"
    },
    {
        "line": 21,
        "fullcodeline": "double identity_multiplier = input->params.scale / output->params.scale;"
    },
    {
        "line": 22,
        "fullcodeline": "QuantizeMultiplier(identity_multiplier, &data->output_multiplier_identity,"
    },
    {
        "line": 26,
        "fullcodeline": "TfLiteIntArrayCopy(input->dims));"
    },
    {
        "line": 15,
        "fullcodeline": "reinterpret_cast<TfLiteLeakyReluParams*>(node->builtin_data);"
    },
    {
        "line": 18,
        "fullcodeline": "input->params.scale * params->alpha / output->params.scale;"
    }
]