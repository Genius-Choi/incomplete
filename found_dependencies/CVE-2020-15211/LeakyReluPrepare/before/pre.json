[
    {
        "line": 2,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);"
    },
    {
        "line": 3,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);"
    },
    {
        "line": 4,
        "fullcodeline": "const TfLiteTensor* input = GetInput(context, node, 0);"
    },
    {
        "line": 5,
        "fullcodeline": "TfLiteTensor* output = GetOutput(context, node, 0);"
    },
    {
        "line": 6,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);"
    },
    {
        "line": 8,
        "fullcodeline": "LeakyReluOpData* data = reinterpret_cast<LeakyReluOpData*>(node->user_data);"
    },
    {
        "line": 10,
        "fullcodeline": "if (output->type == kTfLiteUInt8 || output->type == kTfLiteInt8 ||"
    },
    {
        "line": 23,
        "fullcodeline": "return context->ResizeTensor(context, output,"
    },
    {
        "line": 11,
        "fullcodeline": "output->type == kTfLiteInt16) {"
    },
    {
        "line": 12,
        "fullcodeline": "const auto* params ="
    },
    {
        "line": 15,
        "fullcodeline": "double alpha_multiplier ="
    },
    {
        "line": 17,
        "fullcodeline": "QuantizeMultiplier(alpha_multiplier, &data->output_multiplier_alpha,"
    },
    {
        "line": 19,
        "fullcodeline": "double identity_multiplier = input->params.scale / output->params.scale;"
    },
    {
        "line": 20,
        "fullcodeline": "QuantizeMultiplier(identity_multiplier, &data->output_multiplier_identity,"
    },
    {
        "line": 24,
        "fullcodeline": "TfLiteIntArrayCopy(input->dims));"
    },
    {
        "line": 13,
        "fullcodeline": "reinterpret_cast<TfLiteLeakyReluParams*>(node->builtin_data);"
    },
    {
        "line": 16,
        "fullcodeline": "input->params.scale * params->alpha / output->params.scale;"
    }
]