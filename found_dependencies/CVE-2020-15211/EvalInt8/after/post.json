[
    {
        "line": 7,
        "fullcodeline": "int32_t input_offset = -lhs->params.zero_point;"
    },
    {
        "line": 8,
        "fullcodeline": "int32_t filter_offset = -rhs->params.zero_point;"
    },
    {
        "line": 10,
        "fullcodeline": "op_params.input_offset = input_offset;"
    },
    {
        "line": 11,
        "fullcodeline": "op_params.weights_offset = filter_offset;"
    },
    {
        "line": 12,
        "fullcodeline": "op_params.output_offset = output_offset;"
    },
    {
        "line": 13,
        "fullcodeline": "op_params.output_multiplier = data->output_multiplier;"
    },
    {
        "line": 14,
        "fullcodeline": "op_params.output_shift = data->output_shift;"
    },
    {
        "line": 15,
        "fullcodeline": "op_params.quantized_activation_min = data->output_activation_min;"
    },
    {
        "line": 16,
        "fullcodeline": "op_params.quantized_activation_max = data->output_activation_max;"
    },
    {
        "line": 17,
        "fullcodeline": "op_params.lhs_cacheable = IsConstantTensor(lhs);"
    },
    {
        "line": 18,
        "fullcodeline": "op_params.rhs_cacheable = IsConstantTensor(rhs);"
    },
    {
        "line": 20,
        "fullcodeline": "if (kernel_type == kReference) {"
    },
    {
        "line": 21,
        "fullcodeline": "reference_ops::BatchMatMul(op_params, rhs_shape, GetTensorData<int8_t>(rhs),"
    },
    {
        "line": 22,
        "fullcodeline": "lhs_shape, GetTensorData<int8_t>(lhs),"
    },
    {
        "line": 23,
        "fullcodeline": "GetTensorShape(output),"
    },
    {
        "line": 24,
        "fullcodeline": "GetTensorData<int8_t>(output));"
    },
    {
        "line": 26,
        "fullcodeline": "optimized_ops::BatchMatMul(op_params, rhs_shape, GetTensorData<int8_t>(rhs),"
    },
    {
        "line": 27,
        "fullcodeline": "lhs_shape, GetTensorData<int8_t>(lhs),"
    },
    {
        "line": 28,
        "fullcodeline": "GetTensorShape(output),"
    },
    {
        "line": 29,
        "fullcodeline": "GetTensorData<int8_t>(output),"
    },
    {
        "line": 30,
        "fullcodeline": "CpuBackendContext::GetFromContext(context));"
    }
]