[
    {
        "line": 6,
        "fullcodeline": "bool has_bias = node->inputs->size == 3;"
    },
    {
        "line": 8,
        "fullcodeline": "TF_LITE_ENSURE(context, has_bias || node->inputs->size == 2);"
    },
    {
        "line": 9,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);"
    },
    {
        "line": 12,
        "fullcodeline": "auto padding = params->padding;"
    },
    {
        "line": 13,
        "fullcodeline": "data->padding = ComputePaddingHeightWidth("
    },
    {
        "line": 20,
        "fullcodeline": "if (data_type != kTfLiteFloat32) {"
    },
    {
        "line": 21,
        "fullcodeline": "const TfLiteTensor* input = GetInput(context, node, kInputTensor);"
    },
    {
        "line": 22,
        "fullcodeline": "const TfLiteTensor* filter = GetInput(context, node, kFilterTensor);"
    },
    {
        "line": 23,
        "fullcodeline": "const TfLiteTensor* bias ="
    },
    {
        "line": 25,
        "fullcodeline": "TfLiteTensor* output = GetOutput(context, node, kOutputTensor);"
    },
    {
        "line": 28,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams("
    },
    {
        "line": 24,
        "fullcodeline": "GetOptionalInputTensor(context, node, kBiasTensor);"
    },
    {
        "line": 33,
        "fullcodeline": "reinterpret_cast<int*>(data->per_channel_output_shift),"
    }
]