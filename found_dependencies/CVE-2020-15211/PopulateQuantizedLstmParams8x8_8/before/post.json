[
    {
        "line": 5,
        "fullcodeline": "const TfLiteTensor* input = GetInput(context, node, kInputTensor);"
    },
    {
        "line": 6,
        "fullcodeline": "const TfLiteTensor* input_to_input_weights ="
    },
    {
        "line": 8,
        "fullcodeline": "const TfLiteTensor* input_to_forget_weights ="
    },
    {
        "line": 10,
        "fullcodeline": "const TfLiteTensor* input_to_cell_weights ="
    },
    {
        "line": 12,
        "fullcodeline": "const TfLiteTensor* input_to_output_weights ="
    },
    {
        "line": 15,
        "fullcodeline": "const TfLiteTensor* recurrent_to_input_weights ="
    },
    {
        "line": 17,
        "fullcodeline": "const TfLiteTensor* recurrent_to_forget_weights ="
    },
    {
        "line": 19,
        "fullcodeline": "const TfLiteTensor* recurrent_to_cell_weights ="
    },
    {
        "line": 21,
        "fullcodeline": "const TfLiteTensor* recurrent_to_output_weights ="
    },
    {
        "line": 24,
        "fullcodeline": "const TfLiteTensor* cell_to_input_weights ="
    },
    {
        "line": 26,
        "fullcodeline": "const TfLiteTensor* cell_to_forget_weights ="
    },
    {
        "line": 28,
        "fullcodeline": "const TfLiteTensor* cell_to_output_weights ="
    },
    {
        "line": 31,
        "fullcodeline": "const TfLiteTensor* input_layer_norm_coefficients ="
    },
    {
        "line": 33,
        "fullcodeline": "const TfLiteTensor* forget_layer_norm_coefficients ="
    },
    {
        "line": 35,
        "fullcodeline": "const TfLiteTensor* cell_layer_norm_coefficients ="
    },
    {
        "line": 37,
        "fullcodeline": "const TfLiteTensor* output_layer_norm_coefficients ="
    },
    {
        "line": 40,
        "fullcodeline": "const TfLiteTensor* input_gate_bias ="
    },
    {
        "line": 42,
        "fullcodeline": "const TfLiteTensor* forget_gate_bias ="
    },
    {
        "line": 44,
        "fullcodeline": "const TfLiteTensor* cell_gate_bias ="
    },
    {
        "line": 46,
        "fullcodeline": "const TfLiteTensor* output_gate_bias ="
    },
    {
        "line": 49,
        "fullcodeline": "const TfLiteTensor* projection_weights ="
    },
    {
        "line": 51,
        "fullcodeline": "const TfLiteTensor* projection_bias ="
    },
    {
        "line": 54,
        "fullcodeline": "TfLiteTensor* output_state ="
    },
    {
        "line": 56,
        "fullcodeline": "TF_LITE_ENSURE(context, output_state != nullptr);"
    },
    {
        "line": 57,
        "fullcodeline": "TfLiteTensor* cell_state = GetVariableInput(context, node, kCellStateTensor);"
    },
    {
        "line": 58,
        "fullcodeline": "TF_LITE_ENSURE(context, cell_state != nullptr);"
    },
    {
        "line": 62,
        "fullcodeline": "const bool use_cifg = (input_to_input_weights == nullptr);"
    },
    {
        "line": 63,
        "fullcodeline": "const bool use_peephole = (cell_to_output_weights != nullptr);"
    },
    {
        "line": 64,
        "fullcodeline": "const bool is_layer_norm_lstm = (forget_layer_norm_coefficients != nullptr);"
    },
    {
        "line": 65,
        "fullcodeline": "const bool use_projection = (projection_weights != nullptr);"
    },
    {
        "line": 68,
        "fullcodeline": "int8_t* input_to_input_weight_ptr = nullptr;"
    },
    {
        "line": 69,
        "fullcodeline": "int8_t* recurrent_to_input_weight_ptr = nullptr;"
    },
    {
        "line": 70,
        "fullcodeline": "int8_t* cell_to_input_weight_ptr = nullptr;"
    },
    {
        "line": 71,
        "fullcodeline": "int8_t* input_to_forget_weight_ptr = nullptr;"
    },
    {
        "line": 72,
        "fullcodeline": "int8_t* recurrent_to_forget_weight_ptr = nullptr;"
    },
    {
        "line": 73,
        "fullcodeline": "int8_t* cell_to_forget_weight_ptr = nullptr;"
    },
    {
        "line": 74,
        "fullcodeline": "int8_t* input_to_cell_weight_ptr = nullptr;"
    },
    {
        "line": 75,
        "fullcodeline": "int8_t* recurrent_to_cell_weight_ptr = nullptr;"
    },
    {
        "line": 76,
        "fullcodeline": "int8_t* input_to_output_weight_ptr = nullptr;"
    },
    {
        "line": 77,
        "fullcodeline": "int8_t* recurrent_to_output_weight_ptr = nullptr;"
    },
    {
        "line": 78,
        "fullcodeline": "int8_t* cell_to_output_weight_ptr = nullptr;"
    },
    {
        "line": 79,
        "fullcodeline": "int8_t* projection_weight_ptr = nullptr;"
    },
    {
        "line": 80,
        "fullcodeline": "int16_t* layer_norm_input_weight_ptr = nullptr;"
    },
    {
        "line": 81,
        "fullcodeline": "int16_t* layer_norm_forget_weight_ptr = nullptr;"
    },
    {
        "line": 82,
        "fullcodeline": "int16_t* layer_norm_cell_weight_ptr = nullptr;"
    },
    {
        "line": 83,
        "fullcodeline": "int16_t* layer_norm_output_weight_ptr = nullptr;"
    },
    {
        "line": 84,
        "fullcodeline": "int32_t* input_gate_bias_ptr = nullptr;"
    },
    {
        "line": 85,
        "fullcodeline": "int32_t* forget_gate_bias_ptr = nullptr;"
    },
    {
        "line": 86,
        "fullcodeline": "int32_t* cell_gate_bias_ptr = nullptr;"
    },
    {
        "line": 87,
        "fullcodeline": "int32_t* output_gate_bias_ptr = nullptr;"
    },
    {
        "line": 88,
        "fullcodeline": "int32_t* projection_bias_ptr = nullptr;"
    },
    {
        "line": 89,
        "fullcodeline": "int16_t* cell_ptr = nullptr;"
    },
    {
        "line": 90,
        "fullcodeline": "int8_t* output_state_ptr = nullptr;"
    },
    {
        "line": 93,
        "fullcodeline": "const float default_scale = 1.0;"
    },
    {
        "line": 94,
        "fullcodeline": "float input_scale = default_scale;"
    },
    {
        "line": 95,
        "fullcodeline": "float input_to_input_weight_scale = default_scale;"
    },
    {
        "line": 96,
        "fullcodeline": "float recurrent_to_input_weight_scale = default_scale;"
    },
    {
        "line": 97,
        "fullcodeline": "float cell_to_input_weight_scale = default_scale;"
    },
    {
        "line": 98,
        "fullcodeline": "float input_to_forget_weight_scale = default_scale;"
    },
    {
        "line": 99,
        "fullcodeline": "float recurrent_to_forget_weight_scale = default_scale;"
    },
    {
        "line": 100,
        "fullcodeline": "float cell_to_forget_weight_scale = default_scale;"
    },
    {
        "line": 101,
        "fullcodeline": "float input_to_cell_weight_scale = default_scale;"
    },
    {
        "line": 102,
        "fullcodeline": "float recurrent_to_cell_weight_scale = default_scale;"
    },
    {
        "line": 103,
        "fullcodeline": "float input_to_output_weight_scale = default_scale;"
    },
    {
        "line": 104,
        "fullcodeline": "float recurrent_to_output_weight_scale = default_scale;"
    },
    {
        "line": 105,
        "fullcodeline": "float cell_to_output_weight_scale = default_scale;"
    },
    {
        "line": 106,
        "fullcodeline": "float projection_weight_scale = default_scale;"
    },
    {
        "line": 107,
        "fullcodeline": "float layer_norm_input_scale = default_scale;"
    },
    {
        "line": 108,
        "fullcodeline": "float layer_norm_forget_scale = default_scale;"
    },
    {
        "line": 109,
        "fullcodeline": "float layer_norm_cell_scale = default_scale;"
    },
    {
        "line": 110,
        "fullcodeline": "float layer_norm_output_scale = default_scale;"
    },
    {
        "line": 111,
        "fullcodeline": "float output_state_scale = default_scale;"
    },
    {
        "line": 114,
        "fullcodeline": "float effective_input_to_input_scale = default_scale;"
    },
    {
        "line": 115,
        "fullcodeline": "float effective_recurrent_to_input_scale = default_scale;"
    },
    {
        "line": 116,
        "fullcodeline": "float effective_cell_to_input_scale = default_scale;"
    },
    {
        "line": 117,
        "fullcodeline": "float effective_input_to_forget_scale = default_scale;"
    },
    {
        "line": 118,
        "fullcodeline": "float effective_recurrent_to_forget_scale = default_scale;"
    },
    {
        "line": 119,
        "fullcodeline": "float effective_cell_to_forget_scale = default_scale;"
    },
    {
        "line": 120,
        "fullcodeline": "float effective_input_to_cell_scale = default_scale;"
    },
    {
        "line": 121,
        "fullcodeline": "float effective_recurrent_to_cell_scale = default_scale;"
    },
    {
        "line": 122,
        "fullcodeline": "float effective_input_to_output_scale = default_scale;"
    },
    {
        "line": 123,
        "fullcodeline": "float effective_recurrent_to_output_scale = default_scale;"
    },
    {
        "line": 124,
        "fullcodeline": "float effective_cell_to_output_scale = default_scale;"
    },
    {
        "line": 125,
        "fullcodeline": "float effective_proj_scale = default_scale;"
    },
    {
        "line": 128,
        "fullcodeline": "int input_zp = 0;"
    },
    {
        "line": 129,
        "fullcodeline": "int output_state_zp = 0;"
    },
    {
        "line": 212,
        "fullcodeline": "effective_input_to_forget_scale ="
    },
    {
        "line": 214,
        "fullcodeline": "effective_recurrent_to_forget_scale = recurrent_to_forget_weight_scale *"
    },
    {
        "line": 218,
        "fullcodeline": "effective_input_to_cell_scale ="
    },
    {
        "line": 220,
        "fullcodeline": "effective_recurrent_to_cell_scale = recurrent_to_cell_weight_scale *"
    },
    {
        "line": 224,
        "fullcodeline": "effective_input_to_output_scale ="
    },
    {
        "line": 226,
        "fullcodeline": "effective_recurrent_to_output_scale = recurrent_to_output_weight_scale *"
    },
    {
        "line": 229,
        "fullcodeline": "effective_proj_scale ="
    },
    {
        "line": 244,
        "fullcodeline": "QuantizeMultiplier(effective_input_to_input_scale,"
    },
    {
        "line": 247,
        "fullcodeline": "QuantizeMultiplier(effective_recurrent_to_input_scale,"
    },
    {
        "line": 250,
        "fullcodeline": "QuantizeMultiplier(effective_cell_to_input_scale,"
    },
    {
        "line": 253,
        "fullcodeline": "QuantizeMultiplier(effective_input_to_forget_scale,"
    },
    {
        "line": 256,
        "fullcodeline": "QuantizeMultiplier("
    },
    {
        "line": 260,
        "fullcodeline": "QuantizeMultiplier(effective_cell_to_forget_scale,"
    },
    {
        "line": 263,
        "fullcodeline": "QuantizeMultiplier(effective_input_to_cell_scale,"
    },
    {
        "line": 266,
        "fullcodeline": "QuantizeMultiplier(effective_recurrent_to_cell_scale,"
    },
    {
        "line": 269,
        "fullcodeline": "QuantizeMultiplier(effective_input_to_output_scale,"
    },
    {
        "line": 272,
        "fullcodeline": "QuantizeMultiplier("
    },
    {
        "line": 276,
        "fullcodeline": "QuantizeMultiplier(effective_cell_to_output_scale,"
    },
    {
        "line": 279,
        "fullcodeline": "QuantizeMultiplier(effective_proj_scale,"
    },
    {
        "line": 282,
        "fullcodeline": "QuantizeMultiplier(layer_norm_input_scale,"
    },
    {
        "line": 285,
        "fullcodeline": "QuantizeMultiplier(layer_norm_forget_scale,"
    },
    {
        "line": 288,
        "fullcodeline": "QuantizeMultiplier(layer_norm_cell_scale,"
    },
    {
        "line": 291,
        "fullcodeline": "QuantizeMultiplier(layer_norm_output_scale,"
    },
    {
        "line": 329,
        "fullcodeline": "const auto* params = reinterpret_cast<TfLiteLSTMParams*>(node->builtin_data);"
    },
    {
        "line": 330,
        "fullcodeline": "const float cell_clip = params->cell_clip;"
    },
    {
        "line": 331,
        "fullcodeline": "const float proj_clip = params->proj_clip;"
    },
    {
        "line": 333,
        "fullcodeline": "const TfLiteTensor* output_tensor = GetOutput(context, node, kOutputTensor);"
    },
    {
        "line": 339,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, cell_state_params->scale->data[0], 1.0 / 32768);"
    },
    {
        "line": 7,
        "fullcodeline": "GetOptionalInputTensor(context, node, kInputToInputWeightsTensor);"
    },
    {
        "line": 9,
        "fullcodeline": "GetInput(context, node, kInputToForgetWeightsTensor);"
    },
    {
        "line": 11,
        "fullcodeline": "GetInput(context, node, kInputToCellWeightsTensor);"
    },
    {
        "line": 13,
        "fullcodeline": "GetInput(context, node, kInputToOutputWeightsTensor);"
    },
    {
        "line": 16,
        "fullcodeline": "GetOptionalInputTensor(context, node, kRecurrentToInputWeightsTensor);"
    },
    {
        "line": 18,
        "fullcodeline": "GetInput(context, node, kRecurrentToForgetWeightsTensor);"
    },
    {
        "line": 20,
        "fullcodeline": "GetInput(context, node, kRecurrentToCellWeightsTensor);"
    },
    {
        "line": 22,
        "fullcodeline": "GetInput(context, node, kRecurrentToOutputWeightsTensor);"
    },
    {
        "line": 25,
        "fullcodeline": "GetOptionalInputTensor(context, node, kCellToInputWeightsTensor);"
    },
    {
        "line": 27,
        "fullcodeline": "GetOptionalInputTensor(context, node, kCellToForgetWeightsTensor);"
    },
    {
        "line": 29,
        "fullcodeline": "GetOptionalInputTensor(context, node, kCellToOutputWeightsTensor);"
    },
    {
        "line": 32,
        "fullcodeline": "GetOptionalInputTensor(context, node, kInputLayerNormCoefficientsTensor);"
    },
    {
        "line": 34,
        "fullcodeline": "GetOptionalInputTensor(context, node, kForgetLayerNormCoefficientsTensor);"
    },
    {
        "line": 36,
        "fullcodeline": "GetOptionalInputTensor(context, node, kCellLayerNormCoefficientsTensor);"
    },
    {
        "line": 38,
        "fullcodeline": "GetOptionalInputTensor(context, node, kOutputLayerNormCoefficientsTensor);"
    },
    {
        "line": 41,
        "fullcodeline": "GetOptionalInputTensor(context, node, kInputGateBiasTensor);"
    },
    {
        "line": 43,
        "fullcodeline": "GetInput(context, node, kForgetGateBiasTensor);"
    },
    {
        "line": 45,
        "fullcodeline": "GetInput(context, node, kCellGateBiasTensor);"
    },
    {
        "line": 47,
        "fullcodeline": "GetInput(context, node, kOutputGateBiasTensor);"
    },
    {
        "line": 50,
        "fullcodeline": "GetOptionalInputTensor(context, node, kProjectionWeightsTensor);"
    },
    {
        "line": 52,
        "fullcodeline": "GetOptionalInputTensor(context, node, kProjectionBiasTensor);"
    },
    {
        "line": 55,
        "fullcodeline": "GetVariableInput(context, node, kOutputStateTensor);"
    },
    {
        "line": 132,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 195,
        "fullcodeline": "for (int i = 0; i < 12; ++i) {"
    },
    {
        "line": 205,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 213,
        "fullcodeline": "input_to_forget_weight_scale * input_scale / intermediate_scale[4];"
    },
    {
        "line": 219,
        "fullcodeline": "input_to_cell_weight_scale * input_scale / intermediate_scale[7];"
    },
    {
        "line": 225,
        "fullcodeline": "input_to_output_weight_scale * input_scale / intermediate_scale[10];"
    },
    {
        "line": 230,
        "fullcodeline": "projection_weight_scale * std::pow(2, -15) / output_state_scale;"
    },
    {
        "line": 302,
        "fullcodeline": "const float s_1_0 = intermediate_scale[1] / intermediate_scale[0];"
    },
    {
        "line": 303,
        "fullcodeline": "const float s_2_0 = intermediate_scale[2] / intermediate_scale[0];"
    },
    {
        "line": 304,
        "fullcodeline": "const float s_4_3 = intermediate_scale[4] / intermediate_scale[3];"
    },
    {
        "line": 305,
        "fullcodeline": "const float s_5_3 = intermediate_scale[5] / intermediate_scale[3];"
    },
    {
        "line": 306,
        "fullcodeline": "const float s_7_6 = intermediate_scale[7] / intermediate_scale[6];"
    },
    {
        "line": 307,
        "fullcodeline": "const float s_8_6 = intermediate_scale[8] / intermediate_scale[6];"
    },
    {
        "line": 308,
        "fullcodeline": "const float s_10_9 = intermediate_scale[10] / intermediate_scale[9];"
    },
    {
        "line": 309,
        "fullcodeline": "const float s_11_9 = intermediate_scale[11] / intermediate_scale[9];"
    },
    {
        "line": 310,
        "fullcodeline": "QuantizeMultiplier(s_1_0, &integer_lstm_param->intermediate_scale_a[0],"
    },
    {
        "line": 312,
        "fullcodeline": "QuantizeMultiplier(s_2_0, &integer_lstm_param->intermediate_scale_a[1],"
    },
    {
        "line": 314,
        "fullcodeline": "QuantizeMultiplier(s_4_3, &integer_lstm_param->intermediate_scale_a[2],"
    },
    {
        "line": 316,
        "fullcodeline": "QuantizeMultiplier(s_5_3, &integer_lstm_param->intermediate_scale_a[3],"
    },
    {
        "line": 318,
        "fullcodeline": "QuantizeMultiplier(s_7_6, &integer_lstm_param->intermediate_scale_a[4],"
    },
    {
        "line": 320,
        "fullcodeline": "QuantizeMultiplier(s_8_6, &integer_lstm_param->intermediate_scale_a[5],"
    },
    {
        "line": 322,
        "fullcodeline": "QuantizeMultiplier(s_10_9, &integer_lstm_param->intermediate_scale_a[6],"
    },
    {
        "line": 324,
        "fullcodeline": "QuantizeMultiplier(s_11_9, &integer_lstm_param->intermediate_scale_a[7],"
    },
    {
        "line": 340,
        "fullcodeline": "if (cell_clip > 0.0 && cell_clip < 1.0) {"
    },
    {
        "line": 347,
        "fullcodeline": "if (proj_clip > 0.0) {"
    },
    {
        "line": 200,
        "fullcodeline": "intermediate_scale.push_back(params->scale->data[0]);"
    },
    {
        "line": 206,
        "fullcodeline": "effective_input_to_input_scale ="
    },
    {
        "line": 208,
        "fullcodeline": "effective_recurrent_to_input_scale = recurrent_to_input_weight_scale *"
    },
    {
        "line": 237,
        "fullcodeline": "effective_cell_to_forget_scale ="
    },
    {
        "line": 239,
        "fullcodeline": "effective_cell_to_output_scale ="
    },
    {
        "line": 341,
        "fullcodeline": "integer_lstm_param->quantized_cell_clip = static_cast<int16_t>(std::min("
    },
    {
        "line": 348,
        "fullcodeline": "integer_lstm_param->quantized_proj_clip = static_cast<int8_t>(std::min("
    },
    {
        "line": 141,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 152,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 207,
        "fullcodeline": "input_to_input_weight_scale * input_scale / intermediate_scale[1];"
    },
    {
        "line": 233,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 238,
        "fullcodeline": "std::pow(2, -15) * cell_to_forget_weight_scale / intermediate_scale[3];"
    },
    {
        "line": 240,
        "fullcodeline": "std::pow(2, -15) * cell_to_output_weight_scale / intermediate_scale[9];"
    },
    {
        "line": 345,
        "fullcodeline": "integer_lstm_param->quantized_cell_clip = 0;"
    },
    {
        "line": 351,
        "fullcodeline": "integer_lstm_param->quantized_proj_clip = 0;"
    },
    {
        "line": 234,
        "fullcodeline": "effective_cell_to_input_scale ="
    },
    {
        "line": 235,
        "fullcodeline": "std::pow(2, -15) * cell_to_input_weight_scale / intermediate_scale[0];"
    },
    {
        "line": 342,
        "fullcodeline": "std::max(cell_clip / cell_state_params->scale->data[0], -32768.0f),"
    },
    {
        "line": 349,
        "fullcodeline": "std::max(proj_clip / proj_params->scale->data[0], -128.0f), 127.0f));"
    }
]