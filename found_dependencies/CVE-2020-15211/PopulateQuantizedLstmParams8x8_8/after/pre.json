[
    {
        "line": 6,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));"
    },
    {
        "line": 7,
        "fullcodeline": "const TfLiteTensor* input_to_input_weights ="
    },
    {
        "line": 10,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 14,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 18,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 22,
        "fullcodeline": "const TfLiteTensor* recurrent_to_input_weights ="
    },
    {
        "line": 25,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 29,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 33,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 37,
        "fullcodeline": "const TfLiteTensor* cell_to_input_weights ="
    },
    {
        "line": 39,
        "fullcodeline": "const TfLiteTensor* cell_to_forget_weights ="
    },
    {
        "line": 41,
        "fullcodeline": "const TfLiteTensor* cell_to_output_weights ="
    },
    {
        "line": 44,
        "fullcodeline": "const TfLiteTensor* input_layer_norm_coefficients ="
    },
    {
        "line": 46,
        "fullcodeline": "const TfLiteTensor* forget_layer_norm_coefficients ="
    },
    {
        "line": 48,
        "fullcodeline": "const TfLiteTensor* cell_layer_norm_coefficients ="
    },
    {
        "line": 50,
        "fullcodeline": "const TfLiteTensor* output_layer_norm_coefficients ="
    },
    {
        "line": 53,
        "fullcodeline": "const TfLiteTensor* input_gate_bias ="
    },
    {
        "line": 56,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kForgetGateBiasTensor,"
    },
    {
        "line": 59,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kCellGateBiasTensor,"
    },
    {
        "line": 62,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kOutputGateBiasTensor,"
    },
    {
        "line": 65,
        "fullcodeline": "const TfLiteTensor* projection_weights ="
    },
    {
        "line": 67,
        "fullcodeline": "const TfLiteTensor* projection_bias ="
    },
    {
        "line": 70,
        "fullcodeline": "TfLiteTensor* output_state ="
    },
    {
        "line": 72,
        "fullcodeline": "TF_LITE_ENSURE(context, output_state != nullptr);"
    },
    {
        "line": 73,
        "fullcodeline": "TfLiteTensor* cell_state = GetVariableInput(context, node, kCellStateTensor);"
    },
    {
        "line": 74,
        "fullcodeline": "TF_LITE_ENSURE(context, cell_state != nullptr);"
    },
    {
        "line": 78,
        "fullcodeline": "const bool use_cifg = (input_to_input_weights == nullptr);"
    },
    {
        "line": 79,
        "fullcodeline": "const bool use_peephole = (cell_to_output_weights != nullptr);"
    },
    {
        "line": 80,
        "fullcodeline": "const bool is_layer_norm_lstm = (forget_layer_norm_coefficients != nullptr);"
    },
    {
        "line": 81,
        "fullcodeline": "const bool use_projection = (projection_weights != nullptr);"
    },
    {
        "line": 84,
        "fullcodeline": "int8_t* input_to_input_weight_ptr = nullptr;"
    },
    {
        "line": 85,
        "fullcodeline": "int8_t* recurrent_to_input_weight_ptr = nullptr;"
    },
    {
        "line": 86,
        "fullcodeline": "int8_t* cell_to_input_weight_ptr = nullptr;"
    },
    {
        "line": 87,
        "fullcodeline": "int8_t* input_to_forget_weight_ptr = nullptr;"
    },
    {
        "line": 88,
        "fullcodeline": "int8_t* recurrent_to_forget_weight_ptr = nullptr;"
    },
    {
        "line": 89,
        "fullcodeline": "int8_t* cell_to_forget_weight_ptr = nullptr;"
    },
    {
        "line": 90,
        "fullcodeline": "int8_t* input_to_cell_weight_ptr = nullptr;"
    },
    {
        "line": 91,
        "fullcodeline": "int8_t* recurrent_to_cell_weight_ptr = nullptr;"
    },
    {
        "line": 92,
        "fullcodeline": "int8_t* input_to_output_weight_ptr = nullptr;"
    },
    {
        "line": 93,
        "fullcodeline": "int8_t* recurrent_to_output_weight_ptr = nullptr;"
    },
    {
        "line": 94,
        "fullcodeline": "int8_t* cell_to_output_weight_ptr = nullptr;"
    },
    {
        "line": 95,
        "fullcodeline": "int8_t* projection_weight_ptr = nullptr;"
    },
    {
        "line": 96,
        "fullcodeline": "int16_t* layer_norm_input_weight_ptr = nullptr;"
    },
    {
        "line": 97,
        "fullcodeline": "int16_t* layer_norm_forget_weight_ptr = nullptr;"
    },
    {
        "line": 98,
        "fullcodeline": "int16_t* layer_norm_cell_weight_ptr = nullptr;"
    },
    {
        "line": 99,
        "fullcodeline": "int16_t* layer_norm_output_weight_ptr = nullptr;"
    },
    {
        "line": 100,
        "fullcodeline": "int32_t* input_gate_bias_ptr = nullptr;"
    },
    {
        "line": 101,
        "fullcodeline": "int32_t* forget_gate_bias_ptr = nullptr;"
    },
    {
        "line": 102,
        "fullcodeline": "int32_t* cell_gate_bias_ptr = nullptr;"
    },
    {
        "line": 103,
        "fullcodeline": "int32_t* output_gate_bias_ptr = nullptr;"
    },
    {
        "line": 104,
        "fullcodeline": "int32_t* projection_bias_ptr = nullptr;"
    },
    {
        "line": 105,
        "fullcodeline": "int16_t* cell_ptr = nullptr;"
    },
    {
        "line": 106,
        "fullcodeline": "int8_t* output_state_ptr = nullptr;"
    },
    {
        "line": 109,
        "fullcodeline": "const float default_scale = 1.0;"
    },
    {
        "line": 110,
        "fullcodeline": "float input_scale = default_scale;"
    },
    {
        "line": 111,
        "fullcodeline": "float input_to_input_weight_scale = default_scale;"
    },
    {
        "line": 112,
        "fullcodeline": "float recurrent_to_input_weight_scale = default_scale;"
    },
    {
        "line": 113,
        "fullcodeline": "float cell_to_input_weight_scale = default_scale;"
    },
    {
        "line": 114,
        "fullcodeline": "float input_to_forget_weight_scale = default_scale;"
    },
    {
        "line": 115,
        "fullcodeline": "float recurrent_to_forget_weight_scale = default_scale;"
    },
    {
        "line": 116,
        "fullcodeline": "float cell_to_forget_weight_scale = default_scale;"
    },
    {
        "line": 117,
        "fullcodeline": "float input_to_cell_weight_scale = default_scale;"
    },
    {
        "line": 118,
        "fullcodeline": "float recurrent_to_cell_weight_scale = default_scale;"
    },
    {
        "line": 119,
        "fullcodeline": "float input_to_output_weight_scale = default_scale;"
    },
    {
        "line": 120,
        "fullcodeline": "float recurrent_to_output_weight_scale = default_scale;"
    },
    {
        "line": 121,
        "fullcodeline": "float cell_to_output_weight_scale = default_scale;"
    },
    {
        "line": 122,
        "fullcodeline": "float projection_weight_scale = default_scale;"
    },
    {
        "line": 123,
        "fullcodeline": "float layer_norm_input_scale = default_scale;"
    },
    {
        "line": 124,
        "fullcodeline": "float layer_norm_forget_scale = default_scale;"
    },
    {
        "line": 125,
        "fullcodeline": "float layer_norm_cell_scale = default_scale;"
    },
    {
        "line": 126,
        "fullcodeline": "float layer_norm_output_scale = default_scale;"
    },
    {
        "line": 127,
        "fullcodeline": "float output_state_scale = default_scale;"
    },
    {
        "line": 130,
        "fullcodeline": "float effective_input_to_input_scale = default_scale;"
    },
    {
        "line": 131,
        "fullcodeline": "float effective_recurrent_to_input_scale = default_scale;"
    },
    {
        "line": 132,
        "fullcodeline": "float effective_cell_to_input_scale = default_scale;"
    },
    {
        "line": 133,
        "fullcodeline": "float effective_input_to_forget_scale = default_scale;"
    },
    {
        "line": 134,
        "fullcodeline": "float effective_recurrent_to_forget_scale = default_scale;"
    },
    {
        "line": 135,
        "fullcodeline": "float effective_cell_to_forget_scale = default_scale;"
    },
    {
        "line": 136,
        "fullcodeline": "float effective_input_to_cell_scale = default_scale;"
    },
    {
        "line": 137,
        "fullcodeline": "float effective_recurrent_to_cell_scale = default_scale;"
    },
    {
        "line": 138,
        "fullcodeline": "float effective_input_to_output_scale = default_scale;"
    },
    {
        "line": 139,
        "fullcodeline": "float effective_recurrent_to_output_scale = default_scale;"
    },
    {
        "line": 140,
        "fullcodeline": "float effective_cell_to_output_scale = default_scale;"
    },
    {
        "line": 141,
        "fullcodeline": "float effective_proj_scale = default_scale;"
    },
    {
        "line": 144,
        "fullcodeline": "int input_zp = 0;"
    },
    {
        "line": 145,
        "fullcodeline": "int output_state_zp = 0;"
    },
    {
        "line": 187,
        "fullcodeline": "output_state_scale = output_state->params.scale;"
    },
    {
        "line": 189,
        "fullcodeline": "input_to_forget_weight_ptr = input_to_forget_weights->data.int8;"
    },
    {
        "line": 190,
        "fullcodeline": "input_to_forget_weight_scale = input_to_forget_weights->params.scale;"
    },
    {
        "line": 191,
        "fullcodeline": "input_to_cell_weight_ptr = input_to_cell_weights->data.int8;"
    },
    {
        "line": 192,
        "fullcodeline": "input_to_cell_weight_scale = input_to_cell_weights->params.scale;"
    },
    {
        "line": 193,
        "fullcodeline": "input_to_output_weight_ptr = input_to_output_weights->data.int8;"
    },
    {
        "line": 194,
        "fullcodeline": "input_to_output_weight_scale = input_to_output_weights->params.scale;"
    },
    {
        "line": 195,
        "fullcodeline": "recurrent_to_forget_weight_ptr = recurrent_to_forget_weights->data.int8;"
    },
    {
        "line": 196,
        "fullcodeline": "recurrent_to_forget_weight_scale = recurrent_to_forget_weights->params.scale;"
    },
    {
        "line": 197,
        "fullcodeline": "recurrent_to_cell_weight_ptr = recurrent_to_cell_weights->data.int8;"
    },
    {
        "line": 198,
        "fullcodeline": "recurrent_to_cell_weight_scale = recurrent_to_cell_weights->params.scale;"
    },
    {
        "line": 199,
        "fullcodeline": "recurrent_to_output_weight_ptr = recurrent_to_output_weights->data.int8;"
    },
    {
        "line": 200,
        "fullcodeline": "recurrent_to_output_weight_scale = recurrent_to_output_weights->params.scale;"
    },
    {
        "line": 201,
        "fullcodeline": "forget_gate_bias_ptr = forget_gate_bias->data.i32;"
    },
    {
        "line": 202,
        "fullcodeline": "cell_gate_bias_ptr = cell_gate_bias->data.i32;"
    },
    {
        "line": 203,
        "fullcodeline": "output_gate_bias_ptr = output_gate_bias->data.i32;"
    },
    {
        "line": 204,
        "fullcodeline": "output_state_ptr = output_state->data.int8;"
    },
    {
        "line": 205,
        "fullcodeline": "cell_ptr = cell_state->data.i16;"
    },
    {
        "line": 206,
        "fullcodeline": "input_scale = input->params.scale;"
    },
    {
        "line": 207,
        "fullcodeline": "input_zp = input->params.zero_point;"
    },
    {
        "line": 208,
        "fullcodeline": "output_state_zp = output_state->params.zero_point;"
    },
    {
        "line": 228,
        "fullcodeline": "effective_input_to_forget_scale ="
    },
    {
        "line": 230,
        "fullcodeline": "effective_recurrent_to_forget_scale = recurrent_to_forget_weight_scale *"
    },
    {
        "line": 234,
        "fullcodeline": "effective_input_to_cell_scale ="
    },
    {
        "line": 236,
        "fullcodeline": "effective_recurrent_to_cell_scale = recurrent_to_cell_weight_scale *"
    },
    {
        "line": 240,
        "fullcodeline": "effective_input_to_output_scale ="
    },
    {
        "line": 242,
        "fullcodeline": "effective_recurrent_to_output_scale = recurrent_to_output_weight_scale *"
    },
    {
        "line": 245,
        "fullcodeline": "effective_proj_scale ="
    },
    {
        "line": 260,
        "fullcodeline": "QuantizeMultiplier(effective_input_to_input_scale,"
    },
    {
        "line": 263,
        "fullcodeline": "QuantizeMultiplier(effective_recurrent_to_input_scale,"
    },
    {
        "line": 266,
        "fullcodeline": "QuantizeMultiplier(effective_cell_to_input_scale,"
    },
    {
        "line": 269,
        "fullcodeline": "QuantizeMultiplier(effective_input_to_forget_scale,"
    },
    {
        "line": 272,
        "fullcodeline": "QuantizeMultiplier("
    },
    {
        "line": 276,
        "fullcodeline": "QuantizeMultiplier(effective_cell_to_forget_scale,"
    },
    {
        "line": 279,
        "fullcodeline": "QuantizeMultiplier(effective_input_to_cell_scale,"
    },
    {
        "line": 282,
        "fullcodeline": "QuantizeMultiplier(effective_recurrent_to_cell_scale,"
    },
    {
        "line": 285,
        "fullcodeline": "QuantizeMultiplier(effective_input_to_output_scale,"
    },
    {
        "line": 288,
        "fullcodeline": "QuantizeMultiplier("
    },
    {
        "line": 292,
        "fullcodeline": "QuantizeMultiplier(effective_cell_to_output_scale,"
    },
    {
        "line": 295,
        "fullcodeline": "QuantizeMultiplier(effective_proj_scale,"
    },
    {
        "line": 298,
        "fullcodeline": "QuantizeMultiplier(layer_norm_input_scale,"
    },
    {
        "line": 301,
        "fullcodeline": "QuantizeMultiplier(layer_norm_forget_scale,"
    },
    {
        "line": 304,
        "fullcodeline": "QuantizeMultiplier(layer_norm_cell_scale,"
    },
    {
        "line": 307,
        "fullcodeline": "QuantizeMultiplier(layer_norm_output_scale,"
    },
    {
        "line": 345,
        "fullcodeline": "const auto* params = reinterpret_cast<TfLiteLSTMParams*>(node->builtin_data);"
    },
    {
        "line": 346,
        "fullcodeline": "const float cell_clip = params->cell_clip;"
    },
    {
        "line": 347,
        "fullcodeline": "const float proj_clip = params->proj_clip;"
    },
    {
        "line": 350,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 353,
        "fullcodeline": "auto* cell_state_params = reinterpret_cast<TfLiteAffineQuantization*>("
    },
    {
        "line": 355,
        "fullcodeline": "auto* proj_params = reinterpret_cast<TfLiteAffineQuantization*>("
    },
    {
        "line": 357,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, cell_state_params->scale->data[0], 1.0 / 32768);"
    },
    {
        "line": 8,
        "fullcodeline": "GetOptionalInputTensor(context, node, kInputToInputWeightsTensor);"
    },
    {
        "line": 11,
        "fullcodeline": "GetInputSafe(context, node, kInputToForgetWeightsTensor,"
    },
    {
        "line": 15,
        "fullcodeline": "GetInputSafe(context, node, kInputToCellWeightsTensor,"
    },
    {
        "line": 19,
        "fullcodeline": "GetInputSafe(context, node, kInputToOutputWeightsTensor,"
    },
    {
        "line": 23,
        "fullcodeline": "GetOptionalInputTensor(context, node, kRecurrentToInputWeightsTensor);"
    },
    {
        "line": 26,
        "fullcodeline": "GetInputSafe(context, node, kRecurrentToForgetWeightsTensor,"
    },
    {
        "line": 30,
        "fullcodeline": "GetInputSafe(context, node, kRecurrentToCellWeightsTensor,"
    },
    {
        "line": 34,
        "fullcodeline": "GetInputSafe(context, node, kRecurrentToOutputWeightsTensor,"
    },
    {
        "line": 38,
        "fullcodeline": "GetOptionalInputTensor(context, node, kCellToInputWeightsTensor);"
    },
    {
        "line": 40,
        "fullcodeline": "GetOptionalInputTensor(context, node, kCellToForgetWeightsTensor);"
    },
    {
        "line": 42,
        "fullcodeline": "GetOptionalInputTensor(context, node, kCellToOutputWeightsTensor);"
    },
    {
        "line": 45,
        "fullcodeline": "GetOptionalInputTensor(context, node, kInputLayerNormCoefficientsTensor);"
    },
    {
        "line": 47,
        "fullcodeline": "GetOptionalInputTensor(context, node, kForgetLayerNormCoefficientsTensor);"
    },
    {
        "line": 49,
        "fullcodeline": "GetOptionalInputTensor(context, node, kCellLayerNormCoefficientsTensor);"
    },
    {
        "line": 51,
        "fullcodeline": "GetOptionalInputTensor(context, node, kOutputLayerNormCoefficientsTensor);"
    },
    {
        "line": 54,
        "fullcodeline": "GetOptionalInputTensor(context, node, kInputGateBiasTensor);"
    },
    {
        "line": 66,
        "fullcodeline": "GetOptionalInputTensor(context, node, kProjectionWeightsTensor);"
    },
    {
        "line": 68,
        "fullcodeline": "GetOptionalInputTensor(context, node, kProjectionBiasTensor);"
    },
    {
        "line": 71,
        "fullcodeline": "GetVariableInput(context, node, kOutputStateTensor);"
    },
    {
        "line": 148,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 211,
        "fullcodeline": "for (int i = 0; i < 12; ++i) {"
    },
    {
        "line": 221,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 229,
        "fullcodeline": "input_to_forget_weight_scale * input_scale / intermediate_scale[4];"
    },
    {
        "line": 235,
        "fullcodeline": "input_to_cell_weight_scale * input_scale / intermediate_scale[7];"
    },
    {
        "line": 241,
        "fullcodeline": "input_to_output_weight_scale * input_scale / intermediate_scale[10];"
    },
    {
        "line": 246,
        "fullcodeline": "projection_weight_scale * std::pow(2, -15) / output_state_scale;"
    },
    {
        "line": 318,
        "fullcodeline": "const float s_1_0 = intermediate_scale[1] / intermediate_scale[0];"
    },
    {
        "line": 319,
        "fullcodeline": "const float s_2_0 = intermediate_scale[2] / intermediate_scale[0];"
    },
    {
        "line": 320,
        "fullcodeline": "const float s_4_3 = intermediate_scale[4] / intermediate_scale[3];"
    },
    {
        "line": 321,
        "fullcodeline": "const float s_5_3 = intermediate_scale[5] / intermediate_scale[3];"
    },
    {
        "line": 322,
        "fullcodeline": "const float s_7_6 = intermediate_scale[7] / intermediate_scale[6];"
    },
    {
        "line": 323,
        "fullcodeline": "const float s_8_6 = intermediate_scale[8] / intermediate_scale[6];"
    },
    {
        "line": 324,
        "fullcodeline": "const float s_10_9 = intermediate_scale[10] / intermediate_scale[9];"
    },
    {
        "line": 325,
        "fullcodeline": "const float s_11_9 = intermediate_scale[11] / intermediate_scale[9];"
    },
    {
        "line": 326,
        "fullcodeline": "QuantizeMultiplier(s_1_0, &integer_lstm_param->intermediate_scale_a[0],"
    },
    {
        "line": 328,
        "fullcodeline": "QuantizeMultiplier(s_2_0, &integer_lstm_param->intermediate_scale_a[1],"
    },
    {
        "line": 330,
        "fullcodeline": "QuantizeMultiplier(s_4_3, &integer_lstm_param->intermediate_scale_a[2],"
    },
    {
        "line": 332,
        "fullcodeline": "QuantizeMultiplier(s_5_3, &integer_lstm_param->intermediate_scale_a[3],"
    },
    {
        "line": 334,
        "fullcodeline": "QuantizeMultiplier(s_7_6, &integer_lstm_param->intermediate_scale_a[4],"
    },
    {
        "line": 336,
        "fullcodeline": "QuantizeMultiplier(s_8_6, &integer_lstm_param->intermediate_scale_a[5],"
    },
    {
        "line": 338,
        "fullcodeline": "QuantizeMultiplier(s_10_9, &integer_lstm_param->intermediate_scale_a[6],"
    },
    {
        "line": 340,
        "fullcodeline": "QuantizeMultiplier(s_11_9, &integer_lstm_param->intermediate_scale_a[7],"
    },
    {
        "line": 351,
        "fullcodeline": "context, GetOutputSafe(context, node, kOutputTensor, &output_tensor));"
    },
    {
        "line": 358,
        "fullcodeline": "if (cell_clip > 0.0 && cell_clip < 1.0) {"
    },
    {
        "line": 365,
        "fullcodeline": "if (proj_clip > 0.0) {"
    },
    {
        "line": 149,
        "fullcodeline": "input_to_input_weight_ptr = input_to_input_weights->data.int8;"
    },
    {
        "line": 150,
        "fullcodeline": "recurrent_to_input_weight_ptr = recurrent_to_input_weights->data.int8;"
    },
    {
        "line": 151,
        "fullcodeline": "input_gate_bias_ptr = input_gate_bias->data.i32;"
    },
    {
        "line": 152,
        "fullcodeline": "input_to_input_weight_scale = input_to_input_weights->params.scale;"
    },
    {
        "line": 153,
        "fullcodeline": "recurrent_to_input_weight_scale = recurrent_to_input_weights->params.scale;"
    },
    {
        "line": 161,
        "fullcodeline": "cell_to_forget_weight_ptr = cell_to_forget_weights->data.int8;"
    },
    {
        "line": 162,
        "fullcodeline": "cell_to_output_weight_ptr = cell_to_output_weights->data.int8;"
    },
    {
        "line": 163,
        "fullcodeline": "cell_to_forget_weight_scale = cell_to_forget_weights->params.scale;"
    },
    {
        "line": 164,
        "fullcodeline": "cell_to_output_weight_scale = cell_to_output_weights->params.scale;"
    },
    {
        "line": 172,
        "fullcodeline": "layer_norm_forget_weight_ptr = forget_layer_norm_coefficients->data.i16;"
    },
    {
        "line": 173,
        "fullcodeline": "layer_norm_forget_scale = forget_layer_norm_coefficients->params.scale;"
    },
    {
        "line": 174,
        "fullcodeline": "layer_norm_cell_weight_ptr = cell_layer_norm_coefficients->data.i16;"
    },
    {
        "line": 175,
        "fullcodeline": "layer_norm_cell_scale = cell_layer_norm_coefficients->params.scale;"
    },
    {
        "line": 176,
        "fullcodeline": "layer_norm_output_weight_ptr = output_layer_norm_coefficients->data.i16;"
    },
    {
        "line": 177,
        "fullcodeline": "layer_norm_output_scale = output_layer_norm_coefficients->params.scale;"
    },
    {
        "line": 181,
        "fullcodeline": "projection_weight_ptr = projection_weights->data.int8;"
    },
    {
        "line": 182,
        "fullcodeline": "projection_weight_scale = projection_weights->params.scale;"
    },
    {
        "line": 212,
        "fullcodeline": "TfLiteTensor* intermediate ="
    },
    {
        "line": 214,
        "fullcodeline": "auto* params = reinterpret_cast<TfLiteAffineQuantization*>("
    },
    {
        "line": 216,
        "fullcodeline": "intermediate_scale.push_back(params->scale->data[0]);"
    },
    {
        "line": 217,
        "fullcodeline": "integer_lstm_param->intermediate_zp[i] = params->zero_point->data[0];"
    },
    {
        "line": 222,
        "fullcodeline": "effective_input_to_input_scale ="
    },
    {
        "line": 224,
        "fullcodeline": "effective_recurrent_to_input_scale = recurrent_to_input_weight_scale *"
    },
    {
        "line": 253,
        "fullcodeline": "effective_cell_to_forget_scale ="
    },
    {
        "line": 255,
        "fullcodeline": "effective_cell_to_output_scale ="
    },
    {
        "line": 359,
        "fullcodeline": "integer_lstm_param->quantized_cell_clip = static_cast<int16_t>(std::min("
    },
    {
        "line": 366,
        "fullcodeline": "integer_lstm_param->quantized_proj_clip = static_cast<int8_t>(std::min("
    },
    {
        "line": 157,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 168,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 223,
        "fullcodeline": "input_to_input_weight_scale * input_scale / intermediate_scale[1];"
    },
    {
        "line": 249,
        "fullcodeline": "if (!use_cifg) {"
    },
    {
        "line": 254,
        "fullcodeline": "std::pow(2, -15) * cell_to_forget_weight_scale / intermediate_scale[3];"
    },
    {
        "line": 256,
        "fullcodeline": "std::pow(2, -15) * cell_to_output_weight_scale / intermediate_scale[9];"
    },
    {
        "line": 363,
        "fullcodeline": "integer_lstm_param->quantized_cell_clip = 0;"
    },
    {
        "line": 369,
        "fullcodeline": "integer_lstm_param->quantized_proj_clip = 0;"
    },
    {
        "line": 158,
        "fullcodeline": "cell_to_input_weight_ptr = cell_to_input_weights->data.int8;"
    },
    {
        "line": 159,
        "fullcodeline": "cell_to_input_weight_scale = cell_to_input_weights->params.scale;"
    },
    {
        "line": 169,
        "fullcodeline": "layer_norm_input_weight_ptr = input_layer_norm_coefficients->data.i16;"
    },
    {
        "line": 170,
        "fullcodeline": "layer_norm_input_scale = input_layer_norm_coefficients->params.scale;"
    },
    {
        "line": 184,
        "fullcodeline": "projection_bias_ptr = projection_bias->data.i32;"
    },
    {
        "line": 250,
        "fullcodeline": "effective_cell_to_input_scale ="
    },
    {
        "line": 251,
        "fullcodeline": "std::pow(2, -15) * cell_to_input_weight_scale / intermediate_scale[0];"
    },
    {
        "line": 360,
        "fullcodeline": "std::max(cell_clip / cell_state_params->scale->data[0], -32768.0f),"
    },
    {
        "line": 367,
        "fullcodeline": "std::max(proj_clip / proj_params->scale->data[0], -128.0f), 127.0f));"
    }
]