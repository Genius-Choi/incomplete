[
    {
        "line": 2,
        "fullcodeline": "auto* params = reinterpret_cast<TfLitePoolParams*>(node->builtin_data);"
    },
    {
        "line": 3,
        "fullcodeline": "OpData* data = reinterpret_cast<OpData*>(node->user_data);"
    },
    {
        "line": 5,
        "fullcodeline": "TfLiteTensor* output = GetOutput(context, node, 0);"
    },
    {
        "line": 6,
        "fullcodeline": "const TfLiteTensor* input = GetInput(context, node, 0);"
    },
    {
        "line": 24,
        "fullcodeline": "TF_LITE_KERNEL_LOG(context, \"Type %s not currently supported.\","
    },
    {
        "line": 9,
        "fullcodeline": "MaxEvalFloat<kernel_type>(context, node, params, data, input, output);"
    },
    {
        "line": 12,
        "fullcodeline": "MaxEvalQuantizedUInt8<kernel_type>(context, node, params, data, input,"
    },
    {
        "line": 16,
        "fullcodeline": "MaxEvalQuantizedInt8<kernel_type>(context, node, params, data, input,"
    },
    {
        "line": 20,
        "fullcodeline": "MaxEvalQuantizedInt16<kernel_type>(context, node, params, data, input,"
    },
    {
        "line": 25,
        "fullcodeline": "TfLiteTypeGetName(input->type));"
    }
]