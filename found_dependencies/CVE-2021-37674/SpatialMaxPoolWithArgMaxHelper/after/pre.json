[
    {
        "line": 25,
        "fullcodeline": "ConstEigenMatrixMap in_mat("
    },
    {
        "line": 28,
        "fullcodeline": "EigenMatrixMap out_mat("
    },
    {
        "line": 31,
        "fullcodeline": "EigenIndexMatrixMap out_arg_max_mat("
    },
    {
        "line": 35,
        "fullcodeline": "const DeviceBase::CpuWorkerThreads& worker_threads ="
    },
    {
        "line": 48,
        "fullcodeline": "auto shard = [&params, &in_mat, &out_mat, &out_arg_max_mat, &input_backprop,"
    },
    {
        "line": 149,
        "fullcodeline": "const int64_t shard_cost = params.tensor_in_rows * params.tensor_in_cols *"
    },
    {
        "line": 5,
        "fullcodeline": "if (input_backprop != nullptr) {"
    },
    {
        "line": 16,
        "fullcodeline": "if (tensor_in.NumElements() == 0 || output->NumElements() == 0) return;"
    },
    {
        "line": 26,
        "fullcodeline": "tensor_in.flat<T>().data(), params.depth,"
    },
    {
        "line": 27,
        "fullcodeline": "params.tensor_in_cols * params.tensor_in_rows * params.tensor_in_batch);"
    },
    {
        "line": 29,
        "fullcodeline": "output->flat<T>().data(), params.depth,"
    },
    {
        "line": 30,
        "fullcodeline": "params.out_width * params.out_height * params.tensor_in_batch);"
    },
    {
        "line": 32,
        "fullcodeline": "output_arg_max->flat<Targmax>().data(), params.depth,"
    },
    {
        "line": 33,
        "fullcodeline": "params.out_width * params.out_height * params.tensor_in_batch);"
    },
    {
        "line": 6,
        "fullcodeline": "OP_REQUIRES("
    },
    {
        "line": 11,
        "fullcodeline": "OP_REQUIRES("
    },
    {
        "line": 8,
        "fullcodeline": "errors::Internal("
    },
    {
        "line": 13,
        "fullcodeline": "errors::Internal(\"SpatialMaxPoolWithArgMaxHelper requires Targmax \""
    },
    {
        "line": 36,
        "fullcodeline": "*(context->device()->tensorflow_cpu_worker_threads());"
    }
]