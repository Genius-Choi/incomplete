[
    {
        "line": 2,
        "fullcodeline": "ggml_tensor * result = ggml_new_tensor_4d(ctx, (ggml_type) tensor->type,"
    },
    {
        "line": 7,
        "fullcodeline": "result->buffer = reinterpret_cast<ggml_backend_buffer_t>(tensor->buffer);"
    },
    {
        "line": 13,
        "fullcodeline": "uint64_t tensor_size = (uint64_t) ggml_nbytes(result);"
    },
    {
        "line": 14,
        "fullcodeline": "uint64_t buffer_start = (uint64_t) ggml_backend_buffer_get_base(result->buffer);"
    },
    {
        "line": 15,
        "fullcodeline": "uint64_t buffer_size = (uint64_t) ggml_backend_buffer_get_size(result->buffer);"
    },
    {
        "line": 19,
        "fullcodeline": "result->op = (ggml_op) tensor->op;"
    },
    {
        "line": 23,
        "fullcodeline": "result->flags = tensor->flags;"
    },
    {
        "line": 24,
        "fullcodeline": "result->data = reinterpret_cast<void *>(tensor->data);"
    },
    {
        "line": 25,
        "fullcodeline": "ggml_set_name(result, tensor->name);"
    },
    {
        "line": 4,
        "fullcodeline": "for (uint32_t i = 0; i < GGML_MAX_DIMS; i++) {"
    },
    {
        "line": 8,
        "fullcodeline": "if (result->buffer && buffers.find(result->buffer) == buffers.end()) {"
    },
    {
        "line": 16,
        "fullcodeline": "GGML_ASSERT(tensor->data + tensor_size >= tensor->data); // check for overflow"
    },
    {
        "line": 17,
        "fullcodeline": "GGML_ASSERT(tensor->data >= buffer_start && tensor->data + tensor_size <= buffer_start + buffer_size);"
    },
    {
        "line": 20,
        "fullcodeline": "for (uint32_t i = 0; i < GGML_MAX_OP_PARAMS / sizeof(int32_t); i++) {"
    },
    {
        "line": 5,
        "fullcodeline": "result->nb[i] = tensor->nb[i];"
    }
]