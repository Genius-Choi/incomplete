[
    {
        "line": 3,
        "fullcodeline": "auto* params = reinterpret_cast<TfLiteConvParams*>(node->builtin_data);"
    },
    {
        "line": 4,
        "fullcodeline": "OpData* data = reinterpret_cast<OpData*>(node->user_data);"
    },
    {
        "line": 6,
        "fullcodeline": "bool has_bias = node->inputs->size == 3;"
    },
    {
        "line": 8,
        "fullcodeline": "TF_LITE_ENSURE(context, has_bias || node->inputs->size == 2);"
    },
    {
        "line": 9,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);"
    },
    {
        "line": 11,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));"
    },
    {
        "line": 13,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));"
    },
    {
        "line": 15,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &filter));"
    },
    {
        "line": 18,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input->dims->size, 4);"
    },
    {
        "line": 19,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, filter->dims->size, 4);"
    },
    {
        "line": 23,
        "fullcodeline": "auto input_channel = input->dims->data[3];"
    },
    {
        "line": 24,
        "fullcodeline": "auto filter_input_channel = filter->dims->data[3];"
    },
    {
        "line": 25,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input_channel % filter_input_channel, 0);"
    },
    {
        "line": 26,
        "fullcodeline": "data->groups = input_channel / filter_input_channel;"
    },
    {
        "line": 29,
        "fullcodeline": "TfLiteType input_type = input->type;"
    },
    {
        "line": 30,
        "fullcodeline": "TF_LITE_ENSURE(context,"
    },
    {
        "line": 33,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, output->type, input_type);"
    },
    {
        "line": 51,
        "fullcodeline": "const TfLiteTensor* bias = nullptr;"
    },
    {
        "line": 55,
        "fullcodeline": "TF_LITE_ENSURE(context, has_bias);"
    },
    {
        "line": 72,
        "fullcodeline": "const bool is_hybrid ="
    },
    {
        "line": 97,
        "fullcodeline": "data->supports_multithreaded_kernel ="
    },
    {
        "line": 104,
        "fullcodeline": "int channels_in = filter->dims->data[3];"
    },
    {
        "line": 105,
        "fullcodeline": "int channels_out = filter->dims->data[0];"
    },
    {
        "line": 106,
        "fullcodeline": "int width = input->dims->data[2];"
    },
    {
        "line": 107,
        "fullcodeline": "int height = input->dims->data[1];"
    },
    {
        "line": 108,
        "fullcodeline": "int filter_width = filter->dims->data[2];"
    },
    {
        "line": 109,
        "fullcodeline": "int filter_height = filter->dims->data[1];"
    },
    {
        "line": 110,
        "fullcodeline": "int batches = input->dims->data[0];"
    },
    {
        "line": 113,
        "fullcodeline": "auto padding = params->padding;"
    },
    {
        "line": 115,
        "fullcodeline": "data->padding = ComputePaddingHeightWidth("
    },
    {
        "line": 121,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(GetSizeOfType(context, input->type, &im2col_type_size));"
    },
    {
        "line": 124,
        "fullcodeline": "const size_t im2col_bytes = static_cast<size_t>(batches) * out_height *"
    },
    {
        "line": 127,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(AllocateTemporaryTensorsIfRequired("
    },
    {
        "line": 131,
        "fullcodeline": "TF_LITE_ENSURE(context, has_bias);"
    },
    {
        "line": 157,
        "fullcodeline": "TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);"
    },
    {
        "line": 158,
        "fullcodeline": "output_size->data[0] = batches;"
    },
    {
        "line": 159,
        "fullcodeline": "output_size->data[1] = out_height;"
    },
    {
        "line": 160,
        "fullcodeline": "output_size->data[2] = out_width;"
    },
    {
        "line": 161,
        "fullcodeline": "output_size->data[3] = channels_out;"
    },
    {
        "line": 162,
        "fullcodeline": "auto output_status = context->ResizeTensor(context, output, output_size);"
    },
    {
        "line": 31,
        "fullcodeline": "input_type == kTfLiteFloat32 || input_type == kTfLiteUInt8 ||"
    },
    {
        "line": 35,
        "fullcodeline": "if (input_type == kTfLiteInt16) {"
    },
    {
        "line": 40,
        "fullcodeline": "if (input_type == kTfLiteInt16 || input_type == kTfLiteInt8) {"
    },
    {
        "line": 73,
        "fullcodeline": "(input->type == kTfLiteFloat32 &&"
    },
    {
        "line": 76,
        "fullcodeline": "if (is_hybrid && filter->type == kTfLiteInt8 &&"
    },
    {
        "line": 98,
        "fullcodeline": "(kernel_type == kMultithreadOptimized) &&"
    },
    {
        "line": 136,
        "fullcodeline": "if (input_type != kTfLiteFloat32) {"
    },
    {
        "line": 164,
        "fullcodeline": "if (output_status != kTfLiteOk) return output_status;"
    },
    {
        "line": 32,
        "fullcodeline": "input_type == kTfLiteInt8 || input_type == kTfLiteInt16);"
    },
    {
        "line": 36,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);"
    },
    {
        "line": 37,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);"
    },
    {
        "line": 41,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, filter->quantization.type,"
    },
    {
        "line": 43,
        "fullcodeline": "const auto* affine_quantization ="
    },
    {
        "line": 58,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &bias));"
    },
    {
        "line": 69,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumElements(bias), SizeOfDimension(filter, 0));"
    },
    {
        "line": 74,
        "fullcodeline": "(filter->type == kTfLiteUInt8 || filter->type == kTfLiteInt8));"
    },
    {
        "line": 81,
        "fullcodeline": "reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params)"
    },
    {
        "line": 83,
        "fullcodeline": "const auto* affine_quantization ="
    },
    {
        "line": 86,
        "fullcodeline": "const float scale = affine_quantization->scale->data[0];"
    },
    {
        "line": 102,
        "fullcodeline": "(filter->allocation_type != kTfLiteArenaRw) && !IsDynamicTensor(filter);"
    },
    {
        "line": 137,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, filter->quantization.type,"
    },
    {
        "line": 139,
        "fullcodeline": "const auto* affine_quantization ="
    },
    {
        "line": 142,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization);"
    },
    {
        "line": 143,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization->scale);"
    },
    {
        "line": 144,
        "fullcodeline": "TF_LITE_ENSURE(context, (affine_quantization->scale->size == 1 ||"
    },
    {
        "line": 147,
        "fullcodeline": "data->per_channel_output_multiplier.resize(channels_out);"
    },
    {
        "line": 148,
        "fullcodeline": "data->per_channel_output_shift.resize(channels_out);"
    },
    {
        "line": 149,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams("
    },
    {
        "line": 169,
        "fullcodeline": "TfLiteIntArray* im2col_size = TfLiteIntArrayCreate(4);"
    },
    {
        "line": 171,
        "fullcodeline": "auto filter_input_channel = filter->dims->data[3];"
    },
    {
        "line": 177,
        "fullcodeline": "TfLiteTensor* im2col ="
    },
    {
        "line": 179,
        "fullcodeline": "im2col->type = input->type;"
    },
    {
        "line": 183,
        "fullcodeline": "im2col->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 184,
        "fullcodeline": "auto im2col_status = context->ResizeTensor(context, im2col, im2col_size);"
    },
    {
        "line": 190,
        "fullcodeline": "TfLiteIntArray* hwcn_weights_size = TfLiteIntArrayCreate(2);"
    },
    {
        "line": 196,
        "fullcodeline": "auto filter_input_channel = filter->dims->data[3];"
    },
    {
        "line": 201,
        "fullcodeline": "TfLiteTensor* hwcn_weights ="
    },
    {
        "line": 203,
        "fullcodeline": "hwcn_weights->type = input_type;"
    },
    {
        "line": 204,
        "fullcodeline": "hwcn_weights->name = \"Conv_hwcn_weights\";"
    },
    {
        "line": 205,
        "fullcodeline": "hwcn_weights->allocation_type = kTfLiteArenaRwPersistent;"
    },
    {
        "line": 207,
        "fullcodeline": "auto hwcn_weights_status ="
    },
    {
        "line": 220,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 223,
        "fullcodeline": "input_quantized->type = kTfLiteInt8;"
    },
    {
        "line": 224,
        "fullcodeline": "input_quantized->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 234,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 237,
        "fullcodeline": "scaling_factors->type = kTfLiteFloat32;"
    },
    {
        "line": 238,
        "fullcodeline": "scaling_factors->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 242,
        "fullcodeline": "TF_LITE_ENSURE(context, channels_in != 0);"
    },
    {
        "line": 243,
        "fullcodeline": "const int height = NumElements(input) / channels_in;"
    },
    {
        "line": 244,
        "fullcodeline": "int scaling_dims[1] = {height};"
    },
    {
        "line": 254,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 257,
        "fullcodeline": "accum_scratch->type = kTfLiteInt32;"
    },
    {
        "line": 258,
        "fullcodeline": "accum_scratch->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 259,
        "fullcodeline": "const int scratch_width = batches * out_height * out_width;"
    },
    {
        "line": 260,
        "fullcodeline": "int accum_scratch_dims[2] = {channels_out, scratch_width};"
    },
    {
        "line": 46,
        "fullcodeline": "for (int i = 0; i < affine_quantization->zero_point->size; ++i) {"
    },
    {
        "line": 59,
        "fullcodeline": "if (input_type == kTfLiteUInt8 || input_type == kTfLiteInt8) {"
    },
    {
        "line": 84,
        "fullcodeline": "reinterpret_cast<TfLiteAffineQuantization*>("
    },
    {
        "line": 87,
        "fullcodeline": "for (int i = 1; i < affine_quantization->scale->size; i++) {"
    },
    {
        "line": 175,
        "fullcodeline": "im2col_size->data[3] = filter_input_channel * filter_height * filter_width;"
    },
    {
        "line": 185,
        "fullcodeline": "if (im2col_status != kTfLiteOk) return im2col_status;"
    },
    {
        "line": 198,
        "fullcodeline": "(filter_height * filter_width * filter_input_channel);"
    },
    {
        "line": 208,
        "fullcodeline": "context->ResizeTensor(context, hwcn_weights, hwcn_weights_size);"
    },
    {
        "line": 209,
        "fullcodeline": "if (hwcn_weights_status != kTfLiteOk) return hwcn_weights_status;"
    },
    {
        "line": 221,
        "fullcodeline": "context, GetTemporarySafe(context, node, data->input_quantized_index,"
    },
    {
        "line": 235,
        "fullcodeline": "context, GetTemporarySafe(context, node, data->scaling_factors_index,"
    },
    {
        "line": 255,
        "fullcodeline": "GetTemporarySafe(context, node, data->accum_scratch_index,"
    },
    {
        "line": 47,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, affine_quantization->zero_point->data[i], 0);"
    },
    {
        "line": 60,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);"
    },
    {
        "line": 61,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);"
    },
    {
        "line": 79,
        "fullcodeline": "reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params)"
    },
    {
        "line": 101,
        "fullcodeline": "(params->dilation_height_factor == 1) &&"
    },
    {
        "line": 145,
        "fullcodeline": "affine_quantization->scale->size == channels_out));"
    },
    {
        "line": 153,
        "fullcodeline": "data->per_channel_output_multiplier.data(),"
    },
    {
        "line": 154,
        "fullcodeline": "data->per_channel_output_shift.data(), channels_out));"
    },
    {
        "line": 181,
        "fullcodeline": "im2col->type = filter->type;"
    },
    {
        "line": 225,
        "fullcodeline": "if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {"
    },
    {
        "line": 226,
        "fullcodeline": "TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);"
    },
    {
        "line": 227,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,"
    },
    {
        "line": 245,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {"
    },
    {
        "line": 246,
        "fullcodeline": "TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 248,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,"
    },
    {
        "line": 261,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(accum_scratch->dims, 2,"
    },
    {
        "line": 263,
        "fullcodeline": "TfLiteIntArray* accum_scratch_size = TfLiteIntArrayCreate(2);"
    },
    {
        "line": 266,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, accum_scratch,"
    },
    {
        "line": 271,
        "fullcodeline": "const auto* affine_quantization ="
    },
    {
        "line": 274,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization);"
    },
    {
        "line": 275,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization->scale);"
    },
    {
        "line": 276,
        "fullcodeline": "TF_LITE_ENSURE_EQ("
    },
    {
        "line": 281,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 284,
        "fullcodeline": "input_offsets->type = kTfLiteInt32;"
    },
    {
        "line": 285,
        "fullcodeline": "input_offsets->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 287,
        "fullcodeline": "TF_LITE_ENSURE(context, channels_in != 0);"
    },
    {
        "line": 288,
        "fullcodeline": "const int height = NumElements(input) / channels_in;"
    },
    {
        "line": 289,
        "fullcodeline": "const int input_offset_dims[1] = {height};"
    },
    {
        "line": 299,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 302,
        "fullcodeline": "row_sums->type = kTfLiteInt32;"
    },
    {
        "line": 303,
        "fullcodeline": "row_sums->name = \"Conv_row_sums\";"
    },
    {
        "line": 304,
        "fullcodeline": "row_sums->allocation_type = kTfLiteArenaRwPersistent;"
    },
    {
        "line": 306,
        "fullcodeline": "const int row_sums_dims[1] = {channels_out};"
    },
    {
        "line": 77,
        "fullcodeline": "filter->quantization.type == kTfLiteAffineQuantization &&"
    },
    {
        "line": 88,
        "fullcodeline": "if (affine_quantization->scale->data[i] != scale) {"
    },
    {
        "line": 100,
        "fullcodeline": "(params->dilation_width_factor == 1) &&"
    },
    {
        "line": 282,
        "fullcodeline": "context, GetTemporarySafe(context, node, data->input_offset_index,"
    },
    {
        "line": 301,
        "fullcodeline": "GetTemporarySafe(context, node, data->row_sums_index, &row_sums));"
    },
    {
        "line": 62,
        "fullcodeline": "} else if (input_type == kTfLiteInt16) {"
    },
    {
        "line": 89,
        "fullcodeline": "data->is_hybrid_per_channel = true;"
    },
    {
        "line": 99,
        "fullcodeline": "(context->recommended_num_threads != 1) && !is_hybrid &&"
    },
    {
        "line": 290,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1,"
    },
    {
        "line": 292,
        "fullcodeline": "TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 294,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,"
    },
    {
        "line": 307,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {"
    },
    {
        "line": 308,
        "fullcodeline": "TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 63,
        "fullcodeline": "TF_LITE_ENSURE(context, (bias->type == kTfLiteInt32) ||"
    },
    {
        "line": 65,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);"
    },
    {
        "line": 311,
        "fullcodeline": "context, context->ResizeTensor(context, row_sums, row_sums_size));"
    },
    {
        "line": 67,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, bias->type, input_type);"
    },
    {
        "line": 64,
        "fullcodeline": "(bias->type == kTfLiteInt64));"
    }
]