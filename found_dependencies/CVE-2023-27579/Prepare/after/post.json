[
    {
        "line": 3,
        "fullcodeline": "auto* params = reinterpret_cast<TfLiteConvParams*>(node->builtin_data);"
    },
    {
        "line": 4,
        "fullcodeline": "OpData* data = reinterpret_cast<OpData*>(node->user_data);"
    },
    {
        "line": 6,
        "fullcodeline": "bool has_bias = node->inputs->size == 3;"
    },
    {
        "line": 8,
        "fullcodeline": "TF_LITE_ENSURE(context, has_bias || node->inputs->size == 2);"
    },
    {
        "line": 9,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);"
    },
    {
        "line": 11,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));"
    },
    {
        "line": 13,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));"
    },
    {
        "line": 15,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &filter));"
    },
    {
        "line": 18,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input->dims->size, 4);"
    },
    {
        "line": 19,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, filter->dims->size, 4);"
    },
    {
        "line": 25,
        "fullcodeline": "TF_LITE_ENSURE(context, filter_input_channel > 0);"
    },
    {
        "line": 26,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input_channel % filter_input_channel, 0);"
    },
    {
        "line": 27,
        "fullcodeline": "data->groups = input_channel / filter_input_channel;"
    },
    {
        "line": 30,
        "fullcodeline": "TfLiteType input_type = input->type;"
    },
    {
        "line": 31,
        "fullcodeline": "TF_LITE_ENSURE(context,"
    },
    {
        "line": 34,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, output->type, input_type);"
    },
    {
        "line": 52,
        "fullcodeline": "const TfLiteTensor* bias = nullptr;"
    },
    {
        "line": 56,
        "fullcodeline": "TF_LITE_ENSURE(context, has_bias);"
    },
    {
        "line": 73,
        "fullcodeline": "const bool is_hybrid ="
    },
    {
        "line": 98,
        "fullcodeline": "data->supports_multithreaded_kernel ="
    },
    {
        "line": 114,
        "fullcodeline": "auto padding = params->padding;"
    },
    {
        "line": 116,
        "fullcodeline": "data->padding = ComputePaddingHeightWidth("
    },
    {
        "line": 122,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(GetSizeOfType(context, input->type, &im2col_type_size));"
    },
    {
        "line": 125,
        "fullcodeline": "const size_t im2col_bytes = static_cast<size_t>(batches) * out_height *"
    },
    {
        "line": 128,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(AllocateTemporaryTensorsIfRequired("
    },
    {
        "line": 132,
        "fullcodeline": "TF_LITE_ENSURE(context, has_bias);"
    },
    {
        "line": 158,
        "fullcodeline": "TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);"
    },
    {
        "line": 159,
        "fullcodeline": "output_size->data[0] = batches;"
    },
    {
        "line": 160,
        "fullcodeline": "output_size->data[1] = out_height;"
    },
    {
        "line": 161,
        "fullcodeline": "output_size->data[2] = out_width;"
    },
    {
        "line": 162,
        "fullcodeline": "output_size->data[3] = channels_out;"
    },
    {
        "line": 163,
        "fullcodeline": "auto output_status = context->ResizeTensor(context, output, output_size);"
    },
    {
        "line": 32,
        "fullcodeline": "input_type == kTfLiteFloat32 || input_type == kTfLiteUInt8 ||"
    },
    {
        "line": 36,
        "fullcodeline": "if (input_type == kTfLiteInt16) {"
    },
    {
        "line": 41,
        "fullcodeline": "if (input_type == kTfLiteInt16 || input_type == kTfLiteInt8) {"
    },
    {
        "line": 74,
        "fullcodeline": "(input->type == kTfLiteFloat32 &&"
    },
    {
        "line": 77,
        "fullcodeline": "if (is_hybrid && filter->type == kTfLiteInt8 &&"
    },
    {
        "line": 99,
        "fullcodeline": "(kernel_type == kMultithreadOptimized) &&"
    },
    {
        "line": 137,
        "fullcodeline": "if (input_type != kTfLiteFloat32) {"
    },
    {
        "line": 165,
        "fullcodeline": "if (output_status != kTfLiteOk) return output_status;"
    },
    {
        "line": 33,
        "fullcodeline": "input_type == kTfLiteInt8 || input_type == kTfLiteInt16);"
    },
    {
        "line": 37,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);"
    },
    {
        "line": 38,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);"
    },
    {
        "line": 42,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, filter->quantization.type,"
    },
    {
        "line": 59,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &bias));"
    },
    {
        "line": 70,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumElements(bias), SizeOfDimension(filter, 0));"
    },
    {
        "line": 75,
        "fullcodeline": "(filter->type == kTfLiteUInt8 || filter->type == kTfLiteInt8));"
    },
    {
        "line": 82,
        "fullcodeline": "reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params)"
    },
    {
        "line": 84,
        "fullcodeline": "const auto* affine_quantization ="
    },
    {
        "line": 103,
        "fullcodeline": "(filter->allocation_type != kTfLiteArenaRw) && !IsDynamicTensor(filter);"
    },
    {
        "line": 138,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, filter->quantization.type,"
    },
    {
        "line": 140,
        "fullcodeline": "const auto* affine_quantization ="
    },
    {
        "line": 143,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization);"
    },
    {
        "line": 144,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization->scale);"
    },
    {
        "line": 145,
        "fullcodeline": "TF_LITE_ENSURE(context, (affine_quantization->scale->size == 1 ||"
    },
    {
        "line": 148,
        "fullcodeline": "data->per_channel_output_multiplier.resize(channels_out);"
    },
    {
        "line": 149,
        "fullcodeline": "data->per_channel_output_shift.resize(channels_out);"
    },
    {
        "line": 150,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams("
    },
    {
        "line": 168,
        "fullcodeline": "node->temporaries->data[data->im2col_index] = data->im2col_id;"
    },
    {
        "line": 170,
        "fullcodeline": "TfLiteIntArray* im2col_size = TfLiteIntArrayCreate(4);"
    },
    {
        "line": 173,
        "fullcodeline": "im2col_size->data[0] = output_size->data[0];"
    },
    {
        "line": 174,
        "fullcodeline": "im2col_size->data[1] = output_size->data[1];"
    },
    {
        "line": 175,
        "fullcodeline": "im2col_size->data[2] = output_size->data[2];"
    },
    {
        "line": 176,
        "fullcodeline": "im2col_size->data[3] = filter_input_channel * filter_height * filter_width;"
    },
    {
        "line": 180,
        "fullcodeline": "im2col->type = input->type;"
    },
    {
        "line": 184,
        "fullcodeline": "im2col->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 185,
        "fullcodeline": "auto im2col_status = context->ResizeTensor(context, im2col, im2col_size);"
    },
    {
        "line": 190,
        "fullcodeline": "node->temporaries->data[data->hwcn_weights_index] = data->hwcn_weights_id;"
    },
    {
        "line": 191,
        "fullcodeline": "TfLiteIntArray* hwcn_weights_size = TfLiteIntArrayCreate(2);"
    },
    {
        "line": 198,
        "fullcodeline": "hwcn_weights_size->data[0] ="
    },
    {
        "line": 200,
        "fullcodeline": "hwcn_weights_size->data[1] = channels_out;"
    },
    {
        "line": 204,
        "fullcodeline": "hwcn_weights->type = input_type;"
    },
    {
        "line": 205,
        "fullcodeline": "hwcn_weights->name = \"Conv_hwcn_weights\";"
    },
    {
        "line": 206,
        "fullcodeline": "hwcn_weights->allocation_type = kTfLiteArenaRwPersistent;"
    },
    {
        "line": 208,
        "fullcodeline": "auto hwcn_weights_status ="
    },
    {
        "line": 214,
        "fullcodeline": "data->have_weights_been_transposed = false;"
    },
    {
        "line": 218,
        "fullcodeline": "node->temporaries->data[data->input_quantized_index] ="
    },
    {
        "line": 221,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 224,
        "fullcodeline": "input_quantized->type = kTfLiteInt8;"
    },
    {
        "line": 225,
        "fullcodeline": "input_quantized->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 232,
        "fullcodeline": "node->temporaries->data[data->scaling_factors_index] ="
    },
    {
        "line": 235,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 238,
        "fullcodeline": "scaling_factors->type = kTfLiteFloat32;"
    },
    {
        "line": 239,
        "fullcodeline": "scaling_factors->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 243,
        "fullcodeline": "TF_LITE_ENSURE(context, channels_in != 0);"
    },
    {
        "line": 244,
        "fullcodeline": "const int height = NumElements(input) / channels_in;"
    },
    {
        "line": 245,
        "fullcodeline": "int scaling_dims[1] = {height};"
    },
    {
        "line": 253,
        "fullcodeline": "node->temporaries->data[data->accum_scratch_index] = data->accum_scratch_id;"
    },
    {
        "line": 255,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 258,
        "fullcodeline": "accum_scratch->type = kTfLiteInt32;"
    },
    {
        "line": 259,
        "fullcodeline": "accum_scratch->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 260,
        "fullcodeline": "const int scratch_width = batches * out_height * out_width;"
    },
    {
        "line": 261,
        "fullcodeline": "int accum_scratch_dims[2] = {channels_out, scratch_width};"
    },
    {
        "line": 47,
        "fullcodeline": "for (int i = 0; i < affine_quantization->zero_point->size; ++i) {"
    },
    {
        "line": 60,
        "fullcodeline": "if (input_type == kTfLiteUInt8 || input_type == kTfLiteInt8) {"
    },
    {
        "line": 85,
        "fullcodeline": "reinterpret_cast<TfLiteAffineQuantization*>("
    },
    {
        "line": 88,
        "fullcodeline": "for (int i = 1; i < affine_quantization->scale->size; i++) {"
    },
    {
        "line": 141,
        "fullcodeline": "reinterpret_cast<TfLiteAffineQuantization*>("
    },
    {
        "line": 186,
        "fullcodeline": "if (im2col_status != kTfLiteOk) return im2col_status;"
    },
    {
        "line": 199,
        "fullcodeline": "(filter_height * filter_width * filter_input_channel);"
    },
    {
        "line": 209,
        "fullcodeline": "context->ResizeTensor(context, hwcn_weights, hwcn_weights_size);"
    },
    {
        "line": 210,
        "fullcodeline": "if (hwcn_weights_status != kTfLiteOk) return hwcn_weights_status;"
    },
    {
        "line": 222,
        "fullcodeline": "context, GetTemporarySafe(context, node, data->input_quantized_index,"
    },
    {
        "line": 226,
        "fullcodeline": "if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {"
    },
    {
        "line": 236,
        "fullcodeline": "context, GetTemporarySafe(context, node, data->scaling_factors_index,"
    },
    {
        "line": 246,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {"
    },
    {
        "line": 256,
        "fullcodeline": "GetTemporarySafe(context, node, data->accum_scratch_index,"
    },
    {
        "line": 262,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(accum_scratch->dims, 2,"
    },
    {
        "line": 48,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, affine_quantization->zero_point->data[i], 0);"
    },
    {
        "line": 61,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);"
    },
    {
        "line": 62,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);"
    },
    {
        "line": 80,
        "fullcodeline": "reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params)"
    },
    {
        "line": 102,
        "fullcodeline": "(params->dilation_height_factor == 1) &&"
    },
    {
        "line": 146,
        "fullcodeline": "affine_quantization->scale->size == channels_out));"
    },
    {
        "line": 154,
        "fullcodeline": "data->per_channel_output_multiplier.data(),"
    },
    {
        "line": 155,
        "fullcodeline": "data->per_channel_output_shift.data(), channels_out));"
    },
    {
        "line": 182,
        "fullcodeline": "im2col->type = filter->type;"
    },
    {
        "line": 227,
        "fullcodeline": "TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);"
    },
    {
        "line": 228,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,"
    },
    {
        "line": 247,
        "fullcodeline": "TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 248,
        "fullcodeline": "scaling_factors_size->data[0] = height;"
    },
    {
        "line": 249,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,"
    },
    {
        "line": 264,
        "fullcodeline": "TfLiteIntArray* accum_scratch_size = TfLiteIntArrayCreate(2);"
    },
    {
        "line": 265,
        "fullcodeline": "accum_scratch_size->data[0] = channels_out;"
    },
    {
        "line": 266,
        "fullcodeline": "accum_scratch_size->data[1] = scratch_width;"
    },
    {
        "line": 267,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, accum_scratch,"
    },
    {
        "line": 272,
        "fullcodeline": "const auto* affine_quantization ="
    },
    {
        "line": 275,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization);"
    },
    {
        "line": 276,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization->scale);"
    },
    {
        "line": 277,
        "fullcodeline": "TF_LITE_ENSURE_EQ("
    },
    {
        "line": 280,
        "fullcodeline": "node->temporaries->data[data->input_offset_index] = data->input_offset_id;"
    },
    {
        "line": 282,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 285,
        "fullcodeline": "input_offsets->type = kTfLiteInt32;"
    },
    {
        "line": 286,
        "fullcodeline": "input_offsets->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 288,
        "fullcodeline": "TF_LITE_ENSURE(context, channels_in != 0);"
    },
    {
        "line": 289,
        "fullcodeline": "const int height = NumElements(input) / channels_in;"
    },
    {
        "line": 290,
        "fullcodeline": "const int input_offset_dims[1] = {height};"
    },
    {
        "line": 298,
        "fullcodeline": "node->temporaries->data[data->row_sums_index] = data->row_sums_id;"
    },
    {
        "line": 300,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 303,
        "fullcodeline": "row_sums->type = kTfLiteInt32;"
    },
    {
        "line": 304,
        "fullcodeline": "row_sums->name = \"Conv_row_sums\";"
    },
    {
        "line": 305,
        "fullcodeline": "row_sums->allocation_type = kTfLiteArenaRwPersistent;"
    },
    {
        "line": 307,
        "fullcodeline": "const int row_sums_dims[1] = {channels_out};"
    },
    {
        "line": 78,
        "fullcodeline": "filter->quantization.type == kTfLiteAffineQuantization &&"
    },
    {
        "line": 89,
        "fullcodeline": "if (affine_quantization->scale->data[i] != scale) {"
    },
    {
        "line": 101,
        "fullcodeline": "(params->dilation_width_factor == 1) &&"
    },
    {
        "line": 273,
        "fullcodeline": "reinterpret_cast<TfLiteAffineQuantization*>("
    },
    {
        "line": 283,
        "fullcodeline": "context, GetTemporarySafe(context, node, data->input_offset_index,"
    },
    {
        "line": 291,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1,"
    },
    {
        "line": 302,
        "fullcodeline": "GetTemporarySafe(context, node, data->row_sums_index, &row_sums));"
    },
    {
        "line": 308,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {"
    },
    {
        "line": 63,
        "fullcodeline": "} else if (input_type == kTfLiteInt16) {"
    },
    {
        "line": 90,
        "fullcodeline": "data->is_hybrid_per_channel = true;"
    },
    {
        "line": 100,
        "fullcodeline": "(context->recommended_num_threads != 1) && !is_hybrid &&"
    },
    {
        "line": 293,
        "fullcodeline": "TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 294,
        "fullcodeline": "input_offsets_size->data[0] = input_offset_dims[0];"
    },
    {
        "line": 295,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,"
    },
    {
        "line": 309,
        "fullcodeline": "TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 310,
        "fullcodeline": "row_sums_size->data[0] = row_sums_dims[0];"
    },
    {
        "line": 311,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 64,
        "fullcodeline": "TF_LITE_ENSURE(context, (bias->type == kTfLiteInt32) ||"
    },
    {
        "line": 66,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);"
    },
    {
        "line": 312,
        "fullcodeline": "context, context->ResizeTensor(context, row_sums, row_sums_size));"
    },
    {
        "line": 68,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, bias->type, input_type);"
    },
    {
        "line": 65,
        "fullcodeline": "(bias->type == kTfLiteInt64));"
    }
]