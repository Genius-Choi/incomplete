[
    {
        "line": 7,
        "fullcodeline": "TfLiteStatus status = kTfLiteOk;"
    },
    {
        "line": 2,
        "fullcodeline": "if (!consistent_) {"
    },
    {
        "line": 8,
        "fullcodeline": "if (state_ == kStateUninvokable) {"
    },
    {
        "line": 17,
        "fullcodeline": "if (should_apply_nnapi_delegate_ && !applied_nnapi_delegate_) {"
    },
    {
        "line": 28,
        "fullcodeline": "execution_plan_index < execution_plan_.size(); execution_plan_index++) {"
    },
    {
        "line": 3,
        "fullcodeline": "ReportError(\"Invoke called on model that is not consistent.\");"
    },
    {
        "line": 9,
        "fullcodeline": "ReportError(\"Invoke called on model that is not ready.\");"
    },
    {
        "line": 18,
        "fullcodeline": "TF_LITE_ENSURE_OK(&context_, ModifyGraphWithDelegate(NnApiDelegate()));"
    },
    {
        "line": 20,
        "fullcodeline": "applied_nnapi_delegate_ = true;"
    },
    {
        "line": 27,
        "fullcodeline": "for (int execution_plan_index = 0;"
    },
    {
        "line": 34,
        "fullcodeline": "int node_index = execution_plan_[execution_plan_index];"
    },
    {
        "line": 39,
        "fullcodeline": "const char* op_name = nullptr;"
    },
    {
        "line": 41,
        "fullcodeline": "TFLITE_SCOPED_TAGGED_OPERATOR_PROFILE(profiler_.get(), op_name, node_index);"
    },
    {
        "line": 65,
        "fullcodeline": "EnsureTensorsVectorCapacity();"
    },
    {
        "line": 66,
        "fullcodeline": "tensor_resized_since_op_invoke_ = false;"
    },
    {
        "line": 29,
        "fullcodeline": "if (execution_plan_index == next_execution_plan_index_to_prepare_) {"
    },
    {
        "line": 47,
        "fullcodeline": "for (int i = 0; i < node.inputs->size; ++i) {"
    },
    {
        "line": 59,
        "fullcodeline": "if (check_cancelled_func_ != nullptr &&"
    },
    {
        "line": 67,
        "fullcodeline": "if (OpInvoke(registration, &node) != kTfLiteOk) {"
    },
    {
        "line": 74,
        "fullcodeline": "if (tensor_resized_since_op_invoke_ &&"
    },
    {
        "line": 11,
        "fullcodeline": "} else if (memory_planner_ && !memory_planner_->HasNonPersistentMemory()) {"
    },
    {
        "line": 31,
        "fullcodeline": "TF_LITE_ENSURE(&context_, next_execution_plan_index_to_prepare_ >="
    },
    {
        "line": 40,
        "fullcodeline": "if (profiler_) op_name = GetTFLiteOpName(registration);"
    },
    {
        "line": 60,
        "fullcodeline": "check_cancelled_func_(cancellation_data_)) {"
    },
    {
        "line": 61,
        "fullcodeline": "ReportError(\"Client requested cancel during Invoke()\");"
    },
    {
        "line": 75,
        "fullcodeline": "HasDynamicTensor(context_, node.outputs)) {"
    },
    {
        "line": 76,
        "fullcodeline": "next_execution_plan_index_to_prepare_ = execution_plan_index + 1;"
    },
    {
        "line": 12,
        "fullcodeline": "ReportError(\"Non-persistent memory is not available.\");"
    },
    {
        "line": 49,
        "fullcodeline": "if (tensor_index == kTfLiteOptionalTensor) {"
    },
    {
        "line": 53,
        "fullcodeline": "if (tensor->delegate && tensor->delegate != node.delegate &&"
    },
    {
        "line": 68,
        "fullcodeline": "return ReportOpError(&context_, node, registration, node_index,"
    },
    {
        "line": 81,
        "fullcodeline": "if (next_execution_plan_index_to_plan_allocation_ >"
    },
    {
        "line": 55,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(EnsureTensorDataIsReadable(tensor_index));"
    },
    {
        "line": 83,
        "fullcodeline": "next_execution_plan_index_to_plan_allocation_ ="
    },
    {
        "line": 86,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(memory_planner_->ResetAllocationsAfter("
    },
    {
        "line": 87,
        "fullcodeline": "next_execution_plan_index_to_plan_allocation_ - 1));"
    }
]