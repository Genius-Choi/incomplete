[
    {
        "line": 3,
        "fullcodeline": "auto* params = reinterpret_cast<TfLiteConvParams*>(node->builtin_data);"
    },
    {
        "line": 4,
        "fullcodeline": "OpData* data = reinterpret_cast<OpData*>(node->user_data);"
    },
    {
        "line": 6,
        "fullcodeline": "bool has_bias = node->inputs->size == 3;"
    },
    {
        "line": 8,
        "fullcodeline": "TF_LITE_ENSURE(context, has_bias || node->inputs->size == 2);"
    },
    {
        "line": 9,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);"
    },
    {
        "line": 11,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));"
    },
    {
        "line": 13,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));"
    },
    {
        "line": 15,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &filter));"
    },
    {
        "line": 18,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input->dims->size, 4);"
    },
    {
        "line": 19,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, filter->dims->size, 4);"
    },
    {
        "line": 21,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input->dims->data[3], filter->dims->data[3]);"
    },
    {
        "line": 24,
        "fullcodeline": "TfLiteType input_type = input->type;"
    },
    {
        "line": 25,
        "fullcodeline": "TF_LITE_ENSURE(context,"
    },
    {
        "line": 28,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, output->type, input_type);"
    },
    {
        "line": 35,
        "fullcodeline": "const TfLiteTensor* bias = nullptr;"
    },
    {
        "line": 39,
        "fullcodeline": "TF_LITE_ENSURE(context, has_bias);"
    },
    {
        "line": 55,
        "fullcodeline": "const bool is_hybrid ="
    },
    {
        "line": 80,
        "fullcodeline": "data->supports_multithreaded_kernel ="
    },
    {
        "line": 87,
        "fullcodeline": "int channels_in = filter->dims->data[3];"
    },
    {
        "line": 88,
        "fullcodeline": "int channels_out = filter->dims->data[0];"
    },
    {
        "line": 89,
        "fullcodeline": "int width = input->dims->data[2];"
    },
    {
        "line": 90,
        "fullcodeline": "int height = input->dims->data[1];"
    },
    {
        "line": 91,
        "fullcodeline": "int filter_width = filter->dims->data[2];"
    },
    {
        "line": 92,
        "fullcodeline": "int filter_height = filter->dims->data[1];"
    },
    {
        "line": 93,
        "fullcodeline": "int batches = input->dims->data[0];"
    },
    {
        "line": 96,
        "fullcodeline": "auto padding = params->padding;"
    },
    {
        "line": 98,
        "fullcodeline": "data->padding = ComputePaddingHeightWidth("
    },
    {
        "line": 104,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(GetSizeOfType(context, input->type, &im2col_type_size));"
    },
    {
        "line": 105,
        "fullcodeline": "const size_t im2col_bytes = batches * out_height * out_width * channels_in *"
    },
    {
        "line": 107,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(AllocateTemporaryTensorsIfRequired("
    },
    {
        "line": 111,
        "fullcodeline": "TF_LITE_ENSURE(context, has_bias);"
    },
    {
        "line": 137,
        "fullcodeline": "TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);"
    },
    {
        "line": 138,
        "fullcodeline": "output_size->data[0] = batches;"
    },
    {
        "line": 139,
        "fullcodeline": "output_size->data[1] = out_height;"
    },
    {
        "line": 140,
        "fullcodeline": "output_size->data[2] = out_width;"
    },
    {
        "line": 141,
        "fullcodeline": "output_size->data[3] = channels_out;"
    },
    {
        "line": 142,
        "fullcodeline": "auto output_status = context->ResizeTensor(context, output, output_size);"
    },
    {
        "line": 26,
        "fullcodeline": "input_type == kTfLiteFloat32 || input_type == kTfLiteUInt8 ||"
    },
    {
        "line": 30,
        "fullcodeline": "if (input_type == kTfLiteInt16) {"
    },
    {
        "line": 56,
        "fullcodeline": "(input->type == kTfLiteFloat32 &&"
    },
    {
        "line": 59,
        "fullcodeline": "if (is_hybrid && filter->type == kTfLiteInt8 &&"
    },
    {
        "line": 81,
        "fullcodeline": "(kernel_type == kMultithreadOptimized) &&"
    },
    {
        "line": 116,
        "fullcodeline": "if (input_type != kTfLiteFloat32) {"
    },
    {
        "line": 144,
        "fullcodeline": "if (output_status != kTfLiteOk) return output_status;"
    },
    {
        "line": 27,
        "fullcodeline": "input_type == kTfLiteInt8 || input_type == kTfLiteInt16);"
    },
    {
        "line": 31,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);"
    },
    {
        "line": 32,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);"
    },
    {
        "line": 42,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &bias));"
    },
    {
        "line": 52,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumElements(bias), SizeOfDimension(filter, 0));"
    },
    {
        "line": 57,
        "fullcodeline": "(filter->type == kTfLiteUInt8 || filter->type == kTfLiteInt8));"
    },
    {
        "line": 64,
        "fullcodeline": "reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params)"
    },
    {
        "line": 66,
        "fullcodeline": "const auto* affine_quantization ="
    },
    {
        "line": 69,
        "fullcodeline": "const float scale = affine_quantization->scale->data[0];"
    },
    {
        "line": 85,
        "fullcodeline": "(filter->allocation_type != kTfLiteArenaRw) && !IsDynamicTensor(filter);"
    },
    {
        "line": 117,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, filter->quantization.type,"
    },
    {
        "line": 119,
        "fullcodeline": "const auto* affine_quantization ="
    },
    {
        "line": 122,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization);"
    },
    {
        "line": 123,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization->scale);"
    },
    {
        "line": 124,
        "fullcodeline": "TF_LITE_ENSURE(context, (affine_quantization->scale->size == 1 ||"
    },
    {
        "line": 127,
        "fullcodeline": "data->per_channel_output_multiplier.resize(channels_out);"
    },
    {
        "line": 128,
        "fullcodeline": "data->per_channel_output_shift.resize(channels_out);"
    },
    {
        "line": 129,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams("
    },
    {
        "line": 149,
        "fullcodeline": "TfLiteIntArray* im2col_size = TfLiteIntArrayCreate(4);"
    },
    {
        "line": 151,
        "fullcodeline": "int input_depth = input->dims->data[3];"
    },
    {
        "line": 157,
        "fullcodeline": "TfLiteTensor* im2col ="
    },
    {
        "line": 159,
        "fullcodeline": "im2col->type = input->type;"
    },
    {
        "line": 163,
        "fullcodeline": "im2col->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 164,
        "fullcodeline": "auto im2col_status = context->ResizeTensor(context, im2col, im2col_size);"
    },
    {
        "line": 170,
        "fullcodeline": "TfLiteIntArray* hwcn_weights_size = TfLiteIntArrayCreate(2);"
    },
    {
        "line": 176,
        "fullcodeline": "int input_depth = input->dims->data[3];"
    },
    {
        "line": 180,
        "fullcodeline": "TfLiteTensor* hwcn_weights ="
    },
    {
        "line": 182,
        "fullcodeline": "hwcn_weights->type = input_type;"
    },
    {
        "line": 183,
        "fullcodeline": "hwcn_weights->allocation_type = kTfLiteArenaRwPersistent;"
    },
    {
        "line": 185,
        "fullcodeline": "auto hwcn_weights_status ="
    },
    {
        "line": 198,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 201,
        "fullcodeline": "input_quantized->type = kTfLiteInt8;"
    },
    {
        "line": 202,
        "fullcodeline": "input_quantized->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 212,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 215,
        "fullcodeline": "scaling_factors->type = kTfLiteFloat32;"
    },
    {
        "line": 216,
        "fullcodeline": "scaling_factors->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 220,
        "fullcodeline": "TF_LITE_ENSURE(context, channels_in != 0);"
    },
    {
        "line": 221,
        "fullcodeline": "const int height = NumElements(input) / channels_in;"
    },
    {
        "line": 222,
        "fullcodeline": "int scaling_dims[1] = {height};"
    },
    {
        "line": 232,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 235,
        "fullcodeline": "accum_scratch->type = kTfLiteInt32;"
    },
    {
        "line": 236,
        "fullcodeline": "accum_scratch->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 237,
        "fullcodeline": "const int scratch_width = batches * out_height * out_width;"
    },
    {
        "line": 238,
        "fullcodeline": "int accum_scratch_dims[2] = {channels_out, scratch_width};"
    },
    {
        "line": 43,
        "fullcodeline": "if (input_type == kTfLiteUInt8 || input_type == kTfLiteInt8) {"
    },
    {
        "line": 67,
        "fullcodeline": "reinterpret_cast<TfLiteAffineQuantization*>("
    },
    {
        "line": 70,
        "fullcodeline": "for (int i = 1; i < affine_quantization->scale->size; i++) {"
    },
    {
        "line": 155,
        "fullcodeline": "im2col_size->data[3] = input_depth * filter_height * filter_width;"
    },
    {
        "line": 165,
        "fullcodeline": "if (im2col_status != kTfLiteOk) return im2col_status;"
    },
    {
        "line": 177,
        "fullcodeline": "hwcn_weights_size->data[0] = (filter_height * filter_width * input_depth);"
    },
    {
        "line": 186,
        "fullcodeline": "context->ResizeTensor(context, hwcn_weights, hwcn_weights_size);"
    },
    {
        "line": 187,
        "fullcodeline": "if (hwcn_weights_status != kTfLiteOk) return hwcn_weights_status;"
    },
    {
        "line": 199,
        "fullcodeline": "context, GetTemporarySafe(context, node, data->input_quantized_index,"
    },
    {
        "line": 213,
        "fullcodeline": "context, GetTemporarySafe(context, node, data->scaling_factors_index,"
    },
    {
        "line": 233,
        "fullcodeline": "GetTemporarySafe(context, node, data->accum_scratch_index,"
    },
    {
        "line": 44,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);"
    },
    {
        "line": 45,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);"
    },
    {
        "line": 62,
        "fullcodeline": "reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params)"
    },
    {
        "line": 84,
        "fullcodeline": "(params->dilation_height_factor == 1) &&"
    },
    {
        "line": 125,
        "fullcodeline": "affine_quantization->scale->size == channels_out));"
    },
    {
        "line": 133,
        "fullcodeline": "data->per_channel_output_multiplier.data(),"
    },
    {
        "line": 134,
        "fullcodeline": "data->per_channel_output_shift.data(), channels_out));"
    },
    {
        "line": 161,
        "fullcodeline": "im2col->type = filter->type;"
    },
    {
        "line": 203,
        "fullcodeline": "if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {"
    },
    {
        "line": 204,
        "fullcodeline": "TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);"
    },
    {
        "line": 205,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,"
    },
    {
        "line": 223,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {"
    },
    {
        "line": 224,
        "fullcodeline": "TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 226,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,"
    },
    {
        "line": 239,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(accum_scratch->dims, 2,"
    },
    {
        "line": 241,
        "fullcodeline": "TfLiteIntArray* accum_scratch_size = TfLiteIntArrayCreate(2);"
    },
    {
        "line": 244,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, accum_scratch,"
    },
    {
        "line": 252,
        "fullcodeline": "TF_LITE_ENSURE_EQ("
    },
    {
        "line": 257,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 260,
        "fullcodeline": "input_offsets->type = kTfLiteInt32;"
    },
    {
        "line": 261,
        "fullcodeline": "input_offsets->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 263,
        "fullcodeline": "TF_LITE_ENSURE(context, channels_in != 0);"
    },
    {
        "line": 264,
        "fullcodeline": "const int height = NumElements(input) / channels_in;"
    },
    {
        "line": 265,
        "fullcodeline": "const int input_offset_dims[1] = {height};"
    },
    {
        "line": 275,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 278,
        "fullcodeline": "row_sums->type = kTfLiteInt32;"
    },
    {
        "line": 279,
        "fullcodeline": "row_sums->allocation_type = kTfLiteArenaRwPersistent;"
    },
    {
        "line": 281,
        "fullcodeline": "const int row_sums_dims[1] = {channels_out};"
    },
    {
        "line": 60,
        "fullcodeline": "filter->quantization.type == kTfLiteAffineQuantization &&"
    },
    {
        "line": 71,
        "fullcodeline": "if (affine_quantization->scale->data[i] != scale) {"
    },
    {
        "line": 83,
        "fullcodeline": "(params->dilation_width_factor == 1) &&"
    },
    {
        "line": 258,
        "fullcodeline": "context, GetTemporarySafe(context, node, data->input_offset_index,"
    },
    {
        "line": 277,
        "fullcodeline": "GetTemporarySafe(context, node, data->row_sums_index, &row_sums));"
    },
    {
        "line": 46,
        "fullcodeline": "} else if (input_type == kTfLiteInt16) {"
    },
    {
        "line": 72,
        "fullcodeline": "data->is_hybrid_per_channel = true;"
    },
    {
        "line": 82,
        "fullcodeline": "(context->recommended_num_threads != 1) && !is_hybrid &&"
    },
    {
        "line": 266,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1,"
    },
    {
        "line": 268,
        "fullcodeline": "TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 270,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,"
    },
    {
        "line": 282,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {"
    },
    {
        "line": 283,
        "fullcodeline": "TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 47,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt64);"
    },
    {
        "line": 48,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);"
    },
    {
        "line": 286,
        "fullcodeline": "context, context->ResizeTensor(context, row_sums, row_sums_size));"
    },
    {
        "line": 50,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, bias->type, input_type);"
    }
]