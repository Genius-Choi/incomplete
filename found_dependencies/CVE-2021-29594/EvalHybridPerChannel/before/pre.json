[
    {
        "line": 8,
        "fullcodeline": "CalculateActivationRange(params->activation, &output_activation_min,"
    },
    {
        "line": 11,
        "fullcodeline": "const int input_size = NumElements(input) / SizeOfDimension(input, 0);"
    },
    {
        "line": 12,
        "fullcodeline": "const int batch_size = SizeOfDimension(input, 0);"
    },
    {
        "line": 14,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 17,
        "fullcodeline": "int8_t* quantized_input_ptr_batch ="
    },
    {
        "line": 20,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 23,
        "fullcodeline": "float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);"
    },
    {
        "line": 25,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 28,
        "fullcodeline": "int32_t* input_offset_ptr = GetTensorData<int32_t>(input_offset_tensor);"
    },
    {
        "line": 38,
        "fullcodeline": "int8_t* im2col_ptr = nullptr;"
    },
    {
        "line": 39,
        "fullcodeline": "int8_t* filter_ptr = nullptr;"
    },
    {
        "line": 43,
        "fullcodeline": "filter_ptr = filter->data.int8;"
    },
    {
        "line": 44,
        "fullcodeline": "const auto* affine_quantization ="
    },
    {
        "line": 47,
        "fullcodeline": "KernelType effective_kernel_type = kernel_type;"
    },
    {
        "line": 56,
        "fullcodeline": "op_params.padding_type = PaddingType::kSame;"
    },
    {
        "line": 57,
        "fullcodeline": "op_params.padding_values.width = data->padding.width;"
    },
    {
        "line": 58,
        "fullcodeline": "op_params.padding_values.height = data->padding.height;"
    },
    {
        "line": 59,
        "fullcodeline": "op_params.dilation_width_factor = params->dilation_width_factor;"
    },
    {
        "line": 60,
        "fullcodeline": "op_params.dilation_height_factor = params->dilation_height_factor;"
    },
    {
        "line": 61,
        "fullcodeline": "op_params.stride_width = params->stride_width;"
    },
    {
        "line": 62,
        "fullcodeline": "op_params.stride_height = params->stride_height;"
    },
    {
        "line": 63,
        "fullcodeline": "op_params.float_activation_min = output_activation_min;"
    },
    {
        "line": 64,
        "fullcodeline": "op_params.float_activation_max = output_activation_max;"
    },
    {
        "line": 15,
        "fullcodeline": "GetTemporarySafe(context, node, data->input_quantized_index,"
    },
    {
        "line": 18,
        "fullcodeline": "GetTensorData<int8_t>(quantized_input_tensor);"
    },
    {
        "line": 21,
        "fullcodeline": "GetTemporarySafe(context, node, data->scaling_factors_index,"
    },
    {
        "line": 26,
        "fullcodeline": "GetTemporarySafe(context, node, data->input_offset_index,"
    },
    {
        "line": 30,
        "fullcodeline": "for (int b = 0; b < batch_size; ++b) {"
    },
    {
        "line": 40,
        "fullcodeline": "if (im2col != nullptr) {"
    },
    {
        "line": 45,
        "fullcodeline": "reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);"
    },
    {
        "line": 31,
        "fullcodeline": "const int offset = b * input_size;"
    },
    {
        "line": 32,
        "fullcodeline": "tensor_utils::AsymmetricQuantizeFloats("
    },
    {
        "line": 41,
        "fullcodeline": "im2col_ptr = im2col->data.int8;"
    },
    {
        "line": 52,
        "fullcodeline": "effective_kernel_type = kReference;"
    },
    {
        "line": 67,
        "fullcodeline": "reference_ops::HybridConvPerChannel("
    },
    {
        "line": 33,
        "fullcodeline": "GetTensorData<float>(input) + offset, input_size,"
    },
    {
        "line": 34,
        "fullcodeline": "quantized_input_ptr_batch + offset, &scaling_factors_ptr[b],"
    },
    {
        "line": 68,
        "fullcodeline": "op_params, scaling_factors_ptr, GetTensorShape(input),"
    },
    {
        "line": 69,
        "fullcodeline": "quantized_input_ptr_batch, GetTensorShape(filter), filter_ptr,"
    },
    {
        "line": 70,
        "fullcodeline": "GetTensorShape(bias), GetTensorData<float>(bias),"
    },
    {
        "line": 71,
        "fullcodeline": "GetTensorShape(output), GetTensorData<float>(output),"
    },
    {
        "line": 72,
        "fullcodeline": "GetTensorShape(im2col), im2col_ptr, affine_quantization->scale->data,"
    },
    {
        "line": 79,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 83,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 86,
        "fullcodeline": "optimized_ops::HybridConvPerChannel("
    },
    {
        "line": 96,
        "fullcodeline": "data->compute_hybrid_row_sums = false;"
    },
    {
        "line": 81,
        "fullcodeline": "GetTemporarySafe(context, node, data->row_sums_index, &row_sums));"
    },
    {
        "line": 85,
        "fullcodeline": "GetTemporarySafe(context, node, data->accum_scratch_index, &scratch));"
    },
    {
        "line": 87,
        "fullcodeline": "op_params, scaling_factors_ptr, GetTensorShape(input),"
    },
    {
        "line": 88,
        "fullcodeline": "quantized_input_ptr_batch, GetTensorShape(filter), filter_ptr,"
    },
    {
        "line": 89,
        "fullcodeline": "GetTensorShape(bias), GetTensorData<float>(bias),"
    },
    {
        "line": 90,
        "fullcodeline": "GetTensorShape(output), GetTensorData<float>(output),"
    },
    {
        "line": 91,
        "fullcodeline": "GetTensorShape(im2col), im2col_ptr, affine_quantization->scale->data,"
    },
    {
        "line": 92,
        "fullcodeline": "input_offset_ptr, GetTensorShape(scratch),"
    },
    {
        "line": 93,
        "fullcodeline": "GetTensorData<int32>(scratch), GetTensorData<int32_t>(row_sums),"
    },
    {
        "line": 95,
        "fullcodeline": "CpuBackendContext::GetFromContext(context));"
    }
]