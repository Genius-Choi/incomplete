[
    {
        "line": 16,
        "fullcodeline": "const bool is_broken_identity_fused_conv ="
    },
    {
        "line": 25,
        "fullcodeline": "const bool is_unsupported_x32 ="
    },
    {
        "line": 30,
        "fullcodeline": "const bool is_pre_frontend_cudnn = CUDNN_VERSION < 8100;"
    },
    {
        "line": 32,
        "fullcodeline": "const bool actually_use_cudnn_frontend ="
    },
    {
        "line": 18,
        "fullcodeline": "activation_mode == dnn::ActivationMode::kNone;"
    },
    {
        "line": 26,
        "fullcodeline": "input_descriptor.layout() == dnn::kBatchDepthYX32;"
    },
    {
        "line": 33,
        "fullcodeline": "use_cudnn_frontend && !is_pre_frontend_cudnn &&"
    },
    {
        "line": 36,
        "fullcodeline": "if (use_cudnn_frontend && !actually_use_cudnn_frontend) {"
    },
    {
        "line": 55,
        "fullcodeline": "if (input_type == dnn::DataType::kInt8 &&"
    },
    {
        "line": 62,
        "fullcodeline": "if (input_type == dnn::DataType::kInt8 &&"
    },
    {
        "line": 70,
        "fullcodeline": "if (activation_mode != dnn::ActivationMode::kRelu &&"
    },
    {
        "line": 80,
        "fullcodeline": "if (!actually_use_cudnn_frontend) {"
    },
    {
        "line": 134,
        "fullcodeline": "return tsl::errors::Unimplemented("
    },
    {
        "line": 34,
        "fullcodeline": "!is_broken_identity_fused_conv && !is_unsupported_x32;"
    },
    {
        "line": 37,
        "fullcodeline": "const char* reason = \"the current cuDNN version does not support it.\";"
    },
    {
        "line": 48,
        "fullcodeline": "LOG(INFO) << \"Disabling cuDNN frontend for the following convolution:\\n\""
    },
    {
        "line": 56,
        "fullcodeline": "!stream->GetCudaComputeCapability().IsAtLeast(6, 1)) {"
    },
    {
        "line": 64,
        "fullcodeline": "(CUDNN_VERSION >= 8000 && CUDNN_VERSION <= 8200)) {"
    },
    {
        "line": 74,
        "fullcodeline": "activation_mode != dnn::ActivationMode::kNone) {"
    },
    {
        "line": 81,
        "fullcodeline": "std::vector<dnn::AlgorithmDesc> algorithms;"
    },
    {
        "line": 83,
        "fullcodeline": "auto cuda_compute_capability = stream->GetCudaComputeCapability();"
    },
    {
        "line": 57,
        "fullcodeline": "return tsl::errors::Unimplemented("
    },
    {
        "line": 63,
        "fullcodeline": "output_type == dnn::DataType::kFloat &&"
    },
    {
        "line": 65,
        "fullcodeline": "return tsl::errors::Unimplemented("
    },
    {
        "line": 73,
        "fullcodeline": "activation_mode != dnn::ActivationMode::kLeakyRelu &&"
    },
    {
        "line": 75,
        "fullcodeline": "return tsl::Status(tsl::error::INVALID_ARGUMENT,"
    },
    {
        "line": 84,
        "fullcodeline": "if (!GetConvolveAlgorithms(cuda_compute_capability, input_type,"
    },
    {
        "line": 111,
        "fullcodeline": "return ::tsl::OkStatus();"
    },
    {
        "line": 39,
        "fullcodeline": "reason = \"Tx32 convolutions are unsupported.\";"
    },
    {
        "line": 72,
        "fullcodeline": "activation_mode != dnn::ActivationMode::kElu &&"
    },
    {
        "line": 98,
        "fullcodeline": "auto runner_or = FusedConvolveRunnerFromDesc("
    },
    {
        "line": 109,
        "fullcodeline": "out_exec_plans->push_back(std::move(runner_or).value());"
    },
    {
        "line": 71,
        "fullcodeline": "activation_mode != dnn::ActivationMode::kRelu6 &&"
    },
    {
        "line": 86,
        "fullcodeline": "return tsl::Status(tsl::error::UNKNOWN,"
    },
    {
        "line": 94,
        "fullcodeline": "if (activation_mode == dnn::ActivationMode::kNone &&"
    },
    {
        "line": 103,
        "fullcodeline": "if (!runner_or.ok()) {"
    },
    {
        "line": 51,
        "fullcodeline": "<< \"  \" << convolution_descriptor.ToString() << \"\\n\""
    },
    {
        "line": 95,
        "fullcodeline": "algo.algo_id() != CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM) {"
    },
    {
        "line": 41,
        "fullcodeline": "reason = \"it uses an identity activation.\";"
    },
    {
        "line": 50,
        "fullcodeline": "<< \"  filter: \" << filter_descriptor.ToString() << \"\\n\""
    },
    {
        "line": 49,
        "fullcodeline": "<< \"  input: \" << input_descriptor.ToString() << \"\\n\""
    }
]