[
    {
        "line": 9,
        "fullcodeline": "const float alpha_f = 1.0f;"
    },
    {
        "line": 10,
        "fullcodeline": "const double alpha_d = 1.0;"
    },
    {
        "line": 11,
        "fullcodeline": "const void* alpha = element_type == dnn::DataType::kDouble"
    },
    {
        "line": 15,
        "fullcodeline": "const float beta_f = 0.0f;"
    },
    {
        "line": 16,
        "fullcodeline": "const double beta_d = 0.0;"
    },
    {
        "line": 17,
        "fullcodeline": "const void* beta = element_type == dnn::DataType::kDouble"
    },
    {
        "line": 21,
        "fullcodeline": "cudnnDataType_t cudnn_input_type ="
    },
    {
        "line": 23,
        "fullcodeline": "cudnnDataType_t cudnn_output_type ="
    },
    {
        "line": 25,
        "fullcodeline": "CudnnPoolingDescriptor pooling_desc(pooling_dimensions);"
    },
    {
        "line": 26,
        "fullcodeline": "auto cudnn = cudnn_->GetHandle(parent_, stream);"
    },
    {
        "line": 28,
        "fullcodeline": "auto cudnn_launcher = [&](CudnnTensorDescriptor& src_desc,"
    },
    {
        "line": 39,
        "fullcodeline": "auto splits_or ="
    },
    {
        "line": 44,
        "fullcodeline": "auto splits = std::move(splits_or.value());"
    },
    {
        "line": 46,
        "fullcodeline": "dnn::BatchDescriptor input_split = input_dimensions;"
    },
    {
        "line": 47,
        "fullcodeline": "dnn::BatchDescriptor output_split = output_dimensions;"
    },
    {
        "line": 22,
        "fullcodeline": "ToCudnnDataType(element_type, input_dimensions.layout());"
    },
    {
        "line": 24,
        "fullcodeline": "ToCudnnDataType(element_type, output_dimensions.layout());"
    },
    {
        "line": 40,
        "fullcodeline": "GetTensorSplits(input_dimensions, output_dimensions, element_type);"
    },
    {
        "line": 41,
        "fullcodeline": "if (!splits_or.ok()) {"
    },
    {
        "line": 48,
        "fullcodeline": "for (int i = 0; i < splits.size(); i++) {"
    },
    {
        "line": 72,
        "fullcodeline": "return ::tsl::OkStatus();"
    },
    {
        "line": 12,
        "fullcodeline": "? static_cast<const void*>(&alpha_d)"
    },
    {
        "line": 13,
        "fullcodeline": ": static_cast<const void*>(&alpha_f);"
    },
    {
        "line": 18,
        "fullcodeline": "? static_cast<const void*>(&beta_d)"
    },
    {
        "line": 19,
        "fullcodeline": ": static_cast<const void*>(&beta_f);"
    },
    {
        "line": 52,
        "fullcodeline": "input_split.set_count(splits[i].num_batches);"
    },
    {
        "line": 53,
        "fullcodeline": "output_split.set_count(splits[i].num_batches);"
    },
    {
        "line": 54,
        "fullcodeline": "CudnnTensorDescriptor src_desc(input_split, cudnn_input_type);"
    },
    {
        "line": 55,
        "fullcodeline": "CudnnTensorDescriptor dest_desc(output_split, cudnn_output_type);"
    },
    {
        "line": 57,
        "fullcodeline": "void* output_data_ptr = static_cast<char*>(output_data.opaque()) +"
    },
    {
        "line": 59,
        "fullcodeline": "void* input_diff_data_ptr = static_cast<char*>(input_diff_data.opaque()) +"
    },
    {
        "line": 61,
        "fullcodeline": "void* input_data_ptr = static_cast<char*>(input_data.opaque()) +"
    },
    {
        "line": 63,
        "fullcodeline": "void* output_diff_data_ptr = static_cast<char*>(output_diff_data.opaque()) +"
    },
    {
        "line": 65,
        "fullcodeline": "const auto status = cudnn_launcher(src_desc, dest_desc, output_data_ptr,"
    },
    {
        "line": 42,
        "fullcodeline": "return tsl::Status(port::error::INTERNAL, \"Cudnn pooling failed to split\");"
    },
    {
        "line": 68,
        "fullcodeline": "if (!IsStatusOk(status, /*report_error=*/true)) {"
    }
]