[
    {
        "line": 38,
        "fullcodeline": "CudnnTensorDescriptor conv_input_nd("
    },
    {
        "line": 41,
        "fullcodeline": "CudnnTensorDescriptor output_nd("
    },
    {
        "line": 49,
        "fullcodeline": "DeviceMemory<uint8_t> scratch;"
    },
    {
        "line": 69,
        "fullcodeline": "CudnnActivationDescriptor activation_desc("
    },
    {
        "line": 16,
        "fullcodeline": "if (input_type == dnn::DataType::kInt8 &&"
    },
    {
        "line": 40,
        "fullcodeline": "ToCudnnDataType(input_type, conv_input_descriptor.layout()));"
    },
    {
        "line": 43,
        "fullcodeline": "ToCudnnDataType(output_type, conv_input_descriptor.layout()));"
    },
    {
        "line": 46,
        "fullcodeline": "ToCudnnDataType(input_type, filter_descriptor.layout()));"
    },
    {
        "line": 47,
        "fullcodeline": "CudnnTensorDescriptor bias_nd(bias_descriptor, ToCudnnDataType(bias_type));"
    },
    {
        "line": 52,
        "fullcodeline": "auto cudnn = cudnn_->GetHandle(parent_, stream);"
    },
    {
        "line": 53,
        "fullcodeline": "TF_ASSIGN_OR_RETURN("
    },
    {
        "line": 62,
        "fullcodeline": "ToCudnnDataType(GetConvAccumulatorType(input_type)));"
    },
    {
        "line": 63,
        "fullcodeline": "conv.set_use_tensor_op_math(algo_desc.tensor_ops_enabled());"
    },
    {
        "line": 70,
        "fullcodeline": "activation_mode, CUDNN_NOT_PROPAGATE_NAN, output_descriptor.value_max());"
    },
    {
        "line": 80,
        "fullcodeline": "return runner(stream, output_profile_result, scratch, conv_input_data,"
    },
    {
        "line": 17,
        "fullcodeline": "!stream->GetCudaComputeCapability().IsAtLeast(6, 1)) {"
    },
    {
        "line": 23,
        "fullcodeline": "if (input_type == dnn::DataType::kInt8 &&"
    },
    {
        "line": 25,
        "fullcodeline": "(CUDNN_VERSION >= 8000 && CUDNN_VERSION <= 8200)) {"
    },
    {
        "line": 31,
        "fullcodeline": "if (activation_mode != dnn::ActivationMode::kRelu &&"
    },
    {
        "line": 32,
        "fullcodeline": "activation_mode != dnn::ActivationMode::kNone) {"
    },
    {
        "line": 55,
        "fullcodeline": "GetCudnnConvolutionForwardAlgorithm("
    },
    {
        "line": 18,
        "fullcodeline": "return tsl::errors::Unimplemented("
    },
    {
        "line": 24,
        "fullcodeline": "output_type == dnn::DataType::kFloat &&"
    },
    {
        "line": 26,
        "fullcodeline": "return tsl::errors::Unimplemented("
    },
    {
        "line": 33,
        "fullcodeline": "return tsl::Status(port::error::INVALID_ARGUMENT,"
    }
]