[
    {
        "line": 8,
        "fullcodeline": "const float alpha_f = 1.0f;"
    },
    {
        "line": 9,
        "fullcodeline": "const double alpha_d = 1.0;"
    },
    {
        "line": 10,
        "fullcodeline": "const void* alpha = element_type == dnn::DataType::kDouble"
    },
    {
        "line": 14,
        "fullcodeline": "const float beta_f = 0.0f;"
    },
    {
        "line": 15,
        "fullcodeline": "const double beta_d = 0.0;"
    },
    {
        "line": 16,
        "fullcodeline": "const void* beta = element_type == dnn::DataType::kDouble"
    },
    {
        "line": 20,
        "fullcodeline": "cudnnDataType_t cudnn_input_type ="
    },
    {
        "line": 22,
        "fullcodeline": "cudnnDataType_t cudnn_output_type ="
    },
    {
        "line": 24,
        "fullcodeline": "CudnnPoolingDescriptor pooling_desc(pooling_dimensions);"
    },
    {
        "line": 25,
        "fullcodeline": "auto cudnn = cudnn_->GetHandle(parent_, stream);"
    },
    {
        "line": 27,
        "fullcodeline": "auto cudnn_launcher = [&](CudnnTensorDescriptor& src_desc,"
    },
    {
        "line": 36,
        "fullcodeline": "auto splits_or ="
    },
    {
        "line": 41,
        "fullcodeline": "auto splits = std::move(splits_or.value());"
    },
    {
        "line": 43,
        "fullcodeline": "dnn::BatchDescriptor input_split = input_dimensions;"
    },
    {
        "line": 44,
        "fullcodeline": "dnn::BatchDescriptor output_split = output_dimensions;"
    },
    {
        "line": 21,
        "fullcodeline": "ToCudnnDataType(element_type, input_dimensions.layout());"
    },
    {
        "line": 23,
        "fullcodeline": "ToCudnnDataType(element_type, output_dimensions.layout());"
    },
    {
        "line": 37,
        "fullcodeline": "GetTensorSplits(input_dimensions, output_dimensions, element_type);"
    },
    {
        "line": 38,
        "fullcodeline": "if (!splits_or.ok()) {"
    },
    {
        "line": 45,
        "fullcodeline": "for (int i = 0; i < splits.size(); i++) {"
    },
    {
        "line": 64,
        "fullcodeline": "return ::tsl::OkStatus();"
    },
    {
        "line": 11,
        "fullcodeline": "? static_cast<const void*>(&alpha_d)"
    },
    {
        "line": 12,
        "fullcodeline": ": static_cast<const void*>(&alpha_f);"
    },
    {
        "line": 17,
        "fullcodeline": "? static_cast<const void*>(&beta_d)"
    },
    {
        "line": 18,
        "fullcodeline": ": static_cast<const void*>(&beta_f);"
    },
    {
        "line": 49,
        "fullcodeline": "input_split.set_count(splits[i].num_batches);"
    },
    {
        "line": 50,
        "fullcodeline": "output_split.set_count(splits[i].num_batches);"
    },
    {
        "line": 51,
        "fullcodeline": "CudnnTensorDescriptor src_desc(input_split, cudnn_input_type);"
    },
    {
        "line": 52,
        "fullcodeline": "CudnnTensorDescriptor dest_desc(output_split, cudnn_output_type);"
    },
    {
        "line": 54,
        "fullcodeline": "void* input_data_ptr = static_cast<char*>(input_data.opaque()) +"
    },
    {
        "line": 56,
        "fullcodeline": "void* output_data_ptr = static_cast<char*>(output_data.opaque()) +"
    },
    {
        "line": 58,
        "fullcodeline": "const auto status ="
    },
    {
        "line": 39,
        "fullcodeline": "return tsl::Status(tsl::error::INTERNAL, \"Cudnn pooling failed to split\");"
    },
    {
        "line": 59,
        "fullcodeline": "cudnn_launcher(src_desc, dest_desc, input_data_ptr, output_data_ptr);"
    },
    {
        "line": 60,
        "fullcodeline": "if (!IsStatusOk(status, /*report_error=*/true)) {"
    }
]