[
    {
        "line": 24,
        "fullcodeline": "ConstEigenMatrixMap in_mat("
    },
    {
        "line": 27,
        "fullcodeline": "EigenMatrixMap out_mat("
    },
    {
        "line": 30,
        "fullcodeline": "EigenIndexMatrixMap out_arg_max_mat("
    },
    {
        "line": 34,
        "fullcodeline": "const DeviceBase::CpuWorkerThreads& worker_threads ="
    },
    {
        "line": 47,
        "fullcodeline": "auto shard = [&params, &in_mat, &out_mat, &out_arg_max_mat, &input_backprop,"
    },
    {
        "line": 146,
        "fullcodeline": "const int64 shard_cost = params.tensor_in_rows * params.tensor_in_cols *"
    },
    {
        "line": 149,
        "fullcodeline": "Shard(worker_threads.num_threads, worker_threads.workers,"
    },
    {
        "line": 5,
        "fullcodeline": "if (input_backprop != nullptr) {"
    },
    {
        "line": 25,
        "fullcodeline": "tensor_in.flat<T>().data(), params.depth,"
    },
    {
        "line": 26,
        "fullcodeline": "params.tensor_in_cols * params.tensor_in_rows * params.tensor_in_batch);"
    },
    {
        "line": 28,
        "fullcodeline": "output->flat<T>().data(), params.depth,"
    },
    {
        "line": 29,
        "fullcodeline": "params.out_width * params.out_height * params.tensor_in_batch);"
    },
    {
        "line": 31,
        "fullcodeline": "output_arg_max->flat<Targmax>().data(), params.depth,"
    },
    {
        "line": 32,
        "fullcodeline": "params.out_width * params.out_height * params.tensor_in_batch);"
    },
    {
        "line": 6,
        "fullcodeline": "OP_REQUIRES("
    },
    {
        "line": 11,
        "fullcodeline": "OP_REQUIRES("
    },
    {
        "line": 35,
        "fullcodeline": "*(context->device()->tensorflow_cpu_worker_threads());"
    },
    {
        "line": 8,
        "fullcodeline": "errors::Internal("
    },
    {
        "line": 13,
        "fullcodeline": "errors::Internal(\"SpatialMaxPoolWithArgMaxHelper requires Targmax \""
    }
]