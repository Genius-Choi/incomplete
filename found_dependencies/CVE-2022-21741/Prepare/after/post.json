[
    {
        "line": 2,
        "fullcodeline": "auto* params ="
    },
    {
        "line": 4,
        "fullcodeline": "OpData* data = reinterpret_cast<OpData*>(node->user_data);"
    },
    {
        "line": 6,
        "fullcodeline": "bool has_bias = NumInputs(node) == 3;"
    },
    {
        "line": 8,
        "fullcodeline": "TF_LITE_ENSURE(context, has_bias || NumInputs(node) == 2);"
    },
    {
        "line": 10,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));"
    },
    {
        "line": 12,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 14,
        "fullcodeline": "const TfLiteTensor* bias = nullptr;"
    },
    {
        "line": 16,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);"
    },
    {
        "line": 18,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 21,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);"
    },
    {
        "line": 22,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 4);"
    },
    {
        "line": 23,
        "fullcodeline": "TF_LITE_ENSURE(context, params->dilation_height_factor > 0);"
    },
    {
        "line": 24,
        "fullcodeline": "TF_LITE_ENSURE(context, params->dilation_width_factor > 0);"
    },
    {
        "line": 26,
        "fullcodeline": "const TfLiteType data_type = input->type;"
    },
    {
        "line": 28,
        "fullcodeline": "const TfLiteType filter_type = filter->type;"
    },
    {
        "line": 29,
        "fullcodeline": "const bool is_hybrid ="
    },
    {
        "line": 31,
        "fullcodeline": "TF_LITE_ENSURE(context,"
    },
    {
        "line": 34,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, output->type, data_type);"
    },
    {
        "line": 46,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 0), 1);"
    },
    {
        "line": 64,
        "fullcodeline": "int channels_out = SizeOfDimension(filter, 3);"
    },
    {
        "line": 65,
        "fullcodeline": "int width = SizeOfDimension(input, 2);"
    },
    {
        "line": 66,
        "fullcodeline": "int height = SizeOfDimension(input, 1);"
    },
    {
        "line": 67,
        "fullcodeline": "int filter_width = SizeOfDimension(filter, 2);"
    },
    {
        "line": 68,
        "fullcodeline": "int filter_height = SizeOfDimension(filter, 1);"
    },
    {
        "line": 69,
        "fullcodeline": "int batches = SizeOfDimension(input, 0);"
    },
    {
        "line": 72,
        "fullcodeline": "auto padding = params->padding;"
    },
    {
        "line": 75,
        "fullcodeline": "data->padding = ComputePaddingHeightWidth("
    },
    {
        "line": 183,
        "fullcodeline": "TfLiteIntArray* outputSize = TfLiteIntArrayCreate(4);"
    },
    {
        "line": 184,
        "fullcodeline": "outputSize->data[0] = batches;"
    },
    {
        "line": 185,
        "fullcodeline": "outputSize->data[1] = out_height;"
    },
    {
        "line": 186,
        "fullcodeline": "outputSize->data[2] = out_width;"
    },
    {
        "line": 187,
        "fullcodeline": "outputSize->data[3] = channels_out;"
    },
    {
        "line": 3,
        "fullcodeline": "reinterpret_cast<TfLiteDepthwiseConvParams*>(node->builtin_data);"
    },
    {
        "line": 13,
        "fullcodeline": "GetInputSafe(context, node, kFilterTensor, &filter));"
    },
    {
        "line": 19,
        "fullcodeline": "GetOutputSafe(context, node, kOutputTensor, &output));"
    },
    {
        "line": 30,
        "fullcodeline": "data_type == kTfLiteFloat32 && filter_type == kTfLiteInt8;"
    },
    {
        "line": 32,
        "fullcodeline": "data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||"
    },
    {
        "line": 35,
        "fullcodeline": "if (!is_hybrid) {"
    },
    {
        "line": 40,
        "fullcodeline": "if (data_type == kTfLiteInt16) {"
    },
    {
        "line": 83,
        "fullcodeline": "if (data_type != kTfLiteFloat32) {"
    },
    {
        "line": 188,
        "fullcodeline": "return context->ResizeTensor(context, output, outputSize);"
    },
    {
        "line": 33,
        "fullcodeline": "data_type == kTfLiteInt8 || data_type == kTfLiteInt16);"
    },
    {
        "line": 36,
        "fullcodeline": "TF_LITE_ENSURE(context,"
    },
    {
        "line": 41,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);"
    },
    {
        "line": 42,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);"
    },
    {
        "line": 49,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));"
    },
    {
        "line": 59,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, NumDimensions(bias), 1);"
    },
    {
        "line": 60,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 3),"
    },
    {
        "line": 84,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, filter->quantization.type,"
    },
    {
        "line": 86,
        "fullcodeline": "TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);"
    },
    {
        "line": 90,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization);"
    },
    {
        "line": 91,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization->scale);"
    },
    {
        "line": 92,
        "fullcodeline": "TF_LITE_ENSURE(context, (affine_quantization->scale->size == 1 ||"
    },
    {
        "line": 95,
        "fullcodeline": "data->per_channel_output_multiplier.resize(channels_out);"
    },
    {
        "line": 96,
        "fullcodeline": "data->per_channel_output_shift.resize(channels_out);"
    },
    {
        "line": 97,
        "fullcodeline": "TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams("
    },
    {
        "line": 106,
        "fullcodeline": "TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);"
    },
    {
        "line": 110,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization);"
    },
    {
        "line": 111,
        "fullcodeline": "TF_LITE_ENSURE(context, affine_quantization->scale);"
    },
    {
        "line": 112,
        "fullcodeline": "TF_LITE_ENSURE_EQ("
    },
    {
        "line": 116,
        "fullcodeline": "int temporaries_count = 0;"
    },
    {
        "line": 117,
        "fullcodeline": "data->input_quantized_index = temporaries_count;"
    },
    {
        "line": 122,
        "fullcodeline": "++temporaries_count;"
    },
    {
        "line": 123,
        "fullcodeline": "data->scaling_factors_index = temporaries_count;"
    },
    {
        "line": 128,
        "fullcodeline": "++temporaries_count;"
    },
    {
        "line": 129,
        "fullcodeline": "data->input_offset_index = temporaries_count;"
    },
    {
        "line": 134,
        "fullcodeline": "++temporaries_count;"
    },
    {
        "line": 136,
        "fullcodeline": "TfLiteIntArrayFree(node->temporaries);"
    },
    {
        "line": 137,
        "fullcodeline": "node->temporaries = TfLiteIntArrayCreate(temporaries_count);"
    },
    {
        "line": 139,
        "fullcodeline": "node->temporaries->data[data->input_quantized_index] ="
    },
    {
        "line": 142,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 145,
        "fullcodeline": "input_quantized->type = kTfLiteInt8;"
    },
    {
        "line": 146,
        "fullcodeline": "input_quantized->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 152,
        "fullcodeline": "node->temporaries->data[data->scaling_factors_index] ="
    },
    {
        "line": 155,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 158,
        "fullcodeline": "scaling_factors->type = kTfLiteFloat32;"
    },
    {
        "line": 159,
        "fullcodeline": "scaling_factors->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 160,
        "fullcodeline": "const int batch_size = SizeOfDimension(input, 0);"
    },
    {
        "line": 161,
        "fullcodeline": "int scaling_dims[1] = {batch_size};"
    },
    {
        "line": 168,
        "fullcodeline": "node->temporaries->data[data->input_offset_index] = data->input_offset_id;"
    },
    {
        "line": 170,
        "fullcodeline": "TF_LITE_ENSURE_OK(context,"
    },
    {
        "line": 173,
        "fullcodeline": "input_offsets->type = kTfLiteInt32;"
    },
    {
        "line": 174,
        "fullcodeline": "input_offsets->allocation_type = kTfLiteArenaRw;"
    },
    {
        "line": 37,
        "fullcodeline": "filter->type == data_type || data_type == kTfLiteInt16);"
    },
    {
        "line": 50,
        "fullcodeline": "if (data_type == kTfLiteUInt8 || data_type == kTfLiteInt8) {"
    },
    {
        "line": 61,
        "fullcodeline": "SizeOfDimension(bias, 0));"
    },
    {
        "line": 118,
        "fullcodeline": "if (data->input_quantized_id == kTensorNotAllocated) {"
    },
    {
        "line": 124,
        "fullcodeline": "if (data->scaling_factors_id == kTensorNotAllocated) {"
    },
    {
        "line": 130,
        "fullcodeline": "if (data->input_offset_id == kTensorNotAllocated) {"
    },
    {
        "line": 143,
        "fullcodeline": "context, GetTemporarySafe(context, node, data->input_quantized_index,"
    },
    {
        "line": 147,
        "fullcodeline": "if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {"
    },
    {
        "line": 156,
        "fullcodeline": "context, GetTemporarySafe(context, node, data->scaling_factors_index,"
    },
    {
        "line": 162,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {"
    },
    {
        "line": 171,
        "fullcodeline": "GetTemporarySafe(context, node, data->input_offset_index,"
    },
    {
        "line": 175,
        "fullcodeline": "if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {"
    },
    {
        "line": 51,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);"
    },
    {
        "line": 52,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);"
    },
    {
        "line": 93,
        "fullcodeline": "affine_quantization->scale->size == channels_out));"
    },
    {
        "line": 101,
        "fullcodeline": "data->per_channel_output_multiplier.data(),"
    },
    {
        "line": 102,
        "fullcodeline": "data->per_channel_output_shift.data(), channels_out));"
    },
    {
        "line": 119,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 125,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 131,
        "fullcodeline": "TF_LITE_ENSURE_OK("
    },
    {
        "line": 148,
        "fullcodeline": "TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);"
    },
    {
        "line": 149,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,"
    },
    {
        "line": 163,
        "fullcodeline": "TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 164,
        "fullcodeline": "scaling_factors_size->data[0] = batch_size;"
    },
    {
        "line": 165,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,"
    },
    {
        "line": 176,
        "fullcodeline": "TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);"
    },
    {
        "line": 177,
        "fullcodeline": "input_offsets_size->data[0] = batch_size;"
    },
    {
        "line": 178,
        "fullcodeline": "TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,"
    },
    {
        "line": 120,
        "fullcodeline": "context, context->AddTensors(context, 1, &data->input_quantized_id));"
    },
    {
        "line": 126,
        "fullcodeline": "context, context->AddTensors(context, 1, &data->scaling_factors_id));"
    },
    {
        "line": 132,
        "fullcodeline": "context, context->AddTensors(context, 1, &data->input_offset_id));"
    },
    {
        "line": 53,
        "fullcodeline": "} else if (data_type == kTfLiteInt16) {"
    },
    {
        "line": 54,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt64);"
    },
    {
        "line": 55,
        "fullcodeline": "TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);"
    },
    {
        "line": 57,
        "fullcodeline": "TF_LITE_ENSURE_TYPES_EQ(context, bias->type, data_type);"
    }
]