[
    {
        "line": 2,
        "fullcodeline": "FILE * file = ggml_fopen(fname, \"rb\");"
    },
    {
        "line": 9,
        "fullcodeline": "size_t offset = 0;"
    },
    {
        "line": 11,
        "fullcodeline": "char magic[4];"
    },
    {
        "line": 26,
        "fullcodeline": "bool ok = true;"
    },
    {
        "line": 28,
        "fullcodeline": "struct gguf_context * ctx = GGML_CALLOC(1, sizeof(struct gguf_context));"
    },
    {
        "line": 205,
        "fullcodeline": "ctx->alignment = GGUF_DEFAULT_ALIGNMENT;"
    },
    {
        "line": 207,
        "fullcodeline": "int alignment_idx = gguf_find_key(ctx, \"general.alignment\");"
    },
    {
        "line": 223,
        "fullcodeline": "ctx->offset = offset;"
    },
    {
        "line": 333,
        "fullcodeline": "fclose(file);"
    },
    {
        "line": 3,
        "fullcodeline": "if (!file) {"
    },
    {
        "line": 15,
        "fullcodeline": "gguf_fread_el(file, &magic, sizeof(magic), &offset);"
    },
    {
        "line": 32,
        "fullcodeline": "strncpy(ctx->header.magic, magic, 4);"
    },
    {
        "line": 34,
        "fullcodeline": "ctx->kv    = NULL;"
    },
    {
        "line": 35,
        "fullcodeline": "ctx->infos = NULL;"
    },
    {
        "line": 36,
        "fullcodeline": "ctx->data  = NULL;"
    },
    {
        "line": 38,
        "fullcodeline": "ok = ok && gguf_fread_el(file, &ctx->header.version,   sizeof(ctx->header.version),   &offset);"
    },
    {
        "line": 39,
        "fullcodeline": "ok = ok && gguf_fread_el(file, &ctx->header.n_tensors, sizeof(ctx->header.n_tensors), &offset);"
    },
    {
        "line": 40,
        "fullcodeline": "ok = ok && gguf_fread_el(file, &ctx->header.n_kv,      sizeof(ctx->header.n_kv),      &offset);"
    },
    {
        "line": 51,
        "fullcodeline": "ok = ok && (ctx->header.n_tensors < (SIZE_MAX/2)/sizeof(struct gguf_tensor_info));"
    },
    {
        "line": 52,
        "fullcodeline": "ok = ok && (ctx->header.n_tensors < (SIZE_MAX/2)/ggml_tensor_overhead());"
    },
    {
        "line": 53,
        "fullcodeline": "ok = ok && (ctx->header.n_kv      < (SIZE_MAX/2)/sizeof(struct gguf_kv));"
    },
    {
        "line": 65,
        "fullcodeline": "const uint64_t n_kv = ctx->header.n_kv;"
    },
    {
        "line": 68,
        "fullcodeline": "ctx->header.n_kv = 0;"
    },
    {
        "line": 69,
        "fullcodeline": "ctx->kv = GGML_CALLOC(n_kv, sizeof(struct gguf_kv));"
    },
    {
        "line": 163,
        "fullcodeline": "if (ctx->header.n_tensors > 0) {"
    },
    {
        "line": 208,
        "fullcodeline": "if (alignment_idx != -1) {"
    },
    {
        "line": 214,
        "fullcodeline": "const size_t offset_pad = offset % ctx->alignment;"
    },
    {
        "line": 227,
        "fullcodeline": "ctx->size = 0;"
    },
    {
        "line": 252,
        "fullcodeline": "if (params.ctx != NULL) {"
    },
    {
        "line": 4,
        "fullcodeline": "fprintf(stderr, \"%s: failed to open '%s': '%s'\\n\", __func__, fname, strerror(errno));"
    },
    {
        "line": 17,
        "fullcodeline": "for (uint32_t i = 0; i < sizeof(magic); i++) {"
    },
    {
        "line": 42,
        "fullcodeline": "if (ctx->header.version == 1) {"
    },
    {
        "line": 55,
        "fullcodeline": "if (!ok) {"
    },
    {
        "line": 71,
        "fullcodeline": "for (uint64_t i = 0; i < n_kv; ++i) {"
    },
    {
        "line": 154,
        "fullcodeline": "if (!ok) {"
    },
    {
        "line": 164,
        "fullcodeline": "ctx->infos = GGML_CALLOC(ctx->header.n_tensors, sizeof(struct gguf_tensor_info));"
    },
    {
        "line": 209,
        "fullcodeline": "ctx->alignment = gguf_get_val_u32(ctx, alignment_idx);"
    },
    {
        "line": 216,
        "fullcodeline": "if (offset_pad != 0) {"
    },
    {
        "line": 228,
        "fullcodeline": "for (uint64_t i = 0; i < ctx->header.n_tensors; ++i) {"
    },
    {
        "line": 258,
        "fullcodeline": "const size_t mem_size ="
    },
    {
        "line": 263,
        "fullcodeline": "struct ggml_init_params pdata = {"
    },
    {
        "line": 269,
        "fullcodeline": "*params.ctx = ggml_init(pdata);"
    },
    {
        "line": 271,
        "fullcodeline": "struct ggml_context * ctx_data = *params.ctx;"
    },
    {
        "line": 273,
        "fullcodeline": "struct ggml_tensor * data = NULL;"
    },
    {
        "line": 294,
        "fullcodeline": "ggml_set_no_alloc(ctx_data, true);"
    },
    {
        "line": 330,
        "fullcodeline": "ggml_set_no_alloc(ctx_data, params.no_alloc);"
    },
    {
        "line": 43,
        "fullcodeline": "fprintf(stderr, \"%s: GGUFv1 is no longer supported. please use a more up-to-date version\\n\", __func__);"
    },
    {
        "line": 44,
        "fullcodeline": "fclose(file);"
    },
    {
        "line": 45,
        "fullcodeline": "gguf_free(ctx);"
    },
    {
        "line": 56,
        "fullcodeline": "fprintf(stderr, \"%s: failed to read header\\n\", __func__);"
    },
    {
        "line": 57,
        "fullcodeline": "fclose(file);"
    },
    {
        "line": 58,
        "fullcodeline": "gguf_free(ctx);"
    },
    {
        "line": 72,
        "fullcodeline": "struct gguf_kv * kv = &ctx->kv[i];"
    },
    {
        "line": 76,
        "fullcodeline": "ok = ok && gguf_fread_str(file, &kv->key,                    &offset);"
    },
    {
        "line": 77,
        "fullcodeline": "ok = ok && gguf_fread_el (file, &kv->type, sizeof(kv->type), &offset);"
    },
    {
        "line": 151,
        "fullcodeline": "ctx->header.n_kv++;"
    },
    {
        "line": 155,
        "fullcodeline": "fprintf(stderr, \"%s: failed to read key-value pairs\\n\", __func__);"
    },
    {
        "line": 156,
        "fullcodeline": "fclose(file);"
    },
    {
        "line": 157,
        "fullcodeline": "gguf_free(ctx);"
    },
    {
        "line": 166,
        "fullcodeline": "for (uint64_t i = 0; i < ctx->header.n_tensors; ++i) {"
    },
    {
        "line": 217,
        "fullcodeline": "offset += ctx->alignment - offset_pad;"
    },
    {
        "line": 218,
        "fullcodeline": "fseek(file, offset, SEEK_SET);"
    },
    {
        "line": 229,
        "fullcodeline": "struct gguf_tensor_info * info = &ctx->infos[i];"
    },
    {
        "line": 231,
        "fullcodeline": "const int64_t ne ="
    },
    {
        "line": 245,
        "fullcodeline": "const size_t size_cur = ggml_row_size(info->type, ne);"
    },
    {
        "line": 247,
        "fullcodeline": "ctx->size += GGML_PAD(size_cur, ctx->alignment);"
    },
    {
        "line": 259,
        "fullcodeline": "params.no_alloc ?"
    },
    {
        "line": 275,
        "fullcodeline": "if (!params.no_alloc) {"
    },
    {
        "line": 297,
        "fullcodeline": "for (uint64_t i = 0; i < ctx->header.n_tensors; ++i) {"
    },
    {
        "line": 322,
        "fullcodeline": "if (!ok) {"
    },
    {
        "line": 147,
        "fullcodeline": "if (!ok) {"
    },
    {
        "line": 167,
        "fullcodeline": "struct gguf_tensor_info * info = &ctx->infos[i];"
    },
    {
        "line": 173,
        "fullcodeline": "ok = ok && gguf_fread_str(file, &info->name,                          &offset);"
    },
    {
        "line": 174,
        "fullcodeline": "ok = ok && gguf_fread_el (file, &info->n_dims, sizeof(info->n_dims),  &offset);"
    },
    {
        "line": 176,
        "fullcodeline": "ok = ok && (info->n_dims <= GGML_MAX_DIMS);"
    },
    {
        "line": 182,
        "fullcodeline": "ok = ok && gguf_fread_el (file, &info->type,   sizeof(info->type),    &offset);"
    },
    {
        "line": 183,
        "fullcodeline": "ok = ok && gguf_fread_el (file, &info->offset, sizeof(info->offset),  &offset);"
    },
    {
        "line": 186,
        "fullcodeline": "gguf_tensor_info_sanitize(info);"
    },
    {
        "line": 232,
        "fullcodeline": "(int64_t) info->ne[0] *"
    },
    {
        "line": 237,
        "fullcodeline": "if (ne % ggml_blck_size(info->type) != 0) {"
    },
    {
        "line": 260,
        "fullcodeline": "(ctx->header.n_tensors    )*ggml_tensor_overhead() :"
    },
    {
        "line": 261,
        "fullcodeline": "(ctx->header.n_tensors + 1)*ggml_tensor_overhead() + ctx->size;"
    },
    {
        "line": 276,
        "fullcodeline": "data = ggml_new_tensor_1d(ctx_data, GGML_TYPE_I8, ctx->size);"
    },
    {
        "line": 278,
        "fullcodeline": "ok = ok && data != NULL;"
    },
    {
        "line": 281,
        "fullcodeline": "ok = ok && gguf_fread_el(file, data->data, ctx->size, &offset);"
    },
    {
        "line": 291,
        "fullcodeline": "ctx->data = data->data;"
    },
    {
        "line": 298,
        "fullcodeline": "const int64_t ne[GGML_MAX_DIMS] = {"
    },
    {
        "line": 305,
        "fullcodeline": "struct ggml_tensor * cur = ggml_new_tensor(ctx_data, ctx->infos[i].type, ctx->infos[i].n_dims, ne);"
    },
    {
        "line": 307,
        "fullcodeline": "ok = ok && cur != NULL;"
    },
    {
        "line": 313,
        "fullcodeline": "ggml_set_name(cur, ctx->infos[i].name.data);"
    },
    {
        "line": 323,
        "fullcodeline": "fprintf(stderr, \"%s: failed to read the tensor data\\n\", __func__);"
    },
    {
        "line": 324,
        "fullcodeline": "fclose(file);"
    },
    {
        "line": 325,
        "fullcodeline": "ggml_free(ctx_data);"
    },
    {
        "line": 326,
        "fullcodeline": "gguf_free(ctx);"
    },
    {
        "line": 19,
        "fullcodeline": "fprintf(stderr, \"%s: invalid magic characters '%c%c%c%c'\\n\", __func__, magic[0], magic[1], magic[2], magic[3]);"
    },
    {
        "line": 20,
        "fullcodeline": "fclose(file);"
    },
    {
        "line": 82,
        "fullcodeline": "case GGUF_TYPE_UINT8:   ok = ok && gguf_fread_el (file, &kv->value.uint8,   sizeof(kv->value.uint8),   &offset); break;"
    },
    {
        "line": 83,
        "fullcodeline": "case GGUF_TYPE_INT8:    ok = ok && gguf_fread_el (file, &kv->value.int8,    sizeof(kv->value.int8),    &offset); break;"
    },
    {
        "line": 84,
        "fullcodeline": "case GGUF_TYPE_UINT16:  ok = ok && gguf_fread_el (file, &kv->value.uint16,  sizeof(kv->value.uint16),  &offset); break;"
    },
    {
        "line": 85,
        "fullcodeline": "case GGUF_TYPE_INT16:   ok = ok && gguf_fread_el (file, &kv->value.int16,   sizeof(kv->value.int16),   &offset); break;"
    },
    {
        "line": 86,
        "fullcodeline": "case GGUF_TYPE_UINT32:  ok = ok && gguf_fread_el (file, &kv->value.uint32,  sizeof(kv->value.uint32),  &offset); break;"
    },
    {
        "line": 87,
        "fullcodeline": "case GGUF_TYPE_INT32:   ok = ok && gguf_fread_el (file, &kv->value.int32,   sizeof(kv->value.int32),   &offset); break;"
    },
    {
        "line": 88,
        "fullcodeline": "case GGUF_TYPE_FLOAT32: ok = ok && gguf_fread_el (file, &kv->value.float32, sizeof(kv->value.float32), &offset); break;"
    },
    {
        "line": 89,
        "fullcodeline": "case GGUF_TYPE_UINT64:  ok = ok && gguf_fread_el (file, &kv->value.uint64,  sizeof(kv->value.uint64),  &offset); break;"
    },
    {
        "line": 90,
        "fullcodeline": "case GGUF_TYPE_INT64:   ok = ok && gguf_fread_el (file, &kv->value.int64,   sizeof(kv->value.int64),   &offset); break;"
    },
    {
        "line": 91,
        "fullcodeline": "case GGUF_TYPE_FLOAT64: ok = ok && gguf_fread_el (file, &kv->value.float64, sizeof(kv->value.float64), &offset); break;"
    },
    {
        "line": 92,
        "fullcodeline": "case GGUF_TYPE_BOOL:    ok = ok && gguf_fread_el (file, &kv->value.bool_,   sizeof(kv->value.bool_),   &offset); break;"
    },
    {
        "line": 93,
        "fullcodeline": "case GGUF_TYPE_STRING:  ok = ok && gguf_fread_str(file, &kv->value.str,                                &offset); break;"
    },
    {
        "line": 144,
        "fullcodeline": "default: GGML_ASSERT(false && \"invalid type\");"
    },
    {
        "line": 169,
        "fullcodeline": "for (int j = 0; j < GGML_MAX_DIMS; ++j) {"
    },
    {
        "line": 178,
        "fullcodeline": "for (uint32_t j = 0; j < info->n_dims; ++j) {"
    },
    {
        "line": 189,
        "fullcodeline": "for (uint64_t j = 0; j < i && ok; ++j) {"
    },
    {
        "line": 196,
        "fullcodeline": "if (!ok) {"
    },
    {
        "line": 240,
        "fullcodeline": "fclose(file);"
    },
    {
        "line": 241,
        "fullcodeline": "gguf_free(ctx);"
    },
    {
        "line": 264,
        "fullcodeline": ".mem_size   = mem_size,"
    },
    {
        "line": 265,
        "fullcodeline": ".mem_buffer = NULL,"
    },
    {
        "line": 266,
        "fullcodeline": ".no_alloc   = params.no_alloc,"
    },
    {
        "line": 283,
        "fullcodeline": "if (!ok) {"
    },
    {
        "line": 309,
        "fullcodeline": "if (!ok) {"
    },
    {
        "line": 316,
        "fullcodeline": "if (!params.no_alloc) {"
    },
    {
        "line": 96,
        "fullcodeline": "ok = ok && gguf_fread_el(file, &kv->value.arr.type, sizeof(kv->value.arr.type), &offset);"
    },
    {
        "line": 97,
        "fullcodeline": "ok = ok && gguf_fread_el(file, &kv->value.arr.n,    sizeof(kv->value.arr.n),    &offset);"
    },
    {
        "line": 170,
        "fullcodeline": "info->ne[j] = 1;"
    },
    {
        "line": 179,
        "fullcodeline": "ok = ok && gguf_fread_el(file, &info->ne[j], sizeof(info->ne[j]), &offset);"
    },
    {
        "line": 197,
        "fullcodeline": "fprintf(stderr, \"%s: failed to read tensor info\\n\", __func__);"
    },
    {
        "line": 198,
        "fullcodeline": "fclose(file);"
    },
    {
        "line": 199,
        "fullcodeline": "gguf_free(ctx);"
    },
    {
        "line": 284,
        "fullcodeline": "fprintf(stderr, \"%s: failed to read tensor data\\n\", __func__);"
    },
    {
        "line": 285,
        "fullcodeline": "fclose(file);"
    },
    {
        "line": 286,
        "fullcodeline": "ggml_free(ctx_data);"
    },
    {
        "line": 287,
        "fullcodeline": "gguf_free(ctx);"
    },
    {
        "line": 318,
        "fullcodeline": "cur->data = (char *) data->data + ctx->infos[i].offset;               // offset from data"
    },
    {
        "line": 190,
        "fullcodeline": "if (strcmp(info->name.data, ctx->infos[j].name.data) == 0) {"
    },
    {
        "line": 141,
        "fullcodeline": "default: GGML_ASSERT(false && \"invalid type\"); break;"
    },
    {
        "line": 191,
        "fullcodeline": "fprintf(stderr, \"%s: duplicated tensor name %s\\n\", __func__, info->name.data);"
    },
    {
        "line": 192,
        "fullcodeline": "ok = false;"
    },
    {
        "line": 120,
        "fullcodeline": "kv->value.arr.data = GGML_CALLOC(kv->value.arr.n, gguf_type_size(kv->value.arr.type));"
    },
    {
        "line": 122,
        "fullcodeline": "ok = ok && gguf_fread_el(file, kv->value.arr.data, kv->value.arr.n * gguf_type_size(kv->value.arr.type), &offset);"
    },
    {
        "line": 134,
        "fullcodeline": "kv->value.arr.data = GGML_CALLOC(kv->value.arr.n, sizeof(struct gguf_str));"
    },
    {
        "line": 113,
        "fullcodeline": "if (kv->value.arr.n >= SIZE_MAX/gguf_type_size(kv->value.arr.type)) {"
    },
    {
        "line": 127,
        "fullcodeline": "if (kv->value.arr.n >= SIZE_MAX/sizeof(struct gguf_str)) {"
    },
    {
        "line": 136,
        "fullcodeline": "for (uint64_t j = 0; j < kv->value.arr.n; ++j) {"
    },
    {
        "line": 115,
        "fullcodeline": "fclose(file);"
    },
    {
        "line": 116,
        "fullcodeline": "gguf_free(ctx);"
    },
    {
        "line": 129,
        "fullcodeline": "fclose(file);"
    },
    {
        "line": 130,
        "fullcodeline": "gguf_free(ctx);"
    },
    {
        "line": 137,
        "fullcodeline": "ok = ok && gguf_fread_str(file, &((struct gguf_str *) kv->value.arr.data)[j], &offset);"
    }
]