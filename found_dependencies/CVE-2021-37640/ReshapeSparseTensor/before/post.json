[
    {
        "line": 6,
        "fullcodeline": "OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),"
    },
    {
        "line": 10,
        "fullcodeline": "OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),"
    },
    {
        "line": 14,
        "fullcodeline": "OP_REQUIRES(context, TensorShapeUtils::IsVector(target_shape_in.shape()),"
    },
    {
        "line": 19,
        "fullcodeline": "const int64_t output_rank = target_shape_in.NumElements();"
    },
    {
        "line": 20,
        "fullcodeline": "const TensorShape input_shape(input_shape_in.vec<int64>());"
    },
    {
        "line": 21,
        "fullcodeline": "const int64_t dense_size = input_shape.num_elements();"
    },
    {
        "line": 22,
        "fullcodeline": "const int64_t nnz = input_indices_in.shape().dim_size(0);"
    },
    {
        "line": 27,
        "fullcodeline": "int64_t product = 1;"
    },
    {
        "line": 28,
        "fullcodeline": "int unknown_index = -1;"
    },
    {
        "line": 29,
        "fullcodeline": "auto target_shape = target_shape_in.vec<int64>();"
    },
    {
        "line": 65,
        "fullcodeline": "OP_REQUIRES("
    },
    {
        "line": 80,
        "fullcodeline": "Tensor *result_shape = nullptr;"
    },
    {
        "line": 81,
        "fullcodeline": "OP_REQUIRES_OK(context, context->allocate_output(output_shape_idx,"
    },
    {
        "line": 84,
        "fullcodeline": "auto output_shape_vec = result_shape->vec<int64>();"
    },
    {
        "line": 89,
        "fullcodeline": "Tensor *result_indices = nullptr;"
    },
    {
        "line": 90,
        "fullcodeline": "OP_REQUIRES_OK(context,"
    },
    {
        "line": 7,
        "fullcodeline": "errors::InvalidArgument("
    },
    {
        "line": 11,
        "fullcodeline": "errors::InvalidArgument("
    },
    {
        "line": 15,
        "fullcodeline": "errors::InvalidArgument("
    },
    {
        "line": 30,
        "fullcodeline": "for (int d = 0; d < output_rank; ++d) {"
    },
    {
        "line": 48,
        "fullcodeline": "if (unknown_index != -1) {"
    },
    {
        "line": 66,
        "fullcodeline": "context, output_shape.num_elements() == dense_size,"
    },
    {
        "line": 67,
        "fullcodeline": "errors::InvalidArgument(\"Input to reshape is a tensor with \", dense_size,"
    },
    {
        "line": 74,
        "fullcodeline": "if (input_shape == output_shape) {"
    },
    {
        "line": 85,
        "fullcodeline": "for (int j = 0; j < output_shape.dims(); ++j) {"
    },
    {
        "line": 91,
        "fullcodeline": "context->allocate_output(output_indices_idx,"
    },
    {
        "line": 94,
        "fullcodeline": "if (nnz > 0) {"
    },
    {
        "line": 9,
        "fullcodeline": "input_indices_in.shape().DebugString()));"
    },
    {
        "line": 13,
        "fullcodeline": "input_shape_in.shape().DebugString()));"
    },
    {
        "line": 17,
        "fullcodeline": "target_shape_in.shape().DebugString()));"
    },
    {
        "line": 31,
        "fullcodeline": "const int64_t size = target_shape(d);"
    },
    {
        "line": 49,
        "fullcodeline": "OP_REQUIRES("
    },
    {
        "line": 54,
        "fullcodeline": "const int64_t missing = dense_size / product;"
    },
    {
        "line": 55,
        "fullcodeline": "OP_REQUIRES("
    },
    {
        "line": 62,
        "fullcodeline": "output_shape.set_dim(unknown_index, missing);"
    },
    {
        "line": 69,
        "fullcodeline": "output_shape.num_elements(),"
    },
    {
        "line": 70,
        "fullcodeline": "\". input_shape=\", input_shape.DebugString(),"
    },
    {
        "line": 71,
        "fullcodeline": "\" output_shape=\", output_shape.DebugString()));"
    },
    {
        "line": 75,
        "fullcodeline": "context->set_output(output_indices_idx, input_indices_in);"
    },
    {
        "line": 76,
        "fullcodeline": "context->set_output(output_shape_idx, input_shape_in);"
    },
    {
        "line": 82,
        "fullcodeline": "TensorShape({output_rank}),"
    },
    {
        "line": 86,
        "fullcodeline": "output_shape_vec(j) = output_shape.dim_size(j);"
    },
    {
        "line": 92,
        "fullcodeline": "TensorShape({nnz, output_rank}),"
    },
    {
        "line": 95,
        "fullcodeline": "OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()("
    },
    {
        "line": 32,
        "fullcodeline": "if (size == -1) {"
    },
    {
        "line": 50,
        "fullcodeline": "context, product > 0,"
    },
    {
        "line": 51,
        "fullcodeline": "errors::InvalidArgument(\"reshape cannot infer the missing \""
    },
    {
        "line": 56,
        "fullcodeline": "context, product * missing == dense_size,"
    },
    {
        "line": 57,
        "fullcodeline": "errors::InvalidArgument("
    },
    {
        "line": 33,
        "fullcodeline": "OP_REQUIRES("
    },
    {
        "line": 38,
        "fullcodeline": "unknown_index = d;"
    },
    {
        "line": 39,
        "fullcodeline": "output_shape.AddDim(1);"
    },
    {
        "line": 60,
        "fullcodeline": "product, \". input_shape=\", input_shape.DebugString(),"
    },
    {
        "line": 61,
        "fullcodeline": "\" output_shape=\", output_shape.DebugString()));"
    },
    {
        "line": 97,
        "fullcodeline": "input_indices_in.matrix<int64>(),"
    },
    {
        "line": 98,
        "fullcodeline": "result_indices->matrix<int64>()));"
    },
    {
        "line": 34,
        "fullcodeline": "context, unknown_index == -1,"
    },
    {
        "line": 35,
        "fullcodeline": "errors::InvalidArgument(\"only one output dimension may be -1, \""
    },
    {
        "line": 41,
        "fullcodeline": "OP_REQUIRES(context, size >= 0,"
    },
    {
        "line": 44,
        "fullcodeline": "product *= size;"
    },
    {
        "line": 45,
        "fullcodeline": "output_shape.AddDim(size);"
    },
    {
        "line": 42,
        "fullcodeline": "errors::InvalidArgument(\"size \", d,"
    }
]