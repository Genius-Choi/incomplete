[
    {
        "line": 2,
        "fullcodeline": "rq_job = queue.fetch_job(rq_id)"
    },
    {
        "line": 81,
        "fullcodeline": "serializer = RqIdSerializer(data={'rq_id': rq_id})"
    },
    {
        "line": 82,
        "fullcodeline": "serializer.is_valid(raise_exception=True)"
    },
    {
        "line": 4,
        "fullcodeline": "if (user_id_from_meta := getattr(rq_job, 'meta', {}).get('user', {}).get('id')) and user_id_from_meta != request.user.id:"
    },
    {
        "line": 7,
        "fullcodeline": "if not rq_job:"
    },
    {
        "line": 84,
        "fullcodeline": "return Response(serializer.data, status=status.HTTP_202_ACCEPTED)"
    },
    {
        "line": 8,
        "fullcodeline": "org_id = getattr(request.iam_context['organization'], 'id', None)"
    },
    {
        "line": 9,
        "fullcodeline": "location = location_conf.get('location')"
    },
    {
        "line": 41,
        "fullcodeline": "func = import_resource_with_clean_up_after"
    },
    {
        "line": 42,
        "fullcodeline": "func_args = (importer, filename, request.user.id, org_id)"
    },
    {
        "line": 48,
        "fullcodeline": "user_id = request.user.id"
    },
    {
        "line": 11,
        "fullcodeline": "if location == Location.LOCAL:"
    },
    {
        "line": 44,
        "fullcodeline": "if location == Location.CLOUD_STORAGE:"
    },
    {
        "line": 50,
        "fullcodeline": "with get_rq_lock_by_user(queue, user_id):"
    },
    {
        "line": 24,
        "fullcodeline": "file_name = request.query_params.get('filename')"
    },
    {
        "line": 25,
        "fullcodeline": "assert file_name, \"The filename wasn't specified\""
    },
    {
        "line": 33,
        "fullcodeline": "db_storage = get_cloud_storage_for_import_or_export("
    },
    {
        "line": 37,
        "fullcodeline": "key = filename"
    },
    {
        "line": 45,
        "fullcodeline": "func_args = (db_storage, key, func) + func_args"
    },
    {
        "line": 46,
        "fullcodeline": "func = import_resource_from_cloud_storage"
    },
    {
        "line": 65,
        "fullcodeline": "project_id = rq_job.return_value()"
    },
    {
        "line": 66,
        "fullcodeline": "rq_job.delete()"
    },
    {
        "line": 12,
        "fullcodeline": "if not filename:"
    },
    {
        "line": 38,
        "fullcodeline": "with NamedTemporaryFile(prefix='cvat_', dir=settings.TMP_FILES_ROOT, delete=False) as tf:"
    },
    {
        "line": 51,
        "fullcodeline": "rq_job = queue.enqueue_call("
    },
    {
        "line": 67,
        "fullcodeline": "return Response({'id': project_id}, status=status.HTTP_201_CREATED)"
    },
    {
        "line": 13,
        "fullcodeline": "serializer = Serializer(data=request.data)"
    },
    {
        "line": 14,
        "fullcodeline": "serializer.is_valid(raise_exception=True)"
    },
    {
        "line": 27,
        "fullcodeline": "storage_id = location_conf['storage_id']"
    },
    {
        "line": 69,
        "fullcodeline": "exc_info = process_failed_job(rq_job)"
    },
    {
        "line": 71,
        "fullcodeline": "import_error_prefix = '{}.{}'.format("
    },
    {
        "line": 16,
        "fullcodeline": "with NamedTemporaryFile("
    },
    {
        "line": 39,
        "fullcodeline": "filename = tf.name"
    },
    {
        "line": 59,
        "fullcodeline": "depends_on=define_dependent_job(queue, user_id),"
    },
    {
        "line": 73,
        "fullcodeline": "if exc_info.startswith(import_error_prefix):"
    },
    {
        "line": 29,
        "fullcodeline": "raise serializers.ValidationError("
    },
    {
        "line": 55,
        "fullcodeline": "meta={"
    },
    {
        "line": 60,
        "fullcodeline": "result_ttl=settings.IMPORT_CACHE_SUCCESS_TTL.total_seconds(),"
    },
    {
        "line": 61,
        "fullcodeline": "failure_ttl=settings.IMPORT_CACHE_FAILED_TTL.total_seconds()"
    },
    {
        "line": 74,
        "fullcodeline": "exc_info = exc_info.replace(import_error_prefix + ': ', '')"
    },
    {
        "line": 20,
        "fullcodeline": "filename = tf.name"
    },
    {
        "line": 57,
        "fullcodeline": "**get_rq_job_meta(request=request, db_obj=None)"
    },
    {
        "line": 75,
        "fullcodeline": "return Response(data=exc_info,"
    },
    {
        "line": 78,
        "fullcodeline": "return Response(data=exc_info,"
    },
    {
        "line": 21,
        "fullcodeline": "for chunk in payload_file.chunks():"
    },
    {
        "line": 30,
        "fullcodeline": "'Cloud storage location was selected as the source,'"
    },
    {
        "line": 22,
        "fullcodeline": "tf.write(chunk)"
    }
]