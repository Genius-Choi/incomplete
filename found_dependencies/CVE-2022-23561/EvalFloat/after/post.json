[
    {
        "line": 6,
        "fullcodeline": "CalculateActivationRange(params->activation, &output_activation_min,"
    },
    {
        "line": 8,
        "fullcodeline": "if (kernel_type == kReference) {"
    },
    {
        "line": 10,
        "fullcodeline": "op_params.float_activation_min = output_activation_min;"
    },
    {
        "line": 11,
        "fullcodeline": "op_params.float_activation_max = output_activation_max;"
    },
    {
        "line": 12,
        "fullcodeline": "if (filter->sparsity != nullptr) {"
    },
    {
        "line": 14,
        "fullcodeline": "reference_ops::FullyConnectedSparseWeight("
    },
    {
        "line": 27,
        "fullcodeline": "} else if (kernel_type == kLegacyPie) {"
    },
    {
        "line": 15,
        "fullcodeline": "sparsity, op_params, GetTensorShape(input),"
    },
    {
        "line": 16,
        "fullcodeline": "GetTensorData<float>(input), GetTensorShape(filter),"
    },
    {
        "line": 17,
        "fullcodeline": "GetTensorData<float>(filter), GetTensorShape(bias),"
    },
    {
        "line": 18,
        "fullcodeline": "GetTensorData<float>(bias), GetTensorShape(output),"
    },
    {
        "line": 19,
        "fullcodeline": "GetTensorData<float>(output));"
    },
    {
        "line": 21,
        "fullcodeline": "reference_ops::FullyConnected("
    },
    {
        "line": 22,
        "fullcodeline": "op_params, GetTensorShape(input), GetTensorData<float>(input),"
    },
    {
        "line": 23,
        "fullcodeline": "GetTensorShape(filter), GetTensorData<float>(filter),"
    },
    {
        "line": 24,
        "fullcodeline": "GetTensorShape(bias), GetTensorData<float>(bias),"
    },
    {
        "line": 25,
        "fullcodeline": "GetTensorShape(output), GetTensorData<float>(output));"
    },
    {
        "line": 28,
        "fullcodeline": "return EvalPie(context, node, params, data, input, filter, bias, output);"
    },
    {
        "line": 31,
        "fullcodeline": "op_params.float_activation_min = output_activation_min;"
    },
    {
        "line": 32,
        "fullcodeline": "op_params.float_activation_max = output_activation_max;"
    },
    {
        "line": 33,
        "fullcodeline": "if (filter->sparsity != nullptr) {"
    },
    {
        "line": 40,
        "fullcodeline": "const auto& input_shape = GetTensorShape(input);"
    },
    {
        "line": 41,
        "fullcodeline": "const auto& filter_shape = GetTensorShape(filter);"
    },
    {
        "line": 42,
        "fullcodeline": "const auto& output_shape = GetTensorShape(output);"
    },
    {
        "line": 43,
        "fullcodeline": "const auto& bias_shape = GetTensorShape(bias);"
    },
    {
        "line": 35,
        "fullcodeline": "if (!SupportedSparsityFormat(sparsity)) {"
    },
    {
        "line": 44,
        "fullcodeline": "if (!VerifySparsity(filter_shape, input_shape, output_shape, &sparsity)) {"
    },
    {
        "line": 49,
        "fullcodeline": "if (sparsity.dim_metadata_size == kDimMetadataSizeRandomSparse) {"
    },
    {
        "line": 74,
        "fullcodeline": "op_params.lhs_cacheable = IsConstantTensor(filter);"
    },
    {
        "line": 75,
        "fullcodeline": "op_params.rhs_cacheable = IsConstantTensor(input);"
    },
    {
        "line": 76,
        "fullcodeline": "optimized_ops::FullyConnected("
    },
    {
        "line": 36,
        "fullcodeline": "TF_LITE_KERNEL_LOG(context,"
    },
    {
        "line": 45,
        "fullcodeline": "TF_LITE_KERNEL_LOG(context, \"Invalid sparse fully-connected format.\");"
    },
    {
        "line": 51,
        "fullcodeline": "optimized_ops::FullyConnectedSparseWeight("
    },
    {
        "line": 77,
        "fullcodeline": "op_params, GetTensorShape(input), GetTensorData<float>(input),"
    },
    {
        "line": 78,
        "fullcodeline": "GetTensorShape(filter), GetTensorData<float>(filter),"
    },
    {
        "line": 79,
        "fullcodeline": "GetTensorShape(bias), GetTensorData<float>(bias),"
    },
    {
        "line": 80,
        "fullcodeline": "GetTensorShape(output), GetTensorData<float>(output),"
    },
    {
        "line": 81,
        "fullcodeline": "CpuBackendContext::GetFromContext(context));"
    },
    {
        "line": 53,
        "fullcodeline": "input_shape, GetTensorData<float>(input),    // Disable formatting"
    },
    {
        "line": 54,
        "fullcodeline": "filter_shape, GetTensorData<float>(filter),  // Disable formatting"
    },
    {
        "line": 55,
        "fullcodeline": "bias_shape, GetTensorData<float>(bias),      // Disable formatting"
    },
    {
        "line": 56,
        "fullcodeline": "output_shape, GetTensorData<float>(output));"
    },
    {
        "line": 57,
        "fullcodeline": "} else if (sparsity.dim_metadata_size == kDimMetadataSizeBlockSparse &&"
    },
    {
        "line": 58,
        "fullcodeline": "sparsity.dim_metadata[2].dense_size == 4) {"
    },
    {
        "line": 60,
        "fullcodeline": "optimized_ops::FullyConnectedSparseWeight1x4("
    },
    {
        "line": 62,
        "fullcodeline": "input_shape, GetTensorData<float>(input),    // Disable formatting"
    },
    {
        "line": 63,
        "fullcodeline": "filter_shape, GetTensorData<float>(filter),  // Disable formatting"
    },
    {
        "line": 64,
        "fullcodeline": "bias_shape, GetTensorData<float>(bias),      // Disable formatting"
    },
    {
        "line": 65,
        "fullcodeline": "output_shape, GetTensorData<float>(output),"
    },
    {
        "line": 66,
        "fullcodeline": "CpuBackendContext::GetFromContext(context));"
    },
    {
        "line": 68,
        "fullcodeline": "TF_LITE_KERNEL_LOG(context,"
    }
]