def export(db_instance, request, queue_name):
    action = request.query_params.get('action', None)
    filename = request.query_params.get('filename', None)

    if action not in (None, 'download'):
        raise serializers.ValidationError(
            "Unexpected action specified for the request")

    if isinstance(db_instance, Task):
        obj_type = 'task'
        logger = slogger.task[db_instance.pk]
        Exporter = TaskExporter
        cache_ttl = TASK_CACHE_TTL
        use_target_storage_conf = request.query_params.get('use_default_location', True)
    elif isinstance(db_instance, Project):
        obj_type = 'project'
        logger = slogger.project[db_instance.pk]
        Exporter = ProjectExporter
        cache_ttl = PROJECT_CACHE_TTL
        use_target_storage_conf = request.query_params.get('use_default_location', True)
    else:
        raise Exception(
            "Unexpected type of db_instance: {}".format(type(db_instance)))
    use_settings = to_bool(use_target_storage_conf)
    obj = db_instance if use_settings else request.query_params
    location_conf = get_location_configuration(
        obj=obj,
        use_settings=use_settings,
        field_name=StorageType.TARGET
    )

    last_instance_update_time = timezone.localtime(db_instance.updated_date)

    queue = django_rq.get_queue(queue_name)
    rq_id = f"export:{obj_type}.id{db_instance.pk}-by-{request.user}"
    rq_job = queue.fetch_job(rq_id)

    if rq_job:
        rq_request = rq_job.meta.get('request', None)
        request_time = rq_request.get("timestamp", None) if rq_request else None
        if request_time is None or request_time < last_instance_update_time:
            # in case the server is configured with ONE_RUNNING_JOB_IN_QUEUE_PER_USER
            # we have to enqueue dependent jobs after canceling one
            rq_job.cancel(enqueue_dependents=settings.ONE_RUNNING_JOB_IN_QUEUE_PER_USER)
            rq_job.delete()
            rq_job = None

    timestamp = datetime.strftime(last_instance_update_time, "%Y_%m_%d_%H_%M_%S")
    location = location_conf.get('location')

    if action == "download":
        if location != Location.LOCAL:
            return Response('Action "download" is only supported for a local backup location', status=status.HTTP_400_BAD_REQUEST)

        if not rq_job or not rq_job.is_finished:
            return Response('Backup has not finished', status=status.HTTP_400_BAD_REQUEST)

        file_path = rq_job.return_value()

        if not file_path:
            return Response('A result for exporting job was not found for finished RQ job', status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        elif not os.path.exists(file_path):
            return Response('The result file does not exist in export cache', status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        filename = filename or build_backup_file_name(
            class_name=obj_type,
            identifier=db_instance.name,
            timestamp=timestamp,
            extension=os.path.splitext(file_path)[1]
        )

        rq_job.delete()
        return sendfile(request, file_path, attachment=True,
            attachment_filename=filename)

    if rq_job:
        if rq_job.is_finished:
            if location == Location.LOCAL:
                return Response(status=status.HTTP_201_CREATED)

            elif location == Location.CLOUD_STORAGE:
                rq_job.delete()
                return Response(status=status.HTTP_200_OK)
            else:
                raise NotImplementedError()
        elif rq_job.is_failed:
            exc_info = rq_job.meta.get('formatted_exception', str(rq_job.exc_info))
            rq_job.delete()
            return Response(exc_info,
                status=status.HTTP_500_INTERNAL_SERVER_ERROR)
        else:
            return Response(status=status.HTTP_202_ACCEPTED)

    ttl = dm.views.PROJECT_CACHE_TTL.total_seconds()
    user_id = request.user.id

    func = _create_backup if location == Location.LOCAL else export_resource_to_cloud_storage
    func_args = (db_instance, Exporter, '{}_backup.zip'.format(obj_type), logger, cache_ttl)

    if location == Location.CLOUD_STORAGE:
        try:
            storage_id = location_conf['storage_id']
        except KeyError:
            raise serializers.ValidationError(
                'Cloud storage location was selected as the destination,'
                ' but cloud storage id was not specified')

        db_storage = get_cloud_storage_for_import_or_export(
            storage_id=storage_id, request=request,
            is_default=location_conf['is_default'])
        filename_pattern = build_backup_file_name(
            class_name=obj_type,
            identifier=db_instance.name,
            timestamp=timestamp,
        )
        func_args = (db_storage, filename, filename_pattern, _create_backup) + func_args

    with get_rq_lock_by_user(queue, user_id):
        queue.enqueue_call(
            func=func,
            args=func_args,
            job_id=rq_id,
            meta=get_rq_job_meta(request=request, db_obj=db_instance),
            depends_on=define_dependent_job(queue, user_id, rq_id=rq_id),
            result_ttl=ttl,
            failure_ttl=ttl,
        )
    return Response(status=status.HTTP_202_ACCEPTED)
