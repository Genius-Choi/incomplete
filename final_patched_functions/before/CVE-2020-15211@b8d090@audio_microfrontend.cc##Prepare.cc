TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  auto* data =
      reinterpret_cast<TfLiteAudioMicrofrontendParams*>(node->user_data);

  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);
  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);

  const TfLiteTensor* input = GetInput(context, node, kInputTensor);
  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 1);

  TF_LITE_ENSURE_EQ(context, input->type, kTfLiteInt16);
  output->type = kTfLiteInt32;
  if (data->out_float) {
    output->type = kTfLiteFloat32;
  }

  TfLiteIntArray* output_size = TfLiteIntArrayCreate(2);
  int num_frames = 0;
  if (input->dims->data[0] >= data->state->window.size) {
    num_frames = (input->dims->data[0] - data->state->window.size) /
                     data->state->window.step / data->frame_stride +
                 1;
  }
  output_size->data[0] = num_frames;
  output_size->data[1] = data->state->filterbank.num_channels *
                         (1 + data->left_context + data->right_context);

  return context->ResizeTensor(context, output, output_size);
}
