        def fetch_and_build_idx(archive_id, decrypted_repository, chunk_idx):
            nonlocal processed_item_metadata_bytes
            nonlocal processed_item_metadata_chunks
            csize, data = decrypted_repository.get(archive_id)
            chunk_idx.add(archive_id, 1, len(data))
            archive = ArchiveItem(internal_dict=msgpack.unpackb(data))
            if archive.version not in (1, 2):  # legacy
                raise Exception("Unknown archive metadata version")
            if archive.version == 1:
                items = archive.items
            elif archive.version == 2:
                items = []
                for chunk_id, (csize, data) in zip(archive.item_ptrs, decrypted_repository.get_many(archive.item_ptrs)):
                    chunk_idx.add(chunk_id, 1, len(data))
                    ids = msgpack.unpackb(data)
                    items.extend(ids)
            sync = CacheSynchronizer(chunk_idx)
            for item_id, (csize, data) in zip(items, decrypted_repository.get_many(items)):
                chunk_idx.add(item_id, 1, len(data))
                processed_item_metadata_bytes += len(data)
                processed_item_metadata_chunks += 1
                sync.feed(data)
            if self.do_cache:
                write_archive_index(archive_id, chunk_idx)
