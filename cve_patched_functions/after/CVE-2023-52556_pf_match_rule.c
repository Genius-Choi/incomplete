pf_match_rule(struct pf_test_ctx *ctx, struct pf_ruleset *ruleset)
{
	struct pf_rule *r;
	struct pf_anchor *child = NULL;
	int target;

	pf_anchor_stack_init();
enter_ruleset:
	r = TAILQ_FIRST(ruleset->rules.active.ptr);
	while (r != NULL) {
		PF_TEST_ATTRIB(r->rule_flag & PFRULE_EXPIRED,
		    TAILQ_NEXT(r, entries));
		r->evaluations++;
		PF_TEST_ATTRIB(
		    (pfi_kif_match(r->kif, ctx->pd->kif) == r->ifnot),
			r->skip[PF_SKIP_IFP].ptr);
		PF_TEST_ATTRIB((r->direction && r->direction != ctx->pd->dir),
			r->skip[PF_SKIP_DIR].ptr);
		PF_TEST_ATTRIB((r->onrdomain >= 0  &&
		    (r->onrdomain == ctx->pd->rdomain) == r->ifnot),
			r->skip[PF_SKIP_RDOM].ptr);
		PF_TEST_ATTRIB((r->af && r->af != ctx->pd->af),
			r->skip[PF_SKIP_AF].ptr);
		PF_TEST_ATTRIB((r->proto && r->proto != ctx->pd->proto),
			r->skip[PF_SKIP_PROTO].ptr);
		PF_TEST_ATTRIB((PF_MISMATCHAW(&r->src.addr, &ctx->pd->nsaddr,
		    ctx->pd->naf, r->src.neg, ctx->pd->kif,
		    ctx->act.rtableid)),
			r->skip[PF_SKIP_SRC_ADDR].ptr);
		PF_TEST_ATTRIB((PF_MISMATCHAW(&r->dst.addr, &ctx->pd->ndaddr,
		    ctx->pd->af, r->dst.neg, NULL, ctx->act.rtableid)),
			r->skip[PF_SKIP_DST_ADDR].ptr);

		switch (ctx->pd->virtual_proto) {
		case PF_VPROTO_FRAGMENT:
			/* tcp/udp only. port_op always 0 in other cases */
			PF_TEST_ATTRIB((r->src.port_op || r->dst.port_op),
				TAILQ_NEXT(r, entries));
			PF_TEST_ATTRIB((ctx->pd->proto == IPPROTO_TCP &&
			    r->flagset),
				TAILQ_NEXT(r, entries));
			/* icmp only. type/code always 0 in other cases */
			PF_TEST_ATTRIB((r->type || r->code),
				TAILQ_NEXT(r, entries));
			/* tcp/udp only. {uid|gid}.op always 0 in other cases */
			PF_TEST_ATTRIB((r->gid.op || r->uid.op),
				TAILQ_NEXT(r, entries));
			break;

		case IPPROTO_TCP:
			PF_TEST_ATTRIB(((r->flagset & ctx->th->th_flags) !=
			    r->flags),
				TAILQ_NEXT(r, entries));
			PF_TEST_ATTRIB((r->os_fingerprint != PF_OSFP_ANY &&
			    !pf_osfp_match(pf_osfp_fingerprint(ctx->pd),
			    r->os_fingerprint)),
				TAILQ_NEXT(r, entries));
			/* FALLTHROUGH */

		case IPPROTO_UDP:
			/* tcp/udp only. port_op always 0 in other cases */
			PF_TEST_ATTRIB((r->src.port_op &&
			    !pf_match_port(r->src.port_op, r->src.port[0],
			    r->src.port[1], ctx->pd->nsport)),
				r->skip[PF_SKIP_SRC_PORT].ptr);
			PF_TEST_ATTRIB((r->dst.port_op &&
			    !pf_match_port(r->dst.port_op, r->dst.port[0],
			    r->dst.port[1], ctx->pd->ndport)),
				r->skip[PF_SKIP_DST_PORT].ptr);
			/* tcp/udp only. uid.op always 0 in other cases */
			PF_TEST_ATTRIB((r->uid.op && (ctx->pd->lookup.done ||
			    (ctx->pd->lookup.done =
			    pf_socket_lookup(ctx->pd), 1)) &&
			    !pf_match_uid(r->uid.op, r->uid.uid[0],
			    r->uid.uid[1], ctx->pd->lookup.uid)),
				TAILQ_NEXT(r, entries));
			/* tcp/udp only. gid.op always 0 in other cases */
			PF_TEST_ATTRIB((r->gid.op && (ctx->pd->lookup.done ||
			    (ctx->pd->lookup.done =
			    pf_socket_lookup(ctx->pd), 1)) &&
			    !pf_match_gid(r->gid.op, r->gid.gid[0],
			    r->gid.gid[1], ctx->pd->lookup.gid)),
				TAILQ_NEXT(r, entries));
			break;

		case IPPROTO_ICMP:
			/* icmp only. type always 0 in other cases */
			PF_TEST_ATTRIB((r->type &&
			    r->type != ctx->icmptype + 1),
				TAILQ_NEXT(r, entries));
			/* icmp only. type always 0 in other cases */
			PF_TEST_ATTRIB((r->code &&
			    r->code != ctx->icmpcode + 1),
				TAILQ_NEXT(r, entries));
			/* icmp only. don't create states on replies */
			PF_TEST_ATTRIB((r->keep_state && !ctx->state_icmp &&
			    (r->rule_flag & PFRULE_STATESLOPPY) == 0 &&
			    ctx->icmp_dir != PF_IN),
				TAILQ_NEXT(r, entries));
			break;

		case IPPROTO_ICMPV6:
			/* icmp only. type always 0 in other cases */
			PF_TEST_ATTRIB((r->type &&
			    r->type != ctx->icmptype + 1),
				TAILQ_NEXT(r, entries));
			/* icmp only. type always 0 in other cases */
			PF_TEST_ATTRIB((r->code &&
			    r->code != ctx->icmpcode + 1),
				TAILQ_NEXT(r, entries));
			/* icmp only. don't create states on replies */
			PF_TEST_ATTRIB((r->keep_state && !ctx->state_icmp &&
			    (r->rule_flag & PFRULE_STATESLOPPY) == 0 &&
			    ctx->icmp_dir != PF_IN &&
			    ctx->icmptype != ND_NEIGHBOR_ADVERT),
				TAILQ_NEXT(r, entries));
			break;

		default:
			break;
		}

		PF_TEST_ATTRIB((r->rule_flag & PFRULE_FRAGMENT &&
		    ctx->pd->virtual_proto != PF_VPROTO_FRAGMENT),
			TAILQ_NEXT(r, entries));
		PF_TEST_ATTRIB((r->tos && !(r->tos == ctx->pd->tos)),
			TAILQ_NEXT(r, entries));
		PF_TEST_ATTRIB((r->prob &&
		    r->prob <= arc4random_uniform(UINT_MAX - 1) + 1),
			TAILQ_NEXT(r, entries));
		PF_TEST_ATTRIB((r->match_tag &&
		    !pf_match_tag(ctx->pd->m, r, &ctx->tag)),
			TAILQ_NEXT(r, entries));
		PF_TEST_ATTRIB((r->rcv_kif && pf_match_rcvif(ctx->pd->m, r) ==
		    r->rcvifnot),
			TAILQ_NEXT(r, entries));
		PF_TEST_ATTRIB((r->prio &&
		    (r->prio == PF_PRIO_ZERO ? 0 : r->prio) !=
		    ctx->pd->m->m_pkthdr.pf.prio),
			TAILQ_NEXT(r, entries));

		/* must be last! */
		if (r->pktrate.limit) {
			pf_add_threshold(&r->pktrate);
			PF_TEST_ATTRIB((pf_check_threshold(&r->pktrate)),
				TAILQ_NEXT(r, entries));
		}

		/* FALLTHROUGH */
		if (r->tag)
			ctx->tag = r->tag;
		if (r->anchor == NULL) {

			if (r->rule_flag & PFRULE_ONCE) {
				u_int32_t	rule_flag;

				rule_flag = r->rule_flag;
				if (((rule_flag & PFRULE_EXPIRED) == 0) &&
				    atomic_cas_uint(&r->rule_flag, rule_flag,
				    rule_flag | PFRULE_EXPIRED) == rule_flag) {
					r->exptime = gettime();
				} else {
					r = TAILQ_NEXT(r, entries);
					continue;
				}
			}

			if (r->action == PF_MATCH) {
				if ((ctx->ri = pool_get(&pf_rule_item_pl,
				    PR_NOWAIT)) == NULL) {
					REASON_SET(&ctx->reason, PFRES_MEMORY);
					return (PF_TEST_FAIL);
				}
				ctx->ri->r = r;
				/* order is irrelevant */
				SLIST_INSERT_HEAD(&ctx->rules, ctx->ri, entry);
				ctx->ri = NULL;
				pf_rule_to_actions(r, &ctx->act);
				if (r->rule_flag & PFRULE_AFTO)
					ctx->pd->naf = r->naf;
				if (pf_get_transaddr(r, ctx->pd, ctx->sns,
				    &ctx->nr) == -1) {
					REASON_SET(&ctx->reason,
					    PFRES_TRANSLATE);
					return (PF_TEST_FAIL);
				}
#if NPFLOG > 0
				if (r->log) {
					REASON_SET(&ctx->reason, PFRES_MATCH);
					pflog_packet(ctx->pd, ctx->reason, r,
					    ctx->a, ruleset, NULL);
				}
#endif	/* NPFLOG > 0 */
			} else {
				/*
				 * found matching r
				 */
				*ctx->rm = r;
				/*
				 * anchor, with ruleset, where r belongs to
				 */
				*ctx->am = ctx->a;
				/*
				 * ruleset where r belongs to
				 */
				*ctx->rsm = ruleset;
				/*
				 * ruleset, where anchor belongs to.
				 */
				ctx->arsm = ctx->aruleset;
			}

#if NPFLOG > 0
			if (ctx->act.log & PF_LOG_MATCHES)
				pf_log_matches(ctx->pd, r, ctx->a, ruleset,
				    &ctx->rules);
#endif	/* NPFLOG > 0 */

			if (r->quick)
				return (PF_TEST_QUICK);
		} else {
			ctx->a = r;
			ctx->aruleset = &r->anchor->ruleset;
			if (r->anchor_wildcard) {
				RB_FOREACH(child, pf_anchor_node,
				    &r->anchor->children) {
					if (pf_anchor_stack_push(ruleset, r, child,
					    PF_NEXT_CHILD) != 0)
						return (PF_TEST_FAIL);

					ruleset = &child->ruleset;
					goto enter_ruleset;
next_child:
					continue;	/* with RB_FOREACH() */
				}
			} else {
				if (pf_anchor_stack_push(ruleset, r, child,
				    PF_NEXT_RULE) != 0)
					return (PF_TEST_FAIL);

				ruleset = &r->anchor->ruleset;
				child = NULL;
				goto enter_ruleset;
next_rule:
				;
			}
		}
		r = TAILQ_NEXT(r, entries);
	}

	if (pf_anchor_stack_pop(&ruleset, &r, &child, &target) == 0) {
		/* stop if any rule matched within quick anchors. */
		if (r->quick == PF_TEST_QUICK && *ctx->am == r)
			return (PF_TEST_QUICK);

		switch (target) {
		case PF_NEXT_CHILD:
			goto next_child;
		case PF_NEXT_RULE:
			goto next_rule;
		default:
			panic("%s: unknown jump target", __func__);
		}
	}

	return (PF_TEST_OK);
}
