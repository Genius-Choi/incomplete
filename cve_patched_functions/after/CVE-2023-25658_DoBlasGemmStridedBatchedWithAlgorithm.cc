tsl::Status CUDABlas::DoBlasGemmStridedBatchedWithAlgorithm(
    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,
    uint64_t n, uint64 k, const void *alpha, const DeviceMemoryBase &a,
    blas::DataType type_a, int lda, int64_t stride_a, const DeviceMemoryBase &b,
    blas::DataType type_b, int ldb, int64_t stride_b, const void *beta,
    DeviceMemoryBase *c, blas::DataType type_c, int ldc, int64_t stride_c,
    int batch_count, blas::ComputationType computation_type,
    blas::AlgorithmType algorithm, blas::ComputePrecision precision,
    blas::ProfileResult *output_profile_result) {
  TF_ASSIGN_OR_RETURN(
      cublasMath_t math_type,
      GetMathTypeForGemmEx(stream, algorithm, type_a, type_b, precision));
  TF_ASSIGN_OR_RETURN(auto timer, StartGpuTimerForProfile(
                                      stream, parent_, output_profile_result));

  cudaDataType_t cuda_in_type = AsCudaDataType(type_a);

#if CUDA_VERSION >= 11000
  // Workaround CUDA bug where batched GEMM is erroneously marked as
  // unsupported by manually unbatching it on Pascal.
  if (cuda_in_type == CUDA_R_16BF &&
      !stream->GetCudaComputeCapability().IsAtLeast(7)) {
    for (int batch = 0; batch < batch_count; ++batch) {
      const auto *a_matrix = reinterpret_cast<const __nv_bfloat16 *>(
          static_cast<const Eigen::bfloat16 *>(a.opaque()) + batch * stride_a);
      const auto *b_matrix = reinterpret_cast<const __nv_bfloat16 *>(
          static_cast<const Eigen::bfloat16 *>(b.opaque()) + batch * stride_b);
      auto *c_matrix = reinterpret_cast<__nv_bfloat16 *>(
          static_cast<Eigen::bfloat16 *>(c->opaque()) + batch * stride_c);
      TF_RETURN_IF_ERROR(DoBlasInternalImpl(
          AS_LAMBDA(cublasGemmEx), stream, /*pointer_mode_host=*/true,
          math_type, AsCublasOperation(transa), AsCublasOperation(transb), m, n,
          k, static_cast<const float *>(alpha), a_matrix, CUDA_R_16BF, lda,
          b_matrix, CUDA_R_16BF, ldb, static_cast<const float *>(beta),
          c_matrix, CUDA_R_16BF, ldc, AsCublasComputeType(computation_type),
          static_cast<cublasGemmAlgo_t>(algorithm)));
    }
    TF_RETURN_IF_ERROR(PopulateProfileFromTimer(timer.get(), algorithm,
                                                output_profile_result, stream));
    return tsl::OkStatus();
  }
#endif

  TF_RETURN_IF_ERROR(DoBlasInternalImpl(
      AS_LAMBDA(cublasGemmStridedBatchedEx), stream, /*pointer_mode_host=*/true,
      math_type, AsCublasOperation(transa), AsCublasOperation(transb), m, n, k,
      alpha, a.opaque(), cuda_in_type, lda, stride_a, b.opaque(), cuda_in_type,
      ldb, stride_b, beta, c->opaque(), AsCudaDataType(type_c), ldc, stride_c,
      batch_count, AsCublasComputeType(computation_type),
      static_cast<cublasGemmAlgo_t>(algorithm)));
  TF_RETURN_IF_ERROR(PopulateProfileFromTimer(timer.get(), algorithm,
                                              output_profile_result, stream));
  return ::tsl::OkStatus();
}
