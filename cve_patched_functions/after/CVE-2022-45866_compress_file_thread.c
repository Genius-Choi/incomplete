void *compress_file_thread(void *arg)
{
    size_t read;
    do
    {
        size_t u, thread_id = (size_t)arg;
        unsigned int crc_r;
        unsigned long long my_chunk;

        update_statusbar("c", false);

        pthread_mutex_lock(&disk_write_mutex);
        my_chunk = chunks_read;
        chunks_read++;

        pthread_mutex_lock(&disk_read_mutex);
        pthread_mutex_unlock(&disk_write_mutex);
        read = aread(src[thread_id], compress_chunk_size);
        pthread_mutex_unlock(&disk_read_mutex);

        if (read == 0)
            return 0;

        u = QLZ_COMPRESS(src[thread_id], dst[thread_id], read, compression_level, scratch[thread_id]);
        crc_r = adler((unsigned char *)dst[thread_id], u, 0x00010000);

        // Could be beautified into not using yield. Schedules writes to occur in correct order.
        for(;;)
        {
            pthread_mutex_lock(&disk_write_mutex);
            if(my_chunk == chunks_written)
                break;
            else
            {
                pthread_mutex_unlock(&disk_write_mutex);
                utils_yield();
            }
        }

        try_awrite("NEWBNEWB", 8);
        fwrite64(current_file_payload);
        payload_counter += read;
        current_file_payload += read;
        fwrite32(crc_r);
        chunks_written++;
        try_awrite(dst[thread_id], u);
        pthread_mutex_unlock(&disk_write_mutex);
    } while (read == compress_chunk_size);

    return 0;
}
