void FilterUtility::setTimeoutHeaders(uint64_t elapsed_time, const TimeoutData& timeout,
                                      const RouteEntry& route,
                                      Http::RequestHeaderMap& request_headers,
                                      bool insert_envoy_expected_request_timeout_ms,
                                      bool grpc_request, bool per_try_timeout_hedging_enabled) {

  const uint64_t global_timeout = timeout.global_timeout_.count();

  // See if there is any timeout to write in the expected timeout header.
  uint64_t expected_timeout = timeout.per_try_timeout_.count();

  // Use the global timeout if no per try timeout was specified or if we're
  // doing hedging when there are per try timeouts. Either of these scenarios
  // mean that the upstream server can use the full global timeout.
  if (per_try_timeout_hedging_enabled || expected_timeout == 0) {
    expected_timeout = global_timeout;
  }

  // If the expected timeout is 0 set no timeout, as Envoy treats 0 as infinite timeout.
  if (expected_timeout > 0) {

    if (global_timeout > 0) {
      if (elapsed_time >= global_timeout) {
        // We are out of time, but 0 would be an infinite timeout. So instead we send a 1ms timeout
        // and assume the timers armed by onRequestComplete() will fire very soon.
        expected_timeout = 1;
      } else {
        expected_timeout = std::min(expected_timeout, global_timeout - elapsed_time);
      }
    }

    if (insert_envoy_expected_request_timeout_ms) {
      request_headers.setEnvoyExpectedRequestTimeoutMs(expected_timeout);
    }

    // If we've configured max_grpc_timeout, override the grpc-timeout header with
    // the expected timeout. This ensures that the optional per try timeout is reflected
    // in grpc-timeout, ensuring that the upstream gRPC server is aware of the actual timeout.
    if (grpc_request && !route.usingNewTimeouts() && route.maxGrpcTimeout()) {
      Grpc::Common::toGrpcTimeout(std::chrono::milliseconds(expected_timeout), request_headers);
    }
  }
}
