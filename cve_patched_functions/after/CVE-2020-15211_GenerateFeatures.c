void GenerateFeatures(TfLiteAudioMicrofrontendParams* data,
                      const TfLiteTensor* input, TfLiteTensor* output) {
  const int16_t* audio_data = GetTensorData<int16_t>(input);
  int64_t audio_size = input->dims->data[0];

  T* filterbanks_flat = GetTensorData<T>(output);

  int num_frames = 0;
  if (audio_size >= data->state->window.size) {
    num_frames = (input->dims->data[0] - data->state->window.size) /
                     data->state->window.step +
                 1;
  }
  std::vector<std::vector<T>> frame_buffer(num_frames);

  int frame_index = 0;
  while (audio_size > 0) {
    size_t num_samples_read;
    struct FrontendOutput output = FrontendProcessSamples(
        data->state, audio_data, audio_size, &num_samples_read);
    audio_data += num_samples_read;
    audio_size -= num_samples_read;

    if (output.values != nullptr) {
      frame_buffer[frame_index].reserve(output.size);
      int i;
      for (i = 0; i < output.size; ++i) {
        frame_buffer[frame_index].push_back(static_cast<T>(output.values[i]) /
                                            data->out_scale);
      }
      ++frame_index;
    }
  }

  int index = 0;
  std::vector<T> pad(data->state->filterbank.num_channels, 0);
  int anchor;
  for (anchor = 0; anchor < frame_buffer.size(); anchor += data->frame_stride) {
    int frame;
    for (frame = anchor - data->left_context;
         frame <= anchor + data->right_context; ++frame) {
      std::vector<T>* feature;
      if (data->zero_padding && (frame < 0 || frame >= frame_buffer.size())) {
        feature = &pad;
      } else if (frame < 0) {
        feature = &frame_buffer[0];
      } else if (frame >= frame_buffer.size()) {
        feature = &frame_buffer[frame_buffer.size() - 1];
      } else {
        feature = &frame_buffer[frame];
      }
      for (auto f : *feature) {
        filterbanks_flat[index++] = f;
      }
    }
  }
}
