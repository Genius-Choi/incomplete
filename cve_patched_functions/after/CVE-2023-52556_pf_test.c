pf_test(sa_family_t af, int fwdir, struct ifnet *ifp, struct mbuf **m0)
{
#if NCARP > 0
	struct ifnet		*ifp0;
#endif
	struct pfi_kif		*kif;
	u_short			 action, reason = 0;
	struct pf_rule		*a = NULL, *r = &pf_default_rule;
	struct pf_state		*st = NULL;
	struct pf_state_key_cmp	 key;
	struct pf_ruleset	*ruleset = NULL;
	struct pf_pdesc		 pd;
	int			 dir = (fwdir == PF_FWD) ? PF_OUT : fwdir;
	u_int32_t		 qid, pqid = 0;
	int			 have_pf_lock = 0;

	if (!pf_status.running)
		return (PF_PASS);

#if NCARP > 0
	if (ifp->if_type == IFT_CARP &&
		(ifp0 = if_get(ifp->if_carpdevidx)) != NULL) {
		kif = (struct pfi_kif *)ifp0->if_pf_kif;
		if_put(ifp0);
	} else
#endif /* NCARP */
		kif = (struct pfi_kif *)ifp->if_pf_kif;

	if (kif == NULL) {
		DPFPRINTF(LOG_ERR,
		    "%s: kif == NULL, if_xname %s", __func__, ifp->if_xname);
		return (PF_DROP);
	}
	if (kif->pfik_flags & PFI_IFLAG_SKIP)
		return (PF_PASS);

#ifdef DIAGNOSTIC
	if (((*m0)->m_flags & M_PKTHDR) == 0)
		panic("non-M_PKTHDR is passed to pf_test");
#endif /* DIAGNOSTIC */

	if ((*m0)->m_pkthdr.pf.flags & PF_TAG_GENERATED)
		return (PF_PASS);

	if ((*m0)->m_pkthdr.pf.flags & PF_TAG_DIVERTED_PACKET) {
		(*m0)->m_pkthdr.pf.flags &= ~PF_TAG_DIVERTED_PACKET;
		return (PF_PASS);
	}

	if ((*m0)->m_pkthdr.pf.flags & PF_TAG_REFRAGMENTED) {
		(*m0)->m_pkthdr.pf.flags &= ~PF_TAG_REFRAGMENTED;
		return (PF_PASS);
	}

	action = pf_setup_pdesc(&pd, af, dir, kif, *m0, &reason);
	if (action != PF_PASS) {
#if NPFLOG > 0
		pd.pflog |= PF_LOG_FORCE;
#endif	/* NPFLOG > 0 */
		goto done;
	}

	/* packet normalization and reassembly */
	switch (pd.af) {
	case AF_INET:
		action = pf_normalize_ip(&pd, &reason);
		break;
#ifdef INET6
	case AF_INET6:
		action = pf_normalize_ip6(&pd, &reason);
		break;
#endif	/* INET6 */
	}
	*m0 = pd.m;
	/* if packet sits in reassembly queue, return without error */
	if (pd.m == NULL)
		return PF_PASS;

	if (action != PF_PASS) {
#if NPFLOG > 0
		pd.pflog |= PF_LOG_FORCE;
#endif	/* NPFLOG > 0 */
		goto done;
	}

	/* if packet has been reassembled, update packet description */
	if (pf_status.reass && pd.virtual_proto == PF_VPROTO_FRAGMENT) {
		action = pf_setup_pdesc(&pd, af, dir, kif, pd.m, &reason);
		if (action != PF_PASS) {
#if NPFLOG > 0
			pd.pflog |= PF_LOG_FORCE;
#endif	/* NPFLOG > 0 */
			goto done;
		}
	}
	pd.m->m_pkthdr.pf.flags |= PF_TAG_PROCESSED;

	/*
	 * Avoid pcb-lookups from the forwarding path.  They should never
	 * match and would cause MP locking problems.
	 */
	if (fwdir == PF_FWD) {
		pd.lookup.done = -1;
		pd.lookup.uid = -1;
		pd.lookup.gid = -1;
		pd.lookup.pid = NO_PID;
	}

	switch (pd.virtual_proto) {

	case PF_VPROTO_FRAGMENT: {
		/*
		 * handle fragments that aren't reassembled by
		 * normalization
		 */
		PF_LOCK();
		have_pf_lock = 1;
		action = pf_test_rule(&pd, &r, &st, &a, &ruleset, &reason);
		st = pf_state_ref(st);
		if (action != PF_PASS)
			REASON_SET(&reason, PFRES_FRAG);
		break;
	}

	case IPPROTO_ICMP: {
		if (pd.af != AF_INET) {
			action = PF_DROP;
			REASON_SET(&reason, PFRES_NORM);
			DPFPRINTF(LOG_NOTICE,
			    "dropping IPv6 packet with ICMPv4 payload");
			break;
		}
		PF_STATE_ENTER_READ();
		action = pf_test_state_icmp(&pd, &st, &reason);
		st = pf_state_ref(st);
		PF_STATE_EXIT_READ();
		if (action == PF_PASS || action == PF_AFRT) {
#if NPFSYNC > 0
			pfsync_update_state(st);
#endif /* NPFSYNC > 0 */
			r = st->rule.ptr;
			a = st->anchor.ptr;
#if NPFLOG > 0
			pd.pflog |= st->log;
#endif	/* NPFLOG > 0 */
		} else if (st == NULL) {
			PF_LOCK();
			have_pf_lock = 1;
			action = pf_test_rule(&pd, &r, &st, &a, &ruleset,
			    &reason);
			st = pf_state_ref(st);
		}
		break;
	}

#ifdef INET6
	case IPPROTO_ICMPV6: {
		if (pd.af != AF_INET6) {
			action = PF_DROP;
			REASON_SET(&reason, PFRES_NORM);
			DPFPRINTF(LOG_NOTICE,
			    "dropping IPv4 packet with ICMPv6 payload");
			break;
		}
		PF_STATE_ENTER_READ();
		action = pf_test_state_icmp(&pd, &st, &reason);
		st = pf_state_ref(st);
		PF_STATE_EXIT_READ();
		if (action == PF_PASS || action == PF_AFRT) {
#if NPFSYNC > 0
			pfsync_update_state(st);
#endif /* NPFSYNC > 0 */
			r = st->rule.ptr;
			a = st->anchor.ptr;
#if NPFLOG > 0
			pd.pflog |= st->log;
#endif	/* NPFLOG > 0 */
		} else if (st == NULL) {
			PF_LOCK();
			have_pf_lock = 1;
			action = pf_test_rule(&pd, &r, &st, &a, &ruleset,
			    &reason);
			st = pf_state_ref(st);
		}
		break;
	}
#endif /* INET6 */

	default:
		if (pd.virtual_proto == IPPROTO_TCP) {
			if (pd.dir == PF_IN && (pd.hdr.tcp.th_flags &
			    (TH_SYN|TH_ACK)) == TH_SYN &&
			    pf_synflood_check(&pd)) {
				PF_LOCK();
				have_pf_lock = 1;
				pf_syncookie_send(&pd);
				action = PF_DROP;
				break;
			}
			if ((pd.hdr.tcp.th_flags & TH_ACK) && pd.p_len == 0)
				pqid = 1;
			action = pf_normalize_tcp(&pd);
			if (action == PF_DROP)
				break;
		}

		key.af = pd.af;
		key.proto = pd.virtual_proto;
		key.rdomain = pd.rdomain;
		pf_addrcpy(&key.addr[pd.sidx], pd.src, key.af);
		pf_addrcpy(&key.addr[pd.didx], pd.dst, key.af);
		key.port[pd.sidx] = pd.osport;
		key.port[pd.didx] = pd.odport;
		key.hash = pd.hash;

		PF_STATE_ENTER_READ();
		action = pf_find_state(&pd, &key, &st);
		st = pf_state_ref(st);
		PF_STATE_EXIT_READ();

		/* check for syncookies if tcp ack and no active state */
		if (pd.dir == PF_IN && pd.virtual_proto == IPPROTO_TCP &&
		    (st == NULL || (st->src.state >= TCPS_FIN_WAIT_2 &&
		    st->dst.state >= TCPS_FIN_WAIT_2)) &&
		    (pd.hdr.tcp.th_flags & (TH_SYN|TH_ACK|TH_RST)) == TH_ACK &&
		    pf_syncookie_validate(&pd)) {
			struct mbuf	*msyn = pf_syncookie_recreate_syn(&pd);
			if (msyn) {
				action = pf_test(af, fwdir, ifp, &msyn);
				m_freem(msyn);
				if (action == PF_PASS || action == PF_AFRT) {
					PF_STATE_ENTER_READ();
					pf_state_unref(st);
					action = pf_find_state(&pd, &key, &st);
					st = pf_state_ref(st);
					PF_STATE_EXIT_READ();
					if (st == NULL)
						return (PF_DROP);
					st->src.seqhi = st->dst.seqhi =
					    ntohl(pd.hdr.tcp.th_ack) - 1;
					st->src.seqlo =
					    ntohl(pd.hdr.tcp.th_seq) - 1;
					pf_set_protostate(st, PF_PEER_SRC,
					    PF_TCPS_PROXY_DST);
				}
			} else
				action = PF_DROP;
		}

		if (action == PF_MATCH)
			action = pf_test_state(&pd, &st, &reason);

		if (action == PF_PASS || action == PF_AFRT) {
#if NPFSYNC > 0
			pfsync_update_state(st);
#endif /* NPFSYNC > 0 */
			r = st->rule.ptr;
			a = st->anchor.ptr;
#if NPFLOG > 0
			pd.pflog |= st->log;
#endif	/* NPFLOG > 0 */
		} else if (st == NULL) {
			PF_LOCK();
			have_pf_lock = 1;
			action = pf_test_rule(&pd, &r, &st, &a, &ruleset,
			    &reason);
			st = pf_state_ref(st);
		}

		if (pd.virtual_proto == IPPROTO_TCP) {
			if (st) {
				if (st->max_mss)
					pf_normalize_mss(&pd, st->max_mss);
			} else if (r->max_mss)
				pf_normalize_mss(&pd, r->max_mss);
		}

		break;
	}

	if (have_pf_lock != 0)
		PF_UNLOCK();

	/*
	 * At the moment, we rely on NET_LOCK() to prevent removal of items
	 * we've collected above ('r', 'anchor' and 'ruleset').  They'll have
	 * to be refcounted when NET_LOCK() is gone.
	 */

done:
	if (action != PF_DROP) {
		if (st) {
			/* The non-state case is handled in pf_test_rule() */
			if (action == PF_PASS && pd.badopts != 0 &&
			    !(st->state_flags & PFSTATE_ALLOWOPTS)) {
				action = PF_DROP;
				REASON_SET(&reason, PFRES_IPOPTIONS);
#if NPFLOG > 0
				pd.pflog |= PF_LOG_FORCE;
#endif	/* NPFLOG > 0 */
				DPFPRINTF(LOG_NOTICE, "dropping packet with "
				    "ip/ipv6 options in pf_test()");
			}

			pf_scrub(pd.m, st->state_flags, pd.af, st->min_ttl,
			    st->set_tos);
			pf_tag_packet(pd.m, st->tag, st->rtableid[pd.didx]);
			if (pqid || (pd.tos & IPTOS_LOWDELAY)) {
				qid = st->pqid;
				if (st->state_flags & PFSTATE_SETPRIO) {
					pd.m->m_pkthdr.pf.prio =
					    st->set_prio[1];
				}
			} else {
				qid = st->qid;
				if (st->state_flags & PFSTATE_SETPRIO) {
					pd.m->m_pkthdr.pf.prio =
					    st->set_prio[0];
				}
			}
			pd.m->m_pkthdr.pf.delay = st->delay;
		} else {
			pf_scrub(pd.m, r->scrub_flags, pd.af, r->min_ttl,
			    r->set_tos);
			if (pqid || (pd.tos & IPTOS_LOWDELAY)) {
				qid = r->pqid;
				if (r->scrub_flags & PFSTATE_SETPRIO)
					pd.m->m_pkthdr.pf.prio = r->set_prio[1];
			} else {
				qid = r->qid;
				if (r->scrub_flags & PFSTATE_SETPRIO)
					pd.m->m_pkthdr.pf.prio = r->set_prio[0];
			}
			pd.m->m_pkthdr.pf.delay = r->delay;
		}
	}

	if (action == PF_PASS && qid)
		pd.m->m_pkthdr.pf.qid = qid;
	if (pd.dir == PF_IN && st && st->key[PF_SK_STACK])
		pf_mbuf_link_state_key(pd.m, st->key[PF_SK_STACK]);
	if (pd.dir == PF_OUT &&
	    pd.m->m_pkthdr.pf.inp && !pd.m->m_pkthdr.pf.inp->inp_pf_sk &&
	    st && st->key[PF_SK_STACK] && !st->key[PF_SK_STACK]->sk_inp)
		pf_state_key_link_inpcb(st->key[PF_SK_STACK],
		    pd.m->m_pkthdr.pf.inp);

	if (st != NULL && !ISSET(pd.m->m_pkthdr.csum_flags, M_FLOWID)) {
		pd.m->m_pkthdr.ph_flowid = st->key[PF_SK_WIRE]->hash;
		SET(pd.m->m_pkthdr.csum_flags, M_FLOWID);
	}

	/*
	 * connections redirected to loopback should not match sockets
	 * bound specifically to loopback due to security implications,
	 * see in_pcblookup_listen().
	 */
	if (pd.destchg)
		if ((pd.af == AF_INET && (ntohl(pd.dst->v4.s_addr) >>
		    IN_CLASSA_NSHIFT) == IN_LOOPBACKNET) ||
		    (pd.af == AF_INET6 && IN6_IS_ADDR_LOOPBACK(&pd.dst->v6)))
			pd.m->m_pkthdr.pf.flags |= PF_TAG_TRANSLATE_LOCALHOST;
	/* We need to redo the route lookup on outgoing routes. */
	if (pd.destchg && pd.dir == PF_OUT)
		pd.m->m_pkthdr.pf.flags |= PF_TAG_REROUTE;

	if (pd.dir == PF_IN && action == PF_PASS &&
	    (r->divert.type == PF_DIVERT_TO ||
	    r->divert.type == PF_DIVERT_REPLY)) {
		struct pf_divert *divert;

		if ((divert = pf_get_divert(pd.m))) {
			pd.m->m_pkthdr.pf.flags |= PF_TAG_DIVERTED;
			divert->addr = r->divert.addr;
			divert->port = r->divert.port;
			divert->rdomain = pd.rdomain;
			divert->type = r->divert.type;
		}
	}

	if (action == PF_PASS && r->divert.type == PF_DIVERT_PACKET)
		action = PF_DIVERT;

#if NPFLOG > 0
	if (pd.pflog) {
		struct pf_rule_item	*ri;

		if (pd.pflog & PF_LOG_FORCE || r->log & PF_LOG_ALL)
			pflog_packet(&pd, reason, r, a, ruleset, NULL);
		if (st) {
			SLIST_FOREACH(ri, &st->match_rules, entry)
				if (ri->r->log & PF_LOG_ALL)
					pflog_packet(&pd, reason, ri->r, a,
					    ruleset, NULL);
		}
	}
#endif	/* NPFLOG > 0 */

	pf_counters_inc(action, &pd, st, r, a);

	switch (action) {
	case PF_SYNPROXY_DROP:
		m_freem(pd.m);
		/* FALLTHROUGH */
	case PF_DEFER:
		pd.m = NULL;
		action = PF_PASS;
		break;
	case PF_DIVERT:
		switch (pd.af) {
		case AF_INET:
			divert_packet(pd.m, pd.dir, r->divert.port);
			pd.m = NULL;
			break;
#ifdef INET6
		case AF_INET6:
			divert6_packet(pd.m, pd.dir, r->divert.port);
			pd.m = NULL;
			break;
#endif /* INET6 */
		}
		action = PF_PASS;
		break;
#ifdef INET6
	case PF_AFRT:
		if (pf_translate_af(&pd)) {
			action = PF_DROP;
			break;
		}
		pd.m->m_pkthdr.pf.flags |= PF_TAG_GENERATED;
		switch (pd.naf) {
		case AF_INET:
			if (pd.dir == PF_IN) {
				if (ipforwarding == 0) {
					ipstat_inc(ips_cantforward);
					action = PF_DROP;
					break;
				}
				ip_forward(pd.m, ifp, NULL, 1);
			} else
				ip_output(pd.m, NULL, NULL, 0, NULL, NULL, 0);
			break;
		case AF_INET6:
			if (pd.dir == PF_IN) {
				if (ip6_forwarding == 0) {
					ip6stat_inc(ip6s_cantforward);
					action = PF_DROP;
					break;
				}
				ip6_forward(pd.m, NULL, 1);
			} else
				ip6_output(pd.m, NULL, NULL, 0, NULL, NULL);
			break;
		}
		if (action != PF_DROP) {
			pd.m = NULL;
			action = PF_PASS;
		}
		break;
#endif /* INET6 */
	case PF_DROP:
		m_freem(pd.m);
		pd.m = NULL;
		break;
	default:
		if (st && st->rt) {
			switch (pd.af) {
			case AF_INET:
				pf_route(&pd, st);
				break;
#ifdef INET6
			case AF_INET6:
				pf_route6(&pd, st);
				break;
#endif /* INET6 */
			}
		}
		break;
	}

#ifdef INET6
	/* if reassembled packet passed, create new fragments */
	if (pf_status.reass && action == PF_PASS && pd.m && fwdir == PF_FWD &&
	    pd.af == AF_INET6) {
		struct m_tag	*mtag;

		if ((mtag = m_tag_find(pd.m, PACKET_TAG_PF_REASSEMBLED, NULL)))
			action = pf_refragment6(&pd.m, mtag, NULL, NULL, NULL);
	}
#endif	/* INET6 */
	if (st && action != PF_DROP) {
		if (!st->if_index_in && dir == PF_IN)
			st->if_index_in = ifp->if_index;
		else if (!st->if_index_out && dir == PF_OUT)
			st->if_index_out = ifp->if_index;
	}

	*m0 = pd.m;

	pf_state_unref(st);

	return (action);
}
