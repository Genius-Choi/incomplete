Status HloEvaluator::EvaluateInternal(
    HloInstruction* instruction, const ShapeIndex& shape_index,
    bool recursively_evaluate_nonconstant_operands) {
  // Don't need to evaluate this instruction again if it has already been
  // evaluated.
  if (IsAlreadyEvaluated(instruction, shape_index)) {
    return OkStatus();
  }

  if (!recursively_evaluate_nonconstant_operands) {
    if (!hlo_query::AllOperandsAreConstants(*instruction)) {
      return tsl::errors::FailedPrecondition("Not all operands are constants.");
    }
  } else {
    if (instruction->opcode() == HloOpcode::kGetTupleElement) {
      ShapeIndex new_shape_index = shape_index;
      new_shape_index.push_front(instruction->tuple_index());
      TF_RETURN_IF_ERROR(
          EvaluateInternal(instruction->mutable_operand(0), new_shape_index,
                           /*recursively_evaluate_nonconstant_operands=*/true));
    } else if (instruction->opcode() == HloOpcode::kTuple &&
               !shape_index.empty()) {
      ShapeIndex new_shape_index = shape_index;
      int64_t tuple_index = new_shape_index.front();
      new_shape_index.pop_front();
      TF_RETURN_IF_ERROR(EvaluateInternal(
          instruction->mutable_operand(tuple_index), new_shape_index,
          /*recursively_evaluate_nonconstant_operands=*/true));
    } else if (instruction->opcode() == HloOpcode::kParameter) {
      if (!call_graph_cache_) {
        HloModule* module = instruction->GetModule();
        call_graph_cache_ = CallGraph::Build(module);
      }
      if (!tuple_points_to_analysis_cache_) {
        HloModule* module = instruction->GetModule();
        StatusOr<std::unique_ptr<TuplePointsToAnalysis>>
            tuple_points_to_analysis = TuplePointsToAnalysis::Run(module);
        if (tuple_points_to_analysis.ok()) {
          tuple_points_to_analysis_cache_ =
              *std::move(tuple_points_to_analysis);
        }
      }
      if (call_graph_cache_ && tuple_points_to_analysis_cache_) {
        Status argument_eval_status =
            EvaluateParameterFromCallerArgument(instruction, shape_index);
        if (!argument_eval_status.ok()) {
          VLOG(4) << "Failed to evaluate parameter " << instruction->name()
                  << " from caller. Reason: "
                  << argument_eval_status.error_message();
        } else {
          VLOG(4) << "Successfully evaluated parameter: "
                  << instruction->name();
        }
      }
    } else {
      for (HloInstruction* operand : instruction->operands()) {
        TF_RETURN_IF_ERROR(EvaluateInternal(
            operand, /*shape_index=*/{},
            /*recursively_evaluate_nonconstant_operands=*/true));
        // Except for the above and following cases, we do not support handling
        // unknown operands for other HLOs. So mark the result as unknown.
        if ((!GetEvaluatedLiteralFor(operand).IsKnown() &&
             instruction->opcode() != HloOpcode::kCopy &&
             instruction->opcode() != HloOpcode::kCopyStart &&
             instruction->opcode() != HloOpcode::kCopyDone &&
             instruction->opcode() != HloOpcode::kAsyncStart &&
             instruction->opcode() != HloOpcode::kAsyncUpdate &&
             instruction->opcode() != HloOpcode::kAsyncDone &&
             instruction->opcode() != HloOpcode::kWhile)) {
          evaluated_[instruction] =
              Literal::CreateFromShapeWithUnknownLeafArrays(
                  instruction->shape());
          return OkStatus();
        }
      }
    }
  }
  visitor_shape_index_ = shape_index;
  TF_RETURN_IF_ERROR(Preprocess(instruction));
  TF_RETURN_IF_ERROR(instruction->Visit(this));
  TF_RETURN_IF_ERROR(Postprocess(instruction));
  return OkStatus();
}
