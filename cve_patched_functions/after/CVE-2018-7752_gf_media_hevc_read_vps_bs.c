static s32 gf_media_hevc_read_vps_bs(GF_BitStream *bs, HEVCState *hevc, Bool stop_at_vps_ext)
{
	u8 vps_sub_layer_ordering_info_present_flag, vps_extension_flag;
	u32 i, j;
	s32 vps_id = -1;
	HEVC_VPS *vps;
	u8 layer_id_included_flag[MAX_LHVC_LAYERS][64];

	//nalu header already parsed
	vps_id = gf_bs_read_int(bs, 4);

	if (vps_id>=16) return -1;

	vps = &hevc->vps[vps_id];
	vps->bit_pos_vps_extensions = -1;
	if (!vps->state) {
		vps->id = vps_id;
		vps->state = 1;
	}

	vps->base_layer_internal_flag = gf_bs_read_int(bs, 1);
	vps->base_layer_available_flag = gf_bs_read_int(bs, 1);
	vps->max_layers = 1 + gf_bs_read_int(bs, 6);
	if (vps->max_layers>MAX_LHVC_LAYERS) {
		GF_LOG(GF_LOG_ERROR, GF_LOG_CODING, ("[HEVC] sorry, %d layers in VPS but only %d supported\n", vps->max_layers, MAX_LHVC_LAYERS));
		return -1;
	}
	vps->max_sub_layers = gf_bs_read_int(bs, 3) + 1;
	vps->temporal_id_nesting = gf_bs_read_int(bs, 1);
	/* vps_reserved_ffff_16bits = */ gf_bs_read_int(bs, 16);
	profile_tier_level(bs, 1, vps->max_sub_layers-1, &vps->ptl);

	vps_sub_layer_ordering_info_present_flag = gf_bs_read_int(bs, 1);
	for (i=(vps_sub_layer_ordering_info_present_flag ? 0 : vps->max_sub_layers - 1); i < vps->max_sub_layers; i++) {
		/*vps_max_dec_pic_buffering_minus1[i] = */bs_get_ue(bs);
		/*vps_max_num_reorder_pics[i] = */bs_get_ue(bs);
		/*vps_max_latency_increase_plus1[i] = */bs_get_ue(bs);
	}
	vps->max_layer_id = gf_bs_read_int(bs, 6);
	if (vps->max_layer_id > MAX_LHVC_LAYERS) {
		GF_LOG(GF_LOG_ERROR, GF_LOG_CODING, ("[HEVC] VPS max layer ID %u but GPAC only supports %u\n", vps->max_layer_id,  MAX_LHVC_LAYERS));
		return -1;
	}
	vps->num_layer_sets = bs_get_ue(bs) + 1;
	if (vps->num_layer_sets > MAX_LHVC_LAYERS) {
		GF_LOG(GF_LOG_ERROR, GF_LOG_CODING, ("[HEVC] Wrong number of layer sets in VPS %d\n", vps->num_layer_sets));
		return -1;
	}
	for (i=1; i < vps->num_layer_sets; i++) {
		for (j=0; j <= vps->max_layer_id; j++) {
			layer_id_included_flag[ i ][ j ] = gf_bs_read_int(bs, 1);
		}
	}
	vps->num_layers_in_id_list[0] = 1;
	for (i = 1; i < vps->num_layer_sets; i++) {
		u32 n, m;
		n = 0;
		for (m = 0; m <= vps->max_layer_id; m++)
			if (layer_id_included_flag[i][m]) {
				vps->LayerSetLayerIdList[i][n++] = m;
				if (vps->LayerSetLayerIdListMax[i] < m)
					vps->LayerSetLayerIdListMax[i] = m;
			}
		vps->num_layers_in_id_list[i] = n;
	}
	if (/*vps_timing_info_present_flag*/gf_bs_read_int(bs, 1)) {
		u32 vps_num_hrd_parameters;
		/*u32 vps_num_units_in_tick = */gf_bs_read_int(bs, 32);
		/*u32 vps_time_scale = */gf_bs_read_int(bs, 32);
		if (/*vps_poc_proportional_to_timing_flag*/gf_bs_read_int(bs, 1)) {
			/*vps_num_ticks_poc_diff_one_minus1*/bs_get_ue(bs);
		}
		vps_num_hrd_parameters = bs_get_ue(bs);
		for( i = 0; i < vps_num_hrd_parameters; i++ ) {
			Bool cprms_present_flag = GF_TRUE;
			/*hrd_layer_set_idx[i] = */bs_get_ue(bs);
			if (i>0)
				cprms_present_flag = gf_bs_read_int(bs, 1) ;
			hevc_parse_hrd_parameters(bs, cprms_present_flag, vps->max_sub_layers - 1);
		}
	}
	if (stop_at_vps_ext) {
		return vps_id;
	}

	vps_extension_flag = gf_bs_read_int(bs, 1);
	if (vps_extension_flag ) {
		Bool res;
		gf_bs_align(bs);
		res = hevc_parse_vps_extension(vps, bs);
		if (res!=GF_TRUE) {
			GF_LOG(GF_LOG_ERROR, GF_LOG_CODING, ("[HEVC] Failed to parse VPS extensions\n"));
			return -1;
		}
		if (/*vps_extension2_flag*/gf_bs_read_int(bs, 1)) {
			while (gf_bs_available(bs)) {
				/*vps_extension_data_flag */ gf_bs_read_int(bs, 1);
			}
		}
	}
	return vps_id;
}
