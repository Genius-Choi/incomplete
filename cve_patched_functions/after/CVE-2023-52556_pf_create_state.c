pf_create_state(struct pf_pdesc *pd, struct pf_rule *r, struct pf_rule *a,
    struct pf_rule *nr, struct pf_state_key **skw, struct pf_state_key **sks,
    int *rewrite, struct pf_state **sm, int tag, struct pf_rule_slist *rules,
    struct pf_rule_actions *act, struct pf_src_node *sns[PF_SN_MAX])
{
	struct pf_state		*st = NULL;
	struct tcphdr		*th = &pd->hdr.tcp;
	u_int16_t		 mss = tcp_mssdflt;
	u_short			 reason;
	u_int			 i;

	st = pool_get(&pf_state_pl, PR_NOWAIT | PR_ZERO);
	if (st == NULL) {
		REASON_SET(&reason, PFRES_MEMORY);
		goto csfailed;
	}
	st->rule.ptr = r;
	st->anchor.ptr = a;
	st->natrule.ptr = nr;
	if (r->allow_opts)
		st->state_flags |= PFSTATE_ALLOWOPTS;
	if (r->rule_flag & PFRULE_STATESLOPPY)
		st->state_flags |= PFSTATE_SLOPPY;
	if (r->rule_flag & PFRULE_PFLOW)
		st->state_flags |= PFSTATE_PFLOW;
	if (r->rule_flag & PFRULE_NOSYNC)
		st->state_flags |= PFSTATE_NOSYNC;
#if NPFLOG > 0
	st->log = act->log & PF_LOG_ALL;
#endif	/* NPFLOG > 0 */
	st->qid = act->qid;
	st->pqid = act->pqid;
	st->rtableid[pd->didx] = act->rtableid;
	st->rtableid[pd->sidx] = -1;	/* return traffic is routed normally */
	st->min_ttl = act->min_ttl;
	st->set_tos = act->set_tos;
	st->max_mss = act->max_mss;
	st->state_flags |= act->flags;
#if NPFSYNC > 0
	st->sync_state = PFSYNC_S_NONE;
#endif	/* NPFSYNC > 0 */
	st->set_prio[0] = act->set_prio[0];
	st->set_prio[1] = act->set_prio[1];
	st->delay = act->delay;
	SLIST_INIT(&st->src_nodes);

	/*
	 * must initialize refcnt, before pf_state_insert() gets called.
	 * pf_state_inserts() grabs reference for pfsync!
	 */
	PF_REF_INIT(st->refcnt);
	mtx_init(&st->mtx, IPL_NET);

	switch (pd->proto) {
	case IPPROTO_TCP:
		st->src.seqlo = ntohl(th->th_seq);
		st->src.seqhi = st->src.seqlo + pd->p_len + 1;
		if ((th->th_flags & (TH_SYN|TH_ACK)) == TH_SYN &&
		    r->keep_state == PF_STATE_MODULATE) {
			/* Generate sequence number modulator */
			st->src.seqdiff = pf_tcp_iss(pd) - st->src.seqlo;
			if (st->src.seqdiff == 0)
				st->src.seqdiff = 1;
			pf_patch_32(pd, &th->th_seq,
			    htonl(st->src.seqlo + st->src.seqdiff));
			*rewrite = 1;
		} else
			st->src.seqdiff = 0;
		if (th->th_flags & TH_SYN) {
			st->src.seqhi++;
			st->src.wscale = pf_get_wscale(pd);
		}
		st->src.max_win = MAX(ntohs(th->th_win), 1);
		if (st->src.wscale & PF_WSCALE_MASK) {
			/* Remove scale factor from initial window */
			int win = st->src.max_win;
			win += 1 << (st->src.wscale & PF_WSCALE_MASK);
			st->src.max_win = (win - 1) >>
			    (st->src.wscale & PF_WSCALE_MASK);
		}
		if (th->th_flags & TH_FIN)
			st->src.seqhi++;
		st->dst.seqhi = 1;
		st->dst.max_win = 1;
		pf_set_protostate(st, PF_PEER_SRC, TCPS_SYN_SENT);
		pf_set_protostate(st, PF_PEER_DST, TCPS_CLOSED);
		st->timeout = PFTM_TCP_FIRST_PACKET;
		pf_status.states_halfopen++;
		break;
	case IPPROTO_UDP:
		pf_set_protostate(st, PF_PEER_SRC, PFUDPS_SINGLE);
		pf_set_protostate(st, PF_PEER_DST, PFUDPS_NO_TRAFFIC);
		st->timeout = PFTM_UDP_FIRST_PACKET;
		break;
	case IPPROTO_ICMP:
#ifdef INET6
	case IPPROTO_ICMPV6:
#endif	/* INET6 */
		st->timeout = PFTM_ICMP_FIRST_PACKET;
		break;
	default:
		pf_set_protostate(st, PF_PEER_SRC, PFOTHERS_SINGLE);
		pf_set_protostate(st, PF_PEER_DST, PFOTHERS_NO_TRAFFIC);
		st->timeout = PFTM_OTHER_FIRST_PACKET;
	}

	st->creation = getuptime();
	st->expire = getuptime();

	if (pd->proto == IPPROTO_TCP) {
		if (st->state_flags & PFSTATE_SCRUB_TCP &&
		    pf_normalize_tcp_init(pd, &st->src)) {
			REASON_SET(&reason, PFRES_MEMORY);
			goto csfailed;
		}
		if (st->state_flags & PFSTATE_SCRUB_TCP && st->src.scrub &&
		    pf_normalize_tcp_stateful(pd, &reason, st,
		    &st->src, &st->dst, rewrite)) {
			/* This really shouldn't happen!!! */
			DPFPRINTF(LOG_ERR,
			    "%s: tcp normalize failed on first pkt", __func__);
			goto csfailed;
		}
	}
	st->direction = pd->dir;

	if (pf_state_key_setup(pd, skw, sks, act->rtableid)) {
		REASON_SET(&reason, PFRES_MEMORY);
		goto csfailed;
	}

	if (pf_set_rt_ifp(st, pd->src, (*skw)->af, sns) != 0) {
		REASON_SET(&reason, PFRES_NOROUTE);
		goto csfailed;
	}

	for (i = 0; i < PF_SN_MAX; i++)
		if (sns[i] != NULL) {
			struct pf_sn_item	*sni;

			sni = pool_get(&pf_sn_item_pl, PR_NOWAIT);
			if (sni == NULL) {
				REASON_SET(&reason, PFRES_MEMORY);
				goto csfailed;
			}
			sni->sn = sns[i];
			SLIST_INSERT_HEAD(&st->src_nodes, sni, next);
			sni->sn->states++;
		}

#if NPFSYNC > 0
	pfsync_init_state(st, *skw, *sks, 0);
#endif

	if (pf_state_insert(BOUND_IFACE(r, pd->kif), skw, sks, st)) {
		*sks = *skw = NULL;
		REASON_SET(&reason, PFRES_STATEINS);
		goto csfailed;
	} else
		*sm = st;

	/*
	 * Make state responsible for rules it binds here.
	 */
	memcpy(&st->match_rules, rules, sizeof(st->match_rules));
	memset(rules, 0, sizeof(*rules));
	STATE_INC_COUNTERS(st);

	if (tag > 0) {
		pf_tag_ref(tag);
		st->tag = tag;
	}
	if (pd->proto == IPPROTO_TCP && (th->th_flags & (TH_SYN|TH_ACK)) ==
	    TH_SYN && r->keep_state == PF_STATE_SYNPROXY && pd->dir == PF_IN) {
		int rtid = pd->rdomain;
		if (act->rtableid >= 0)
			rtid = act->rtableid;
		pf_set_protostate(st, PF_PEER_SRC, PF_TCPS_PROXY_SRC);
		st->src.seqhi = arc4random();
		/* Find mss option */
		mss = pf_get_mss(pd);
		mss = pf_calc_mss(pd->src, pd->af, rtid, mss);
		mss = pf_calc_mss(pd->dst, pd->af, rtid, mss);
		st->src.mss = mss;
		pf_send_tcp(r, pd->af, pd->dst, pd->src, th->th_dport,
		    th->th_sport, st->src.seqhi, ntohl(th->th_seq) + 1,
		    TH_SYN|TH_ACK, 0, st->src.mss, 0, 1, 0, pd->rdomain);
		REASON_SET(&reason, PFRES_SYNPROXY);
		return (PF_SYNPROXY_DROP);
	}

	return (PF_PASS);

csfailed:
	if (st) {
		pf_normalize_tcp_cleanup(st);	/* safe even w/o init */
		pf_src_tree_remove_state(st);
		pool_put(&pf_state_pl, st);
	}

	for (i = 0; i < PF_SN_MAX; i++)
		if (sns[i] != NULL)
			pf_remove_src_node(sns[i]);

	return (PF_DROP);
}
