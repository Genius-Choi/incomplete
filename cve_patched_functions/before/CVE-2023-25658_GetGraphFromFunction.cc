Status TPUPartitionedCallOp::GetGraphFromFunction(
    Graph* graph, int device_ordinal, bool* use_spmd_for_xla_partitioning,
    TPUMetadata* tpu_metadata) {
  FunctionLibraryRuntime::InstantiateOptions opts;
  FHandle handle;
  TF_RETURN_IF_ERROR(library_runtime_->Instantiate(
      func_.name(), AttrSlice(&func_.attr()), opts, &handle));
  const FunctionBody* fbody = library_runtime_->GetFunctionBody(handle);
  if (fbody == nullptr) {
    return errors::Internal("Could not find handle ", handle);
  }
  CopyGraph(*fbody->graph, graph);

  // Pin the inputs and outputs to the local device to simplify the
  // function-dispatching logic.
  local_device_name_ = library_runtime_->device()->name();
  replaced_input_indices_.resize(fbody->arg_nodes.size(), false);
  for (Node* node : graph->op_nodes()) {
    if (node->IsArg() || node->IsRetval()) {
      node->set_assigned_device_name(local_device_name_);
    } else if (node->type_string() == "TPUReplicateMetadata") {
      // Record the producer name so it can be accessed later during metric
      // collection.
      string producer_name = GetProducerName(func_.name());
      node->AddAttr("_producer_name", producer_name);

      TF_RETURN_IF_ERROR(GetNodeAttr(node->attrs(), "num_cores_per_replica",
                                     &tpu_metadata->num_cores_per_replica));
      TF_RETURN_IF_ERROR(GetNodeAttr(node->attrs(),
                                     "use_spmd_for_xla_partitioning",
                                     use_spmd_for_xla_partitioning));
      VLOG(1) << "num_core_per_replica = "
              << tpu_metadata->num_cores_per_replica
              << ", use_spmd_for_xla_partitioning = "
              << *use_spmd_for_xla_partitioning;

      if (tpu_metadata->num_cores_per_replica > 1) {
        int num_replicas;
        TF_RETURN_IF_ERROR(
            GetNodeAttr(node->attrs(), "num_replicas", &num_replicas));
        if (num_replicas > 1) {
          return errors::InvalidArgument(
              "num_replicas shouldn't be large than 1, however it is: ",
              num_replicas);
        }

        TF_RETURN_IF_ERROR(GetNodeAttr(node->attrs(), "device_assignment",
                                       &tpu_metadata->device_assignment));

        if (!tpu_metadata->device_assignment.empty() && device_ordinal > 0) {
          return errors::InvalidArgument(
              "`device_assignment` shouldn't be set manually in the graph when "
              "round-robin core selection is enabled.");
        }

        tpu_metadata->topology = GetTPUTopology();
        VLOG(1) << "TPU topology: " << tpu_metadata->topology.DebugString();
        std::string topology_str;
        TF_RETURN_IF_ERROR(
            GetNodeAttr(node->attrs(), "topology", &topology_str));
        if (!topology_str.empty()) {
          LOG(WARNING)
              << "Ignore the `topology` value set in TPUReplicateMetadata "
                 "node, the TPU topology is queried in the runtime.";
        }
        node->ClearAttr("topology");
        node->AddAttr("topology", tpu_metadata->topology.SerializeAsString());

        if (tpu_metadata->topology.num_tasks() > 1) {
          return errors::InvalidArgument(
              "TPUPartitionedCallOp is only supported in single-host setup, "
              "however num_task is: ",
              tpu_metadata->topology.num_tasks());
        }

        if (tpu_metadata->device_assignment.empty()) {
          VLOG(1) << "Auto assigning device assignment";

          // The auto generated device assignment should be the same as or a
          // slice of TPU topology device_coordinates. This guarantees the
          // logical device IDs order the same as the physical device IDs order.
          // It is important for round-robin core selection, as we assume
          // the TPU device group for one inference request is
          // [TPU:device_ordinal, TPU:device_ordinal + num_cores_per_replica].

          auto coordinates_start =
              tpu_metadata->topology.device_coordinates().begin() +
              device_ordinal * 4;
          auto coordinates_end =
              tpu_metadata->topology.device_coordinates().begin() +
              (device_ordinal + tpu_metadata->num_cores_per_replica) * 4;

          node->ClearAttr("device_assignment");
          tpu_metadata->device_assignment.insert(
              tpu_metadata->device_assignment.begin(), coordinates_start,
              coordinates_end);
          node->AddAttr("device_assignment", tpu_metadata->device_assignment);
        }

        if (tpu_metadata->topology.num_tpu_devices_per_task() <
            tpu_metadata->num_cores_per_replica) {
          return errors::InvalidArgument(
              "num_cores_per_replica: ", tpu_metadata->num_cores_per_replica,
              " in the graph is larger than the number of available TPU "
              "devices: ",
              tpu_metadata->topology.num_tpu_devices_per_task());
        }
      }
    }
  }
  return OkStatus();
}
