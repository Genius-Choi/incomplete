static int io_issue_sqe(struct io_kiocb *req, bool force_nonblock,
			struct io_comp_state *cs)
{
	struct io_ring_ctx *ctx = req->ctx;
	int ret;

	switch (req->opcode) {
	case IORING_OP_NOP:
		ret = io_nop(req, cs);
		break;
	case IORING_OP_READV:
	case IORING_OP_READ_FIXED:
	case IORING_OP_READ:
		ret = io_read(req, force_nonblock, cs);
		break;
	case IORING_OP_WRITEV:
	case IORING_OP_WRITE_FIXED:
	case IORING_OP_WRITE:
		ret = io_write(req, force_nonblock, cs);
		break;
	case IORING_OP_FSYNC:
		ret = io_fsync(req, force_nonblock);
		break;
	case IORING_OP_POLL_ADD:
		ret = io_poll_add(req);
		break;
	case IORING_OP_POLL_REMOVE:
		ret = io_poll_remove(req);
		break;
	case IORING_OP_SYNC_FILE_RANGE:
		ret = io_sync_file_range(req, force_nonblock);
		break;
	case IORING_OP_SENDMSG:
		ret = io_sendmsg(req, force_nonblock, cs);
		break;
	case IORING_OP_SEND:
		ret = io_send(req, force_nonblock, cs);
		break;
	case IORING_OP_RECVMSG:
		ret = io_recvmsg(req, force_nonblock, cs);
		break;
	case IORING_OP_RECV:
		ret = io_recv(req, force_nonblock, cs);
		break;
	case IORING_OP_TIMEOUT:
		ret = io_timeout(req);
		break;
	case IORING_OP_TIMEOUT_REMOVE:
		ret = io_timeout_remove(req);
		break;
	case IORING_OP_ACCEPT:
		ret = io_accept(req, force_nonblock, cs);
		break;
	case IORING_OP_CONNECT:
		ret = io_connect(req, force_nonblock, cs);
		break;
	case IORING_OP_ASYNC_CANCEL:
		ret = io_async_cancel(req);
		break;
	case IORING_OP_FALLOCATE:
		ret = io_fallocate(req, force_nonblock);
		break;
	case IORING_OP_OPENAT:
		ret = io_openat(req, force_nonblock);
		break;
	case IORING_OP_CLOSE:
		ret = io_close(req, force_nonblock, cs);
		break;
	case IORING_OP_FILES_UPDATE:
		ret = io_files_update(req, force_nonblock, cs);
		break;
	case IORING_OP_STATX:
		ret = io_statx(req, force_nonblock);
		break;
	case IORING_OP_FADVISE:
		ret = io_fadvise(req, force_nonblock);
		break;
	case IORING_OP_MADVISE:
		ret = io_madvise(req, force_nonblock);
		break;
	case IORING_OP_OPENAT2:
		ret = io_openat2(req, force_nonblock);
		break;
	case IORING_OP_EPOLL_CTL:
		ret = io_epoll_ctl(req, force_nonblock, cs);
		break;
	case IORING_OP_SPLICE:
		ret = io_splice(req, force_nonblock);
		break;
	case IORING_OP_PROVIDE_BUFFERS:
		ret = io_provide_buffers(req, force_nonblock, cs);
		break;
	case IORING_OP_REMOVE_BUFFERS:
		ret = io_remove_buffers(req, force_nonblock, cs);
		break;
	case IORING_OP_TEE:
		ret = io_tee(req, force_nonblock);
		break;
	default:
		ret = -EINVAL;
		break;
	}

	if (ret)
		return ret;

	/* If the op doesn't have a file, we're not polling for it */
	if ((ctx->flags & IORING_SETUP_IOPOLL) && req->file) {
		const bool in_async = io_wq_current_is_worker();

		/* workqueue context doesn't hold uring_lock, grab it now */
		if (in_async)
			mutex_lock(&ctx->uring_lock);

		io_iopoll_req_issued(req);

		if (in_async)
			mutex_unlock(&ctx->uring_lock);
	}

	return 0;
}
