vmxnet3_parse_hdr(struct sk_buff *skb, struct vmxnet3_tx_queue *tq,
		  struct vmxnet3_tx_ctx *ctx,
		  struct vmxnet3_adapter *adapter)
{
	u8 protocol = 0;

	if (ctx->mss) {	/* TSO */
		if (VMXNET3_VERSION_GE_4(adapter) && skb->encapsulation) {
			ctx->l4_offset = skb_inner_transport_offset(skb);
			ctx->l4_hdr_size = inner_tcp_hdrlen(skb);
			ctx->copy_size = ctx->l4_offset + ctx->l4_hdr_size;
		} else {
			ctx->l4_offset = skb_transport_offset(skb);
			ctx->l4_hdr_size = tcp_hdrlen(skb);
			ctx->copy_size = ctx->l4_offset + ctx->l4_hdr_size;
		}
	} else {
		if (skb->ip_summed == CHECKSUM_PARTIAL) {
			/* For encap packets, skb_checksum_start_offset refers
			 * to inner L4 offset. Thus, below works for encap as
			 * well as non-encap case
			 */
			ctx->l4_offset = skb_checksum_start_offset(skb);

			if (VMXNET3_VERSION_GE_4(adapter) &&
			    skb->encapsulation) {
				struct iphdr *iph = inner_ip_hdr(skb);

				if (iph->version == 4) {
					protocol = iph->protocol;
				} else {
					const struct ipv6hdr *ipv6h;

					ipv6h = inner_ipv6_hdr(skb);
					protocol = ipv6h->nexthdr;
				}
			} else {
				if (ctx->ipv4) {
					const struct iphdr *iph = ip_hdr(skb);

					protocol = iph->protocol;
				} else if (ctx->ipv6) {
					const struct ipv6hdr *ipv6h;

					ipv6h = ipv6_hdr(skb);
					protocol = ipv6h->nexthdr;
				}
			}

			switch (protocol) {
			case IPPROTO_TCP:
				ctx->l4_hdr_size = skb->encapsulation ? inner_tcp_hdrlen(skb) :
						   tcp_hdrlen(skb);
				break;
			case IPPROTO_UDP:
				ctx->l4_hdr_size = sizeof(struct udphdr);
				break;
			default:
				ctx->l4_hdr_size = 0;
				break;
			}

			ctx->copy_size = min(ctx->l4_offset +
					 ctx->l4_hdr_size, skb->len);
		} else {
			ctx->l4_offset = 0;
			ctx->l4_hdr_size = 0;
			/* copy as much as allowed */
			ctx->copy_size = min_t(unsigned int,
					       tq->txdata_desc_size,
					       skb_headlen(skb));
		}

		if (skb->len <= VMXNET3_HDR_COPY_SIZE)
			ctx->copy_size = skb->len;

		/* make sure headers are accessible directly */
		if (unlikely(!pskb_may_pull(skb, ctx->copy_size)))
			goto err;
	}

	if (unlikely(ctx->copy_size > tq->txdata_desc_size)) {
		tq->stats.oversized_hdr++;
		ctx->copy_size = 0;
		return 0;
	}

	return 1;
err:
	return -1;
}
