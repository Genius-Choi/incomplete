tensorflow::Status ExtractTensorFromEagerTensor(const PyObject* eager_tensor,
                                                TFE_Context* ctx,
                                                const Device* expected_device,
                                                const Tensor** output_tensor) {
  tensorflow::TensorHandle* handle = down_cast<tensorflow::TensorHandle*>(
      tensorflow::unwrap(ctx)->TFTensorHandleFromInterface(
          tensorflow::unwrap(EagerTensor_Handle(eager_tensor))));

  Device* actual_device = handle->device();
  TF_RETURN_IF_ERROR(handle->Tensor(output_tensor));
  // actual_device may be nullptr, which implies local CPU.
  if (expected_device == actual_device) return OkStatus();
  const string& expected_device_name = expected_device->attributes().name();
  if (actual_device == nullptr) {
    if (!IsCPUDevice(expected_device)) {
      return errors::Internal(
          "Expected the py_func to return a Tensor backed by memory in ",
          expected_device_name,
          ", but is actually backed by local host memory. This is a bug.");
    }
    return OkStatus();
  }
  // NOTE(ebrevdo): Here we could try comparing "actual_device_name"
  // (actual_device->attributes()->name()) to expected_device_name and ensure
  // they're the same.  However, this comparison fails if we create a ClusterDef
  // on localhost, mainly because the Device created by Eager code doesn't match
  // the device created by a session.  In this case, expected_device_name may
  // contain "worker" but the Eager device name contains "localhost".  Since we
  // can't easily access the true underlying device of "worker" here, we are not
  // able to perform a proper comparison.  Furthermore, we can't check
  // IsCPUDevice(actual_device) because the kernel's device may indeed be a
  // GPU device (the python interpreter doesn't use it, however).
  return OkStatus();
}
