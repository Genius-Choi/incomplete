static void gf_bt_update_timenode(GF_BTParser *parser, GF_Node *node)
{
	if (!node || !(parser->load->flags & GF_SM_LOAD_FOR_PLAYBACK)) return;

	switch (gf_node_get_tag(node)) {
	case TAG_MPEG4_AnimationStream:
		gf_bt_offset_time(parser, & ((M_AnimationStream*)node)->startTime);
		gf_bt_offset_time(parser, & ((M_AnimationStream*)node)->stopTime);
		break;
	case TAG_MPEG4_AudioBuffer:
		gf_bt_offset_time(parser, & ((M_AudioBuffer*)node)->startTime);
		gf_bt_offset_time(parser, & ((M_AudioBuffer*)node)->stopTime);
		break;
	case TAG_MPEG4_AudioClip:
		gf_bt_offset_time(parser, & ((M_AudioClip*)node)->startTime);
		gf_bt_offset_time(parser, & ((M_AudioClip*)node)->stopTime);
		break;
	case TAG_MPEG4_AudioSource:
		gf_bt_offset_time(parser, & ((M_AudioSource*)node)->startTime);
		gf_bt_offset_time(parser, & ((M_AudioSource*)node)->stopTime);
		break;
	case TAG_MPEG4_MovieTexture:
		gf_bt_offset_time(parser, & ((M_MovieTexture*)node)->startTime);
		gf_bt_offset_time(parser, & ((M_MovieTexture*)node)->stopTime);
		break;
	case TAG_MPEG4_TimeSensor:
		gf_bt_offset_time(parser, & ((M_TimeSensor*)node)->startTime);
		gf_bt_offset_time(parser, & ((M_TimeSensor*)node)->stopTime);
		break;
	case TAG_ProtoNode:
	{
		u32 i, nbFields;
		GF_FieldInfo inf;
		nbFields = gf_node_get_num_fields_in_mode(node, GF_SG_FIELD_CODING_ALL);
		for (i=0; i<nbFields; i++) {
			gf_node_get_field(node, i, &inf);
			if (inf.fieldType != GF_SG_VRML_SFTIME) continue;
			gf_bt_check_time_offset(parser, node, &inf);
		}
	}
	break;
	}
}
