  void VerifyInvoke() {
    std::vector<float> input = {1.0f, 2.0f, 3.0f};
    std::vector<float> variable = {0.0f, 1.0f, 2.0f};
    std::vector<float> expected_output = {2.0f, 4.0f, 6.0f};

    // typed_tensor<...> should work irrespective of custom alloc, since it
    // accesses output_tensor.data.
    memcpy(interpreter_->typed_tensor<float>(interpreter_->variables()[0]),
           variable.data(), 3 * sizeof(float));
    memcpy(interpreter_->typed_tensor<float>(0), input.data(),
           3 * sizeof(float));
    memcpy(interpreter_->typed_tensor<float>(1), input.data(),
           3 * sizeof(float));
    ASSERT_EQ(interpreter_->Invoke(), kTfLiteOk);
    TfLiteTensor* output_tensor =
        interpreter_->tensor(interpreter_->outputs()[0]);
    for (int i = 0; i < 3; ++i) {
      EXPECT_EQ(output_tensor->data.f[i], expected_output[i]) << i;
    }
  }
