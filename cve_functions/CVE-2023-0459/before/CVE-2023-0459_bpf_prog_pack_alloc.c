void *bpf_prog_pack_alloc(u32 size, bpf_jit_fill_hole_t bpf_fill_ill_insns)
{
	unsigned int nbits = BPF_PROG_SIZE_TO_NBITS(size);
	struct bpf_prog_pack *pack;
	unsigned long pos;
	void *ptr = NULL;

	mutex_lock(&pack_mutex);
	if (size > BPF_PROG_PACK_SIZE) {
		size = round_up(size, PAGE_SIZE);
		ptr = module_alloc(size);
		if (ptr) {
			bpf_fill_ill_insns(ptr, size);
			set_vm_flush_reset_perms(ptr);
			set_memory_rox((unsigned long)ptr, size / PAGE_SIZE);
		}
		goto out;
	}
	list_for_each_entry(pack, &pack_list, list) {
		pos = bitmap_find_next_zero_area(pack->bitmap, BPF_PROG_CHUNK_COUNT, 0,
						 nbits, 0);
		if (pos < BPF_PROG_CHUNK_COUNT)
			goto found_free_area;
	}

	pack = alloc_new_pack(bpf_fill_ill_insns);
	if (!pack)
		goto out;

	pos = 0;

found_free_area:
	bitmap_set(pack->bitmap, pos, nbits);
	ptr = (void *)(pack->ptr) + (pos << BPF_PROG_CHUNK_SHIFT);

out:
	mutex_unlock(&pack_mutex);
	return ptr;
}
