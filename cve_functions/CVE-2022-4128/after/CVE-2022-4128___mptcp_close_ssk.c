static void __mptcp_close_ssk(struct sock *sk, struct sock *ssk,
			      struct mptcp_subflow_context *subflow,
			      unsigned int flags)
{
	struct mptcp_sock *msk = mptcp_sk(sk);
	bool need_push, dispose_it;

	dispose_it = !msk->subflow || ssk != msk->subflow->sk;
	if (dispose_it)
		list_del(&subflow->node);

	lock_sock_nested(ssk, SINGLE_DEPTH_NESTING);

	if (flags & MPTCP_CF_FASTCLOSE)
		subflow->send_fastclose = 1;

	need_push = (flags & MPTCP_CF_PUSH) && __mptcp_retransmit_pending_data(sk);
	if (!dispose_it) {
		tcp_disconnect(ssk, 0);
		msk->subflow->state = SS_UNCONNECTED;
		mptcp_subflow_ctx_reset(subflow);
		release_sock(ssk);

		goto out;
	}

	/* if we are invoked by the msk cleanup code, the subflow is
	 * already orphaned
	 */
	if (ssk->sk_socket)
		sock_orphan(ssk);

	subflow->disposable = 1;

	/* if ssk hit tcp_done(), tcp_cleanup_ulp() cleared the related ops
	 * the ssk has been already destroyed, we just need to release the
	 * reference owned by msk;
	 */
	if (!inet_csk(ssk)->icsk_ulp_ops) {
		kfree_rcu(subflow, rcu);
	} else {
		/* otherwise tcp will dispose of the ssk and subflow ctx */
		if (ssk->sk_state == TCP_LISTEN) {
			tcp_set_state(ssk, TCP_CLOSE);
			mptcp_subflow_queue_clean(ssk);
			inet_csk_listen_stop(ssk);
		}
		__tcp_close(ssk, 0);

		/* close acquired an extra ref */
		__sock_put(ssk);
	}
	release_sock(ssk);

	sock_put(ssk);

	if (ssk == msk->first)
		msk->first = NULL;

out:
	if (ssk == msk->last_snd)
		msk->last_snd = NULL;

	if (need_push)
		__mptcp_push_pending(sk, 0);
}
