    .SetShapeFn([](InferenceContext* c) {
      ShapeHandle unused;
      TF_RETURN_WITH_CONTEXT_IF_ERROR(c->WithRank(c->input(0), 0, &unused),
                                      " for 'start'");
      TF_RETURN_WITH_CONTEXT_IF_ERROR(c->WithRank(c->input(1), 0, &unused),
                                      " for 'limit'");
      TF_RETURN_WITH_CONTEXT_IF_ERROR(c->WithRank(c->input(2), 0, &unused),
                                      " for 'delta'");
      const Tensor* start_t = c->input_tensor(0);
      const Tensor* limit_t = c->input_tensor(1);
      const Tensor* delta_t = c->input_tensor(2);
      DataType dtype;
      TF_RETURN_IF_ERROR(c->GetAttr("Tidx", &dtype));
      if (start_t == nullptr || limit_t == nullptr || delta_t == nullptr) {
        c->set_output(0, c->Vector(InferenceContext::kUnknownDim));
        return Status::OK();
      }
      if (dtype == DT_INT32) {
        return RangeSize<int32>(start_t, limit_t, delta_t, c);
      } else if (dtype == DT_INT16) {
        return RangeSize<int16>(start_t, limit_t, delta_t, c);
      } else if (dtype == DT_INT8) {
        return RangeSize<int8>(start_t, limit_t, delta_t, c);
      } else if (dtype == DT_INT64) {
        return RangeSize<int64_t>(start_t, limit_t, delta_t, c);
      } else if (dtype == DT_UINT16) {
        return RangeSize<uint16>(start_t, limit_t, delta_t, c);
      } else if (dtype == DT_UINT32) {
        return RangeSize<uint32>(start_t, limit_t, delta_t, c);
      } else if (dtype == DT_FLOAT) {
        return RangeSize<float>(start_t, limit_t, delta_t, c);
      } else if (dtype == DT_DOUBLE) {
        return RangeSize<double>(start_t, limit_t, delta_t, c);
      } else if (dtype == DT_BFLOAT16) {
        return RangeSize<bfloat16>(start_t, limit_t, delta_t, c);
      } else {
        return errors::InvalidArgument("Unsupported dtype", dtype);
      }
      return Status::OK();
    });
