ipf_init(void)
{
    struct ipf *ipf = xzalloc(sizeof *ipf);

    ovs_mutex_init_adaptive(&ipf->ipf_lock);
    ovs_mutex_lock(&ipf->ipf_lock);
    hmap_init(&ipf->frag_lists);
    ovs_list_init(&ipf->frag_exp_list);
    ovs_list_init(&ipf->frag_complete_list);
    ovs_list_init(&ipf->reassembled_pkt_list);
    atomic_init(&ipf->min_v4_frag_size, IPF_V4_FRAG_SIZE_MIN_DEF);
    atomic_init(&ipf->min_v6_frag_size, IPF_V6_FRAG_SIZE_MIN_DEF);
    ipf->max_v4_frag_list_size = DIV_ROUND_UP(
        IPV4_PACKET_MAX_SIZE - IPV4_PACKET_MAX_HDR_SIZE,
        ipf->min_v4_frag_size - IPV4_PACKET_MAX_HDR_SIZE);
    ovs_mutex_unlock(&ipf->ipf_lock);
    atomic_count_init(&ipf->nfrag, 0);
    for (size_t i = 0; i < IPF_NFRAGS_NUM_CNTS; i++) {
        atomic_init(&ipf->n4frag_cnt[i], 0);
        atomic_init(&ipf->n6frag_cnt[i], 0);
    }
    atomic_init(&ipf->nfrag_max, IPF_MAX_FRAGS_DEFAULT);
    atomic_init(&ipf->ifp_v4_enabled, true);
    atomic_init(&ipf->ifp_v6_enabled, true);
    latch_init(&ipf->ipf_clean_thread_exit);
    ipf->ipf_clean_thread = ovs_thread_create("ipf_clean",
                                         ipf_clean_thread_main, ipf);

    return ipf;
}
