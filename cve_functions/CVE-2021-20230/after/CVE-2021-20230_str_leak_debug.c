NOEXPORT void str_leak_debug(const ALLOC_LIST *alloc_list, int change) {
    static size_t entries=0;
    LEAK_ENTRY *entry;
    int new_entry;
    int allocations;

    if(service_options.log_level<LOG_DEBUG) /* performance optimization */
        return;
#ifdef USE_OS_THREADS
    if(!stunnel_locks[STUNNEL_LOCKS-1]) /* threads not initialized */
        return;
#endif /* USE_OS_THREADS */
    if(!number_of_sections) /* configuration file not initialized */
        return;

    entry=leak_search(alloc_list);
    /* the race condition may lead to false positives, which is handled later */
    new_entry=entry->alloc_line!=alloc_list->alloc_line ||
        entry->alloc_file!=alloc_list->alloc_file;

    if(new_entry) { /* the file:line pair was encountered for the first time */
        CRYPTO_THREAD_write_lock(stunnel_locks[LOCK_LEAK_HASH]);
        entry=leak_search(alloc_list); /* the list may have changed */
        if(entry->alloc_line==0) {
            if(entries>LEAK_TABLE_SIZE-100) { /* this should never happen */
                CRYPTO_THREAD_unlock(stunnel_locks[LOCK_LEAK_HASH]);
                return;
            }
            entries++;
            entry->alloc_line=alloc_list->alloc_line;
            entry->alloc_file=alloc_list->alloc_file;
        }
        CRYPTO_THREAD_unlock(stunnel_locks[LOCK_LEAK_HASH]);
    }

    /* for performance we try to avoid calling CRYPTO_atomic_add() here */
#ifdef USE_OS_THREADS
#if defined(__GNUC__) && defined(__ATOMIC_ACQ_REL)
    if(__atomic_is_lock_free(sizeof entry->num, &entry->num))
        allocations=__atomic_add_fetch(&entry->num, change, __ATOMIC_ACQ_REL);
    else
        CRYPTO_atomic_add(&entry->num, change, &allocations,
            stunnel_locks[LOCK_LEAK_HASH]);
#elif defined(_MSC_VER)
    allocations=InterlockedExchangeAdd(&entry->num, change)+change;
#else /* atomic add not directly supported by the compiler */
    CRYPTO_atomic_add(&entry->num, change, &allocations,
        stunnel_locks[LOCK_LEAK_HASH]);
#endif
#else /* USE_OS_THREADS */
    allocations=(entry->num+=change);
#endif /* USE_OS_THREADS */

    if(allocations<=leak_threshold()) /* leak not detected */
        return;
    if(allocations<=entry->max) /* not the biggest leak for this entry */
        return;
    if(entry->max) { /* not the first time we found a leak for this entry */
        entry->max=allocations; /* just update the value */
        return;
    }
    /* we *may* need to allocate a new leak_results entry */
    /* locking is slow, so we try to avoid it if possible */
    CRYPTO_THREAD_write_lock(stunnel_locks[LOCK_LEAK_RESULTS]);
    if(entry->max==0) { /* the table may have changed */
        leak_results[leak_result_num]=entry;
        entry->max=allocations;
        ++leak_result_num; /* at the end to avoid a lock in leak_report() */
    } else { /* gracefully handle the race condition */
        entry->max=allocations;
    }
    CRYPTO_THREAD_unlock(stunnel_locks[LOCK_LEAK_RESULTS]);
}
