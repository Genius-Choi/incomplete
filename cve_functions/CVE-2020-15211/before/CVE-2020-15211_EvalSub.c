void EvalSub(TfLiteContext* context, TfLiteNode* node, TfLiteSubParams* params,
             const OpData* data, const TfLiteTensor* input1,
             const TfLiteTensor* input2, TfLiteTensor* output) {
  const bool requires_broadcast = data->requires_broadcast;
  switch (output->type) {
    case kTfLiteInt32:
      EvalSubImpl<kernel_type, int32_t>(context, node, params, data, input1,
                                        input2, requires_broadcast, output);
      break;
    case kTfLiteFloat32:
      EvalSubImpl<kernel_type, float>(context, node, params, data, input1,
                                      input2, requires_broadcast, output);
      break;
    case kTfLiteInt64:
      EvalSubImpl<kernel_type, int64_t>(context, node, params, data, input1,
                                        input2, requires_broadcast, output);
      break;

    default:
      TF_LITE_KERNEL_LOG(context, "output type %s is not supported.",
                         TfLiteTypeGetName(output->type));
  }
}
